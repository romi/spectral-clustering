{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to SpectralClustering","text":"<p>For full documentation of the ROMI project visit docs.romi-project.eu.</p>"},{"location":"#about","title":"About","text":"<p>A Python package designed to perform both semantic and instance segmentation of 3D plant point clouds, providing a robust and automatic pipeline for plant structure analysis.</p>"},{"location":"#overview","title":"Overview","text":"<p>Spectral Clustering is a powerful tool for accurate segmentation and classification of plant 3D point clouds. By leveraging advanced graph-based methods, this package enables simultaneous semantic and instance segmentation, correcting potential segmentation defects and incorporating plant structural knowledge.</p> <p>This method has been tested on both synthetic and real datasets to demonstrate reliability and efficiency.</p>"},{"location":"#getting-started","title":"Getting started","text":"<p>To install the <code>spectral_clustering</code> conda package in an existing environment, first activate it, then proceed as follows: <pre><code>conda install spectral_clustering -c romi-eu\n</code></pre></p>"},{"location":"#context","title":"Context","text":"<p>Accurate segmentation and classification of plants in 3D point clouds are essential for automated plant phenotyping. Traditional approaches rely on detecting plant organs based on local geometry but often overlook global plant structure.</p>"},{"location":"#key-features","title":"Key Features","text":"<ol> <li> <p>Point Scale Analysis</p> <ul> <li>Utilizes similarity graphs to compute geometric attributes from the spectrum.</li> <li>Distinguishes between linear organs (e.g., stems, branches, petioles) and planar organs (e.g., leaf blades).</li> </ul> </li> <li> <p>Organ Scale Analysis</p> <ul> <li>Employs quotient graphs for detailed classification and to correct segmentation errors.</li> <li>Maintains structural consistency of the plant.</li> </ul> </li> </ol>"},{"location":"#applications","title":"Applications","text":"<ul> <li>Synthetic and real 3D point cloud datasets of plants such as Chenopodium album (wild spinach) and Solanum lycopersicum (tomato plant).</li> <li>Automatic pipelines for plant research.</li> </ul>"},{"location":"#bibliography","title":"Bibliography","text":"<p>This package is closely related to the following thesis:</p> <p>Katia MIRANDE - Semantic and instance segmentation of plant 3D point cloud. The work explores graph-based methods at point and organ scales for plant phenotyping. Full text can be accessed here.</p>"},{"location":"#contribution-license","title":"Contribution &amp; License","text":"<p>We welcome contributions from the community! If you'd like to contribute, feel free to fork the repository or raise an issue.</p>"},{"location":"dev/","title":"Developers","text":""},{"location":"dev/#clone-a-branch-to-another-repository","title":"Clone a Branch to Another Repository","text":"<p>For clarity, this example demonstrates how to create a clone of the <code>master</code> branch from Inria's GitLab to ROMI's GitHub repository.</p>"},{"location":"dev/#initial-setup-first-time","title":"Initial Setup (First Time)","text":"<ol> <li>Create an empty repository on ROMI's GitHub.</li> <li>If not done yet, clone the original GitLab repository.</li> <li>Add a remote named <code>romi</code> pointing to the new empty GitHub repository:    <pre><code>git remote add romi https://github.com/romi/spectral-clustering.git\n</code></pre></li> </ol>"},{"location":"dev/#updating-the-master-branch-from-the-original-repository","title":"Updating the <code>master</code> Branch from the Original Repository","text":"<ol> <li>Push the local changes from the original <code>master</code> branch to ROMI's GitHub repository (execute this from the repository root):    <pre><code>git push romi master\n</code></pre></li> </ol>"},{"location":"dev/#testing-documentation-locally","title":"Testing Documentation Locally","text":"<p>To preview and test the MkDocs documentation locally, make sure you have the necessary tools installed on your system. You can do this by installing the <code>'doc'</code> optional dependencies specified in the <code>pyproject.toml</code> file as follows:</p> <pre><code>python -m pip install -e '.[doc]'\n</code></pre> <p>Next, navigate to the root directory of your project (where the <code>mkdocs.yml</code> file is located) and run the following command:</p> <pre><code>python docs/assets/scripts/gen_ref_pages.py\nmkdocs serve\n</code></pre> <p>This command starts a local development server, which can be accessed by opening <code>http://127.0.0.1:8000/</code> in your web browser. Any updates made to the documentation files will automatically refresh in your browser.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>spectral_clustering<ul> <li>Segmentation_Dijkstra_litt</li> <li>Viterbi</li> <li>branching_graph</li> <li>constraint_program</li> <li>dijkstra_segmentation</li> <li>display_and_export</li> <li>evaluation</li> <li>point_cloud_graph</li> <li>quotient_graph</li> <li>quotientgraph_operations</li> <li>quotientgraph_semantics</li> <li>segmentation_algorithms</li> <li>similarity_graph</li> <li>split_and_merge</li> <li>topological_energy</li> <li>utils<ul> <li>angle</li> <li>size</li> <li>sparse</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/spectral_clustering/","title":"spectral_clustering","text":"<p>A Python package to perform segmentation of 3D plant point clouds.</p>"},{"location":"reference/spectral_clustering/Segmentation_Dijkstra_litt/","title":"Segmentation_Dijkstra_litt","text":""},{"location":"reference/spectral_clustering/Segmentation_Dijkstra_litt/#spectral_clustering.Segmentation_Dijkstra_litt.affichesegmlitt","title":"affichesegmlitt","text":"<pre><code>affichesegmlitt(pcd, G, segmentdict, c)\n</code></pre> <p>Displays a 3D point cloud and its corresponding graph representation.</p> <p>This function visualizes a 3D point cloud along with its graph structure. It creates a graph representation where nodes correspond to the points in the point cloud, and edges are defined based on the provided segment dictionary. The visualization allows the user to see the structure of the graph overlayed on the point cloud.</p> <p>Parameters:</p> <ul> <li> <code>pcd</code>               (<code>PointCloud</code>)           \u2013            <p>The 3D point cloud to be visualized.</p> </li> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>The base graph structure associated with the point cloud.</p> </li> <li> <code>segmentdict</code>               (<code>dict[int, list[int]]</code>)           \u2013            <p>A dictionary where each key is a segment index and the value is a list of point indices representing a path in the graph.</p> </li> <li> <code>c</code>               (<code>int</code>)           \u2013            <p>The number of graph segments to visualize. Segments in the range [1, c-1] from the segment dictionary are visualized.</p> </li> </ul> Source code in <code>spectral_clustering/Segmentation_Dijkstra_litt.py</code> <pre><code>def affichesegmlitt(pcd, G, segmentdict, c):\n    \"\"\"Displays a 3D point cloud and its corresponding graph representation.\n\n    This function visualizes a 3D point cloud along with its graph structure.\n    It creates a graph representation where nodes correspond to the points in\n    the point cloud, and edges are defined based on the provided segment\n    dictionary. The visualization allows the user to see the structure of\n    the graph overlayed on the point cloud.\n\n    Parameters\n    ----------\n    pcd : open3d.geometry.PointCloud\n        The 3D point cloud to be visualized.\n    G : networkx.Graph\n        The base graph structure associated with the point cloud.\n    segmentdict : dict[int, list[int]]\n        A dictionary where each key is a segment index and the value is a list\n        of point indices representing a path in the graph.\n    c : int\n        The number of graph segments to visualize. Segments in the range\n        [1, c-1] from the segment dictionary are visualized.\n\n    \"\"\"\n    Gaffichage = nx.Graph()\n    pts = np.array(pcd.points)\n    N = len(pcd.points)\n    for i in range(N):\n        Gaffichage.add_node(i, pos=pts[i])\n    for i in range(1, c):\n        Gaffichage.add_path(segmentdict[i])\n    edgelist = Gaffichage.edges\n    print(Gaffichage.edges)\n    cloption = o3d.visualization.RenderOption()\n    graph = o3d.geometry.LineSet()\n    graph.points = o3d.utility.Vector3dVector(pts)\n    graph.lines = o3d.utility.Vector2iVector(edgelist)\n    o3d.visualization.draw_geometries([graph, pcd])\n</code></pre>"},{"location":"reference/spectral_clustering/Segmentation_Dijkstra_litt/#spectral_clustering.Segmentation_Dijkstra_litt.sortienuagelitt","title":"sortienuagelitt","text":"<pre><code>sortienuagelitt(pcd, G, segmentdict, c)\n</code></pre> <p>Sorts segments and labels points based on the shortest paths in a graph.</p> <p>This function processes a point cloud and a graph representing segments, calculates the shortest paths from specified segments to all other points, and labels each point in the point cloud according to the segment it is associated with or assigns a default label if no segment is reachable. It outputs a classified point cloud with these labels.</p> <p>Parameters:</p> <ul> <li> <code>pcd</code>               (<code>PointCloud</code>)           \u2013            <p>A point cloud object representing the spatial data. It is expected to have points that need to be classified.</p> </li> <li> <code>G</code>               (<code>MultiDiGraph</code>)           \u2013            <p>A graph containing nodes and edges representing segments. The nodes correspond to points or locations in the graph, and the edges have associated weights used for shortest path calculations.</p> </li> <li> <code>segmentdict</code>               (<code>dict</code>)           \u2013            <p>A dictionary where keys are segment identifiers (int or str) and values are lists of points or segment nodes. These represent specific paths or segments in the graph for label assignment.</p> </li> <li> <code>c</code>               (<code>int</code>)           \u2013            <p>A default label assigned to points that do not belong to any segment or do not have a reachable shortest path.</p> </li> </ul> Notes <p>The function saves the resulting classified point cloud data as a text file named <code>pcdclassifdijkstra2.txt</code>.</p> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If certain values could not be processed or matched during the segment identification process in the segment dictionary.</p> </li> </ul> Source code in <code>spectral_clustering/Segmentation_Dijkstra_litt.py</code> <pre><code>def sortienuagelitt(pcd, G, segmentdict, c):\n    \"\"\"Sorts segments and labels points based on the shortest paths in a graph.\n\n    This function processes a point cloud and a graph representing segments,\n    calculates the shortest paths from specified segments to all other points,\n    and labels each point in the point cloud according to the segment it is\n    associated with or assigns a default label if no segment is reachable.\n    It outputs a classified point cloud with these labels.\n\n    Parameters\n    ----------\n    pcd : open3d.geometry.PointCloud\n        A point cloud object representing the spatial data. It is expected\n        to have points that need to be classified.\n    G : networkx.classes.multidigraph.MultiDiGraph\n        A graph containing nodes and edges representing segments. The nodes\n        correspond to points or locations in the graph, and the edges have\n        associated weights used for shortest path calculations.\n    segmentdict : dict\n        A dictionary where keys are segment identifiers (int or str) and\n        values are lists of points or segment nodes. These represent specific\n        paths or segments in the graph for label assignment.\n    c : int\n        A default label assigned to points that do not belong to any segment\n        or do not have a reachable shortest path.\n\n    Notes\n    -----\n    The function saves the resulting classified point cloud data as a text file named `pcdclassifdijkstra2.txt`.\n\n    Raises\n    ------\n    ValueError\n        If certain values could not be processed or matched during\n        the segment identification process in the segment dictionary.\n    \"\"\"\n    label = []\n    chemintot = []\n    N = len(pcd.points)\n    for Seg, chemin in segmentdict.items():\n        chemintot = chemintot + chemin\n    # Transformation de la liste obtenue en set\n    setsegments = set(chemintot)\n    length, path = nx.multi_source_dijkstra(G, setsegments, weight='weight')\n    for p in range(N):\n        if p in length:\n            # S\u00e9lection du chemin qui concerne le point d'int\u00e9r\u00eat\n            j = 1\n            ind = -1\n            if length[p] == 0:\n                parrive = p\n            else:\n                parrive = path[p][0]\n            while ind == -1 and j &lt; c:\n                try:\n                    ind = segmentdict[j].index(parrive)\n                except ValueError:\n                    ind = -1\n                j = j + 1\n            j = j - 1\n            label = label + [j]\n        else:\n            label = label + [c]\n    label = np.asarray(label)\n    label = np.asarray(label.reshape(np.asarray(pcd.points).shape[0], 1), dtype=np.float64)\n    pcdtabclassif = np.concatenate([np.asarray(pcd.points), label], axis=1)\n    # FIXME: this should be a parameter:\n    np.savetxt('pcdclassifdijkstra2.txt', pcdtabclassif, delimiter=\",\")\n</code></pre>"},{"location":"reference/spectral_clustering/Viterbi/","title":"Viterbi","text":""},{"location":"reference/spectral_clustering/Viterbi/#spectral_clustering.Viterbi.add_attributes_to_spanning_tree","title":"add_attributes_to_spanning_tree","text":"<pre><code>add_attributes_to_spanning_tree(st_tree, t, list_att=['planarity', 'linearity', 'scattering'])\n</code></pre> <p>Adds specific attributes to a spanning tree structure from a graph.</p> <p>The function updates attributes of nodes in the spanning tree using attribute values present in the original graph. For each node in the tree, a corresponding node from the original graph is identified, and specified attributes are copied over. The user can define which attributes to copy via the <code>list_att</code> parameter.</p> <p>Parameters:</p> <ul> <li> <code>st_tree</code>               (<code>Graph</code>)           \u2013            <p>The spanning tree represented as a NetworkX Graph, containing nodes with attributes that are to be copied.</p> </li> <li> <code>t</code>               (<code>Tree</code>)           \u2013            <p>A class instance representing another tree object. This tree provides methods like <code>dict_of_ids</code>, <code>list_of_ids</code>, and <code>add_attribute_to_id</code>. It is used to retrieve the list of node IDs and update their attributes.</p> </li> <li> <code>list_att</code>               (<code>list of str</code>, default:                   <code>['planarity', 'linearity', 'scattering']</code> )           \u2013            <p>List of attribute names to be added to the spanning tree. By default, the attributes 'planarity', 'linearity', and 'scattering' are copied.</p> </li> </ul> Source code in <code>spectral_clustering/Viterbi.py</code> <pre><code>def add_attributes_to_spanning_tree(st_tree, t, list_att=['planarity', 'linearity', 'scattering']):\n    \"\"\"    Adds specific attributes to a spanning tree structure from a graph.\n\n    The function updates attributes of nodes in the spanning tree using attribute\n    values present in the original graph. For each node in the tree, a corresponding\n    node from the original graph is identified, and specified attributes are copied\n    over. The user can define which attributes to copy via the `list_att` parameter.\n\n    Parameters\n    ----------\n    st_tree : networkx.Graph\n        The spanning tree represented as a NetworkX Graph, containing nodes\n        with attributes that are to be copied.\n    t : Tree\n        A class instance representing another tree object. This tree provides\n        methods like `dict_of_ids`, `list_of_ids`, and `add_attribute_to_id`.\n        It is used to retrieve the list of node IDs and update their attributes.\n    list_att : list of str, optional\n        List of attribute names to be added to the spanning tree. By default,\n        the attributes 'planarity', 'linearity', and 'scattering' are copied.\n    \"\"\"\n    dict = t.dict_of_ids()\n    for node in t.list_of_ids():\n        st_node = dict[node]['attributes']['nx_label']\n        for att in list_att:\n            t.add_attribute_to_id(att, st_tree.nodes[st_node][att], node)\n</code></pre>"},{"location":"reference/spectral_clustering/Viterbi/#spectral_clustering.Viterbi.add_viterbi_results_to_quotient_graph","title":"add_viterbi_results_to_quotient_graph","text":"<pre><code>add_viterbi_results_to_quotient_graph(quotientgraph, t, list_semantics=['leaf', 'stem', 'NSP'])\n</code></pre> <p>Adds Viterbi classification results to the nodes of a quotient graph.</p> <p>This function processes the Viterbi classification results stored in a tree-like data structure and assigns them to corresponding nodes in a quotient graph. It updates the quotient graph nodes with new attributes related to their Viterbi classification.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph whose nodes are to be updated with Viterbi classification results.</p> </li> <li> <code>t</code>               (<code>object</code>)           \u2013            <p>A tree-like data structure that contains node identifiers and corresponding attributes, including <code>nx_label</code> and <code>viterbi_type</code>.</p> </li> <li> <code>list_semantics</code>               (<code>list of str</code>, default:                   <code>['leaf', 'stem', 'NSP']</code> )           \u2013            <p>A list of strings specifying the semantics to process for Viterbi classifications. By default, it includes ['leaf', 'stem', 'NSP'].</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>The function updates the quotientgraph in-place, adding a <code>viterbi_class</code> attribute to its nodes.</p> </li> </ul> Source code in <code>spectral_clustering/Viterbi.py</code> <pre><code>def add_viterbi_results_to_quotient_graph(quotientgraph, t, list_semantics=['leaf', 'stem', 'NSP']):\n    \"\"\"Adds Viterbi classification results to the nodes of a quotient graph.\n\n    This function processes the Viterbi classification results stored in a tree-like\n    data structure and assigns them to corresponding nodes in a quotient graph. It\n    updates the quotient graph nodes with new attributes related to their Viterbi\n    classification.\n\n    Parameters\n    ----------\n    quotientgraph : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph whose nodes are to be updated with Viterbi classification\n        results.\n    t : object\n        A tree-like data structure that contains node identifiers and corresponding\n        attributes, including `nx_label` and `viterbi_type`.\n    list_semantics : list of str, optional\n        A list of strings specifying the semantics to process for Viterbi classifications.\n        By default, it includes ['leaf', 'stem', 'NSP'].\n\n    Returns\n    -------\n    None\n        The function updates the quotientgraph in-place, adding a `viterbi_class`\n        attribute to its nodes.\n    \"\"\"\n    dict = t.dict_of_ids()\n    for n in t.list_of_ids():\n        qg_node = dict[n]['attributes']['nx_label']\n        quotientgraph.nodes[qg_node]['viterbi_class'] = dict[n]['attributes']['viterbi_type']\n</code></pre>"},{"location":"reference/spectral_clustering/Viterbi/#spectral_clustering.Viterbi.build_spanning_tree","title":"build_spanning_tree","text":"<pre><code>build_spanning_tree(st_tree, root_label, list_att=['planarity', 'linearity', 'scattering'])\n</code></pre> <p>Builds a spanning tree from the given graph structure and initializes it with specific attributes for the root node.</p> <p>The spanning tree is constructed iteratively, starting from the root label and adding its connected nodes while copying their attributes.</p> <p>Parameters:</p> <ul> <li> <code>st_tree</code>               (<code>Graph</code>)           \u2013            <p>The input graph from which the spanning tree is to be constructed. It should be a NetworkX graph object with node attributes that will be used in the resulting spanning tree.</p> </li> <li> <code>root_label</code>               (<code>Any</code>)           \u2013            <p>The label of the root node for the spanning tree. This must exist as a node in <code>st_tree</code>.</p> </li> <li> <code>list_att</code>               (<code>list of str</code>, default:                   <code>['planarity', 'linearity', 'scattering']</code> )           \u2013            <p>A list of node attributes to be copied from the original graph <code>st_tree</code> to the spanning tree. By default, this list is ['planarity', 'linearity', 'scattering'].</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tree</code>           \u2013            <p>The constructed spanning tree with the attributes <code>nx_label</code> and any additional attributes from <code>list_att</code> added to each node.</p> </li> </ul> Source code in <code>spectral_clustering/Viterbi.py</code> <pre><code>def build_spanning_tree(st_tree, root_label, list_att=['planarity', 'linearity', 'scattering']):\n    \"\"\"Builds a spanning tree from the given graph structure and initializes it with specific attributes for the root node.\n\n    The spanning tree is constructed iteratively, starting from the root label and adding its connected nodes while\n    copying their attributes.\n\n    Parameters\n    ----------\n    st_tree : networkx.Graph\n        The input graph from which the spanning tree is to be constructed. It\n        should be a NetworkX graph object with node attributes that will be used\n        in the resulting spanning tree.\n    root_label : Any\n        The label of the root node for the spanning tree. This must exist as a\n        node in `st_tree`.\n    list_att : list of str, optional\n        A list of node attributes to be copied from the original graph `st_tree`\n        to the spanning tree. By default, this list is ['planarity', 'linearity',\n        'scattering'].\n\n    Returns\n    -------\n    Tree\n        The constructed spanning tree with the attributes `nx_label` and any\n        additional attributes from `list_att` added to each node.\n\n    \"\"\"\n    t = Tree()\n    t.add_attribute_to_id('nx_label', root_label)\n    for att in list_att:\n        t.add_attribute_to_id(att, st_tree.nodes[root_label][att])\n    list_of_nodes = [root_label]\n    increment_spanning_tree(st_tree, root_label, t, list_of_nodes, list_att)\n    return t\n</code></pre>"},{"location":"reference/spectral_clustering/Viterbi/#spectral_clustering.Viterbi.create_observation_list","title":"create_observation_list","text":"<pre><code>create_observation_list(t, list_obs=['planarity', 'linearity', 'scattering'], name='observations')\n</code></pre> <p>Creates a new attribute in the given tree structure, which contains a list of specific observation values from a predefined list of attributes for each node.</p> <p>This function iterates through each node in the tree's list of IDs, extracts the requested attributes from a dictionary of node information, and stores them as a new attribute in the tree structure.</p> <p>Parameters:</p> <ul> <li> <code>t</code>               (<code>Tree</code>)           \u2013            <p>The tree structure to which the new observation attribute will be added. It must provide access to its nodes and their associated attributes.</p> </li> <li> <code>list_obs</code>               (<code>list of str</code>, default:                   <code>['planarity', 'linearity', 'scattering']</code> )           \u2013            <p>A list of attribute names to be extracted from each node. Defaults to ['planarity', 'linearity', 'scattering'] if not specified.</p> </li> <li> <code>name</code>               (<code>str</code>, default:                   <code>'observations'</code> )           \u2013            <p>The name of the new attribute to be added to each node. Defaults to 'observations' if not specified.</p> </li> </ul> Source code in <code>spectral_clustering/Viterbi.py</code> <pre><code>def create_observation_list(t, list_obs=['planarity', 'linearity', 'scattering'], name='observations'):\n    \"\"\"\n    Creates a new attribute in the given tree structure, which contains a list of specific observation\n    values from a predefined list of attributes for each node.\n\n    This function iterates through each node in the tree's list of IDs, extracts the requested\n    attributes from a dictionary of node information, and stores them as a new attribute in the tree\n    structure.\n\n    Parameters\n    ----------\n    t : Tree\n        The tree structure to which the new observation attribute will be added. It must provide\n        access to its nodes and their associated attributes.\n    list_obs : list of str, optional\n        A list of attribute names to be extracted from each node. Defaults to ['planarity',\n        'linearity', 'scattering'] if not specified.\n    name : str, optional\n        The name of the new attribute to be added to each node. Defaults to 'observations' if not\n        specified.\n    \"\"\"\n    dict = t.dict_of_ids()\n    for node in t.list_of_ids():\n        obs = []\n        for att in list_obs:\n            obs.append(dict[node]['attributes'][att])\n        t.add_attribute_to_id(name, obs, node)\n</code></pre>"},{"location":"reference/spectral_clustering/Viterbi/#spectral_clustering.Viterbi.increment_spanning_tree","title":"increment_spanning_tree","text":"<pre><code>increment_spanning_tree(st_tree, root, t, list_of_nodes, list_att)\n</code></pre> <p>Recursively increments a spanning tree by traversing and adding nodes from a given root node in a graph.</p> <p>The function processes the graph <code>st_tree</code>, traverses neighbors of the <code>root</code> node, and adds their attributes and subtrees to the spanning tree <code>t</code>.</p> <p>Parameters:</p> <ul> <li> <code>st_tree</code>               (<code>Graph</code>)           \u2013            <p>The graph representing the original structure where traversal begins.</p> </li> <li> <code>root</code>               (<code>Any</code>)           \u2013            <p>The root node from which the function starts traversing neighbors.</p> </li> <li> <code>t</code>               (<code>Tree</code>)           \u2013            <p>The spanning tree being constructed or modified by appending subtrees and attributes.</p> </li> <li> <code>list_of_nodes</code>               (<code>list</code>)           \u2013            <p>A list that tracks nodes already visited to avoid revisiting and infinite loops during the traversal.</p> </li> <li> <code>list_att</code>               (<code>list</code>)           \u2013            <p>A list of attributes to be copied from the nodes in the original graph <code>st_tree</code> to the new spanning tree <code>t</code>.</p> </li> </ul> Source code in <code>spectral_clustering/Viterbi.py</code> <pre><code>def increment_spanning_tree(st_tree, root, t, list_of_nodes, list_att):\n    \"\"\"Recursively increments a spanning tree by traversing and adding nodes from a given root node in a graph.\n\n    The function processes the graph `st_tree`, traverses neighbors of the `root` node, and adds their\n    attributes and subtrees to the spanning tree `t`.\n\n    Parameters\n    ----------\n    st_tree : networkx.Graph\n        The graph representing the original structure where traversal\n        begins.\n    root : Any\n        The root node from which the function starts traversing neighbors.\n    t : Tree\n        The spanning tree being constructed or modified by appending\n        subtrees and attributes.\n    list_of_nodes : list\n        A list that tracks nodes already visited to avoid revisiting\n        and infinite loops during the traversal.\n    list_att : list\n        A list of attributes to be copied from the nodes in the original\n        graph `st_tree` to the new spanning tree `t`.\n    \"\"\"\n    for neighbor in st_tree.neighbors(root):\n        if neighbor not in list_of_nodes:\n            s = Tree()\n            s.add_attribute_to_id('nx_label', neighbor)\n            for att in list_att:\n                s.add_attribute_to_id(att, st_tree.nodes[neighbor][att])\n            list_of_nodes.append(neighbor)\n            increment_spanning_tree(st_tree, neighbor, s, list_of_nodes, list_att)\n            t.add_subtree(s)\n</code></pre>"},{"location":"reference/spectral_clustering/Viterbi/#spectral_clustering.Viterbi.read_pointcloudgraph_into_treex","title":"read_pointcloudgraph_into_treex","text":"<pre><code>read_pointcloudgraph_into_treex(pointcloudgraph)\n</code></pre> <p>Reads a point cloud graph object and processes it into a tree diagram before saving and re-loading it.</p> <p>This function performs the following operations: 1. Takes the input <code>pointcloudgraph</code> object. 2. Saves the object with specific attributes using serialization. 3. Reads the serialized object back into a tree representation. 4. Returns the re-loaded tree object.</p> <p>Parameters:</p> <ul> <li> <code>pointcloudgraph</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The input graph object representing a point cloud. This input should hold sufficient attributes required for further processing into a spanning tree format.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>object</code>           \u2013            <p>The deserialized tree object created from the saved graph. This object includes the processed attributes stored during the serialization step.</p> </li> </ul> Source code in <code>spectral_clustering/Viterbi.py</code> <pre><code>def read_pointcloudgraph_into_treex(pointcloudgraph):\n    \"\"\"Reads a point cloud graph object and processes it into a tree diagram before saving and re-loading it.\n\n    This function performs the following operations:\n    1. Takes the input `pointcloudgraph` object.\n    2. Saves the object with specific attributes using serialization.\n    3. Reads the serialized object back into a tree representation.\n    4. Returns the re-loaded tree object.\n\n    Parameters\n    ----------\n    pointcloudgraph : spectral_clustering.pointcloudgraph.PointCloudGraph\n        The input graph object representing a point cloud. This input should\n        hold sufficient attributes required for further processing into a\n        spanning tree format.\n\n    Returns\n    -------\n    object\n        The deserialized tree object created from the saved graph. This object\n        includes the processed attributes stored during the serialization step.\n    \"\"\"\n    mst = pointcloudgraph\n    save_object(mst, 'test_spanning_tree_attributes.p')\n    st_tree = read_object('test_spanning_tree_attributes.p')\n    return st_tree\n</code></pre>"},{"location":"reference/spectral_clustering/Viterbi/#spectral_clustering.Viterbi.viterbi_workflow","title":"viterbi_workflow","text":"<pre><code>viterbi_workflow(minimum_spanning_tree, quotient_graph, root=8, observation_list_import=['planarity2', 'linearity', 'intra_class_node_number'], initial_distribution=[1, 0], transition_matrix=[[0.2, 0.8], [0, 1]], parameters_emission=[[[0.4, 0.4], [0.8, 0.2]], [[0.8, 0.3], [0.4, 0.2]]])\n</code></pre> <p>Executes the Viterbi algorithm on input graphs and their corresponding data, enabling the classification and visualization of node attributes based on observed and derived metrics. The function processes a Minimum Spanning Tree (MST) and a Quotient Graph, preparing and embedding Viterbi results into these structures, while exporting their graphical and numerical details for further applications.</p> <p>Parameters:</p> <ul> <li> <code>minimum_spanning_tree</code>               (<code>object</code>)           \u2013            <p>A data structure representing the Minimum Spanning Tree (MST) of a graph.</p> </li> <li> <code>quotient_graph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph to which Viterbi results are added after computation.</p> </li> <li> <code>root</code>               (<code>int</code>, default:                   <code>8</code> )           \u2013            <p>The root node of the spanning tree, default is 8.</p> </li> <li> <code>observation_list_import</code>               (<code>list of str</code>, default:                   <code>['planarity2', 'linearity', 'intra_class_node_number']</code> )           \u2013            <p>List of attribute names to be considered during tree building and observations, default is ['planarity2', 'linearity', 'intra_class_node_number'].</p> </li> <li> <code>initial_distribution</code>               (<code>list of float</code>, default:                   <code>[1, 0]</code> )           \u2013            <p>The initial state probability distribution for the Viterbi algorithm, default is [1, 0].</p> </li> <li> <code>transition_matrix</code>               (<code>list of list of float</code>, default:                   <code>[[0.2, 0.8], [0, 1]]</code> )           \u2013            <p>The state transition probabilities for the Hidden Markov Model, default is [[0.2, 0.8], [0, 1]].</p> </li> <li> <code>parameters_emission</code>               (<code>list of list of list of float</code>, default:                   <code>[[[0.4, 0.4], [0.8, 0.2]], [[0.8, 0.3], [0.4, 0.2]]]</code> )           \u2013            <p>Parameters for Gaussian emission probabilities, where each sublist corresponds to the mean and standard deviation of the Gaussian distributions for a given state, default is [[[0.4, 0.4], [0.8, 0.2]], [[0.8, 0.3], [0.4, 0.2]]].</p> </li> </ul> Source code in <code>spectral_clustering/Viterbi.py</code> <pre><code>def viterbi_workflow(minimum_spanning_tree,\n                     quotient_graph,\n                     root=8,\n                     observation_list_import=['planarity2', 'linearity', 'intra_class_node_number'],\n                     initial_distribution=[1, 0],\n                     transition_matrix=[[0.2, 0.8], [0, 1]],\n                     parameters_emission=[[[0.4, 0.4], [0.8, 0.2]], [[0.8, 0.3], [0.4, 0.2]]]):\n    \"\"\"\n    Executes the Viterbi algorithm on input graphs and their corresponding data, enabling the\n    classification and visualization of node attributes based on observed and derived metrics.\n    The function processes a Minimum Spanning Tree (MST) and a Quotient Graph, preparing and\n    embedding Viterbi results into these structures, while exporting their graphical and numerical\n    details for further applications.\n\n    Parameters\n    ----------\n    minimum_spanning_tree : object\n        A data structure representing the Minimum Spanning Tree (MST) of a graph.\n    quotient_graph : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph to which Viterbi results are added after computation.\n    root : int, optional\n        The root node of the spanning tree, default is 8.\n    observation_list_import : list of str, optional\n        List of attribute names to be considered during tree building and observations,\n        default is ['planarity2', 'linearity', 'intra_class_node_number'].\n    initial_distribution : list of float, optional\n        The initial state probability distribution for the Viterbi algorithm,\n        default is [1, 0].\n    transition_matrix : list of list of float, optional\n        The state transition probabilities for the Hidden Markov Model,\n        default is [[0.2, 0.8], [0, 1]].\n    parameters_emission : list of list of list of float, optional\n        Parameters for Gaussian emission probabilities, where each sublist corresponds\n        to the mean and standard deviation of the Gaussian distributions for a given state,\n        default is [[[0.4, 0.4], [0.8, 0.2]], [[0.8, 0.3], [0.4, 0.2]]].\n    \"\"\"\n    st_tree = read_pointcloudgraph_into_treex(pointcloudgraph=minimum_spanning_tree)\n    rt = root\n    t = build_spanning_tree(st_tree, rt, list_att=observation_list_import)\n    create_observation_list(t, list_obs=observation_list_import)\n    #########################################################################\n    initial_distribution = initial_distribution\n    # initial_distribution = [1, 0, 0]\n    transition_matrix = transition_matrix\n    # transition_matrix = [[0.2, 0, 0.8], [0, 0.8, 0.2], [0, 0.8, 0.2]]\n    # transition_matrix = [[0, 0, 1], [0, 0, 0], [0, 1, 0]]\n    # insertion bruit\n    # transition_matrix = [[0.2, 0.7, 0.1], [0, 0.9, 0.1], [0.3, 0.3, 0.4]]\n    continuous_obs = True\n\n    if continuous_obs:  # observations are Gaussian\n        parameterstot = parameters_emission\n\n        def gen_emission(k, parameters):  # Gaussian emission\n            return random.gauss(parameters[k][0], parameters[k][1])\n\n        def pdf_emission_dim1(x, moy, sd):  # Gaussian emission\n            return 1.0 / (sd * math.sqrt(2 * math.pi)) * math.exp(\n                -1.0 / (2 * sd ** 2) * (x - moy) ** 2)\n\n        def pdf_emission_dimn(x, k, parameterstot):\n            p = 1\n            if len(parameterstot) == 1:\n                p = pdf_emission_dim1(x, moy=parameterstot[0][k][0], sd=parameterstot[0][k][1])\n                return p\n            else:\n                for i in range(len(parameterstot[0])):\n                    p *= pdf_emission_dim1(x[i], moy=parameterstot[k][i][0], sd=parameterstot[k][i][1])\n                return p\n\n    viterbi(t, 'observations', initial_distribution, transition_matrix, pdf_emission_dimn, parameterstot)\n\n    add_viterbi_results_to_quotient_graph(minimum_spanning_tree, t, list_semantics=['leaf', 'stem', 'NSP'])\n    add_viterbi_results_to_quotient_graph(quotient_graph, t, list_semantics=['leaf', 'stem', 'NSP'])\n    # display_and_export_quotient_graph_matplotlib(quotient_graph=QG_t, node_sizes=20, filename=\"quotient_graph_observation\", data_on_nodes='observations', data=True, attributekmeans4clusters = False)\n    display_and_export_quotient_graph_matplotlib(qg=minimum_spanning_tree, node_sizes=20,\n                                                 name=\"quotient_graph_viterbi\", data_on_nodes='viterbi_class',\n                                                 data=True, attributekmeans4clusters=False)\n    export_quotient_graph_attribute_on_point_cloud(quotient_graph, attribute='viterbi_class')\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/","title":"branching_graph","text":""},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.BranchingGraph","title":"BranchingGraph","text":"<pre><code>BranchingGraph(stem_size=100)\n</code></pre> <p>               Bases: <code>Graph</code></p> <p>A graph structure that allows adding branches to a main stem.</p> <p>The resulting graph is formed by chains of nodes linked together at branching points. This structure enables the modeling of hierarchical systems or trees, where each branch is classified by an order relative to the main stem.</p> <p>Attributes:</p> <ul> <li> <code>node_coords</code>               (<code>ndarray</code>)           \u2013            <p>A matrix of coordinates for each node in the graph. Used for visualization or spatial representation.</p> </li> <li> <code>branch_nodes</code>               (<code>dict</code>)           \u2013            <p>A dictionary where keys are branch IDs and values are lists of node IDs in that branch.</p> </li> <li> <code>branch_linking_node</code>               (<code>dict</code>)           \u2013            <p>A dictionary where keys are branch IDs and values are the node IDs to which the branch is connected (linking point).</p> </li> <li> <code>branch_order</code>               (<code>dict</code>)           \u2013            <p>A dictionary where keys are branch IDs and values are the order of each branch (relative to the main stem).</p> </li> <li> <code>keigenvec</code>               (<code>ndarray or None</code>)           \u2013            <p>Eigenvector matrix computed from the graph Laplacian. Used for spectral graph analysis.</p> </li> <li> <code>keigenval</code>               (<code>ndarray or None</code>)           \u2013            <p>Eigenvalues corresponding to the graph Laplacian. Used for spectral graph analysis.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from spectral_clustering.branching_graph import BranchingGraph\n&gt;&gt;&gt; # Create a main stem with 10 nodes\n&gt;&gt;&gt; graph = BranchingGraph(stem_size=100)\n&gt;&gt;&gt; linking_nodes = [32, 63, 40, 47, 50, 55, 62, 63, 70]\n&gt;&gt;&gt; # Add a branch of size 5 to node 4\n&gt;&gt;&gt; [graph.add_branch(branch_size=5, linking_node=ln) for ln in linking_nodes]\n&gt;&gt;&gt; # Compute eigenvectors for the graph Laplacian\n&gt;&gt;&gt; graph.compute_graph_eigenvectors()\n&gt;&gt;&gt; print(graph.keigenvec)\n&gt;&gt;&gt; # Export graph eigenvectors as a point cloud\n&gt;&gt;&gt; graph.export_eigenvectors_on_pointcloud(path=\"./eigenvectors\", k=3)\n</code></pre> Notes <ul> <li>This class subclasses <code>networkx.Graph</code> and extends its functionality for hierarchical branching systems.</li> <li>Visualization libraries like matplotlib can be used to plot the graph or the point clouds saved.</li> </ul> <p>Initialize the graph with a main stem.</p> <p>The graph is created with a single stem of length <code>stem_size</code>.</p> <p>Parameters:</p> <ul> <li> <code>stem_size</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The number of nodes of the main stem.</p> </li> </ul> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def __init__(self, stem_size=100):\n    \"\"\"Initialize the graph with a main stem.\n\n    The graph is created with a single stem of length `stem_size`.\n\n    Parameters\n    ----------\n    stem_size : int\n        The number of nodes of the main stem.\n    \"\"\"\n    super().__init__(self)\n\n    self.node_coords = None\n    self.branch_nodes = {}\n    self.branch_linking_node = {}\n    self.branch_order = {}\n\n    self.keigenvec = None\n    self.keigenval = None\n\n    self.init_main_stem(stem_size)\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.BranchingGraph.add_branch","title":"add_branch","text":"<pre><code>add_branch(branch_size, linking_node, y_orientation=1, x_offset=0)\n</code></pre> <p>Create a branch and add it to the graph.</p> <p>Parameters:</p> <ul> <li> <code>branch_size</code>               (<code>int</code>)           \u2013            <p>The number of nodes in the branch.</p> </li> <li> <code>linking_node</code>               (<code>int</code>)           \u2013            <p>The node on which to attach the branch.</p> </li> <li> <code>y_orientation</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Whether to go left or right on the Y axis (-1 or 1).</p> </li> <li> <code>x_offset</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>The offset on the X axis.</p> </li> </ul> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def add_branch(self, branch_size, linking_node, y_orientation=1, x_offset=0):\n    \"\"\"Create a branch and add it to the graph.\n\n    Parameters\n    ----------\n    branch_size : int\n        The number of nodes in the branch.\n    linking_node : int\n        The node on which to attach the branch.\n    y_orientation : int, optional\n        Whether to go left or right on the Y axis (-1 or 1).\n    x_offset : float, optional\n        The offset on the X axis.\n    \"\"\"\n    # Cr\u00e9ation de la branche et ajout dans le graphe\n\n    starting_node = np.max(list(self.nodes)) + 1\n    list_nodes = [starting_node + i for i in range(branch_size)]\n    self.add_nodes_from(list_nodes)\n\n    branch_id = np.max(list(self.branch_nodes.keys())) + 1 if len(self.branch_nodes) &gt; 0 else 0\n    self.branch_nodes[branch_id] = list_nodes\n\n    linking_branch_id = self.nodes[linking_node]['branch_id']\n    linking_branch_order = self.branch_order[linking_branch_id]\n    self.branch_linking_node[branch_id] = linking_node\n    self.branch_order[branch_id] = linking_branch_order + 1\n\n    nx.set_node_attributes(self, dict(zip(list_nodes, [branch_id for _ in list_nodes])), 'branch_id')\n    nx.set_node_attributes(self, dict(zip(list_nodes, [self.branch_order[branch_id] for _ in list_nodes])),\n                           'branch_order')\n\n    list_edge = [(starting_node + i, starting_node + i + 1) for i in range(branch_size - 1)]\n    self.add_edges_from(list_edge)\n\n    # On relie la branche au point d'insertion\n    self.add_edge(linking_node, starting_node)\n    # Ajout de coordonn\u00e9es pour repr\u00e9sentation graphique\n    branch_node_coords = np.array(\n        [[x_offset, y_orientation * (i + 1), self.node_coords[linking_node, 2]] for i in range(branch_size)])\n    # branch_node_coords = branch_node_coords.reshape(branch_size, 3)\n    # print(np.shape(Cbranche))\n    self.node_coords = np.concatenate((self.node_coords, branch_node_coords), axis=0)\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.BranchingGraph.add_eigenvector_value_as_attribute","title":"add_eigenvector_value_as_attribute","text":"<pre><code>add_eigenvector_value_as_attribute(k=2, compute_branch_relative=True)\n</code></pre> <p>Adds eigenvector values as node attributes in the graph and optionally computes branch-relative values for the specified eigenvector.</p> <p>This method first calculates eigenvector values if not already computed and then assigns these values to graph node attributes. Optionally, values can be normalized within individual branches defined by nodes' branch IDs.</p> <p>Parameters:</p> <ul> <li> <code>k</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>Index of the eigenvector to use (1-based index). Defaults to <code>2</code>.</p> </li> <li> <code>compute_branch_relative</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code> (default), branch-relative normalized eigenvector values are computed and added as attributes.</p> </li> </ul> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def add_eigenvector_value_as_attribute(self, k=2, compute_branch_relative=True):\n    \"\"\"Adds eigenvector values as node attributes in the graph and optionally computes\n    branch-relative values for the specified eigenvector.\n\n    This method first calculates eigenvector values if not already computed and then assigns these values to graph\n    node attributes. Optionally, values can be normalized within individual branches defined by nodes' branch IDs.\n\n    Parameters\n    ----------\n    k : int, optional\n        Index of the eigenvector to use (1-based index). Defaults to ``2``.\n    compute_branch_relative : bool, optional\n        If ``True`` (default), branch-relative normalized eigenvector values are computed and added as attributes.\n    \"\"\"\n    if self.keigenvec is None:\n        self.compute_graph_eigenvectors()\n\n    # print(type(keigenvec))\n    # vp2 = dict(enumerate(np.transpose(keigenvec[:,1])))\n    node_eigenvector_values = dict(zip(self.nodes(), np.transpose(self.keigenvec[:, k - 1])))\n    # print(vp2)\n    nx.set_node_attributes(self, node_eigenvector_values, 'eigenvector_' + str(k))\n    # print(G.nodes[1]['valp2'])\n    # nx.write_graphml(G, \"graphetestattributs\")\n\n    if compute_branch_relative:\n        branch_relative_values = {}\n        for i in self.nodes:\n            branch_id = self.nodes[i]['branch_id']\n            branch_nodes = self.branch_nodes[branch_id]\n\n            branch_min_value = np.min([self.nodes[j]['eigenvector_' + str(k)] for j in branch_nodes])\n            branch_max_value = np.max([self.nodes[j]['eigenvector_' + str(k)] for j in branch_nodes])\n            branch_relative_values[i] = (self.nodes[i]['eigenvector_' + str(k)] - branch_min_value) / (\n                        branch_max_value - branch_min_value)\n        nx.set_node_attributes(self, branch_relative_values, 'branch_relative_eigenvector_' + str(k))\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.BranchingGraph.clustering_by_fiedler_and_agglomerative","title":"clustering_by_fiedler_and_agglomerative","text":"<pre><code>clustering_by_fiedler_and_agglomerative(number_of_clusters=2, with_coordinates=False)\n</code></pre> <p>Performs graph clustering using Fiedler vector and agglomerative clustering.</p> <p>This method leverages the Fiedler vector (second smallest eigenvector of the Laplacian matrix) to compute gradients across graph nodes, and then applies agglomerative clustering on the gradient values. Optionally incorporates node coordinates into the clustering process.</p> <p>Parameters:</p> <ul> <li> <code>number_of_clusters</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>The number of clusters to form. Default is 2.</p> </li> <li> <code>with_coordinates</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, the clustering process includes node coordinates as an additional feature. Default is False.</p> </li> </ul> Notes <p>This method assigns two attributes to the graph's nodes: 1. <code>gradient_vp2</code> - The gradient of the Fiedler vector for the respective node. 2. <code>clustering_label</code> - The cluster label assigned to the node after clustering.</p> <p><code>AgglomerativeClustering</code> from scikit-learn is used with the 'ward' linkage and 'euclidean' distance metric. If coordinates are included, the features are scaled using <code>MinMaxScaler</code> before clustering. Connectivity of the graph is incorporated into the clustering process.</p> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def clustering_by_fiedler_and_agglomerative(self, number_of_clusters=2, with_coordinates=False):\n    \"\"\"Performs graph clustering using Fiedler vector and agglomerative clustering.\n\n    This method leverages the Fiedler vector (second smallest eigenvector of the\n    Laplacian matrix) to compute gradients across graph nodes, and then applies\n    agglomerative clustering on the gradient values. Optionally incorporates\n    node coordinates into the clustering process.\n\n    Parameters\n    ----------\n    number_of_clusters : int, optional\n        The number of clusters to form. Default is 2.\n    with_coordinates : bool, optional\n        If True, the clustering process includes node coordinates as an\n        additional feature. Default is False.\n\n    Notes\n    -----\n    This method assigns two attributes to the graph's nodes:\n    1. `gradient_vp2` - The gradient of the Fiedler vector for the respective node.\n    2. `clustering_label` - The cluster label assigned to the node after clustering.\n\n    `AgglomerativeClustering` from scikit-learn is used with the 'ward' linkage\n    and 'euclidean' distance metric. If coordinates are included, the features are\n    scaled using `MinMaxScaler` before clustering. Connectivity of the graph\n    is incorporated into the clustering process.\n    \"\"\"\n    self.compute_graph_eigenvectors()\n    self.add_eigenvector_value_as_attribute(k=2)\n\n    A = nx.adjacency_matrix(self)\n    vp2 = np.asarray(self.keigenvec[:, 1])\n\n    vp2_matrix = np.tile(vp2, (len(self), 1))\n    vp2_matrix[A.todense() == 0] = np.nan\n    vp2grad = (np.nanmax(vp2_matrix, axis=1) - np.nanmin(vp2_matrix, axis=1)) / 2.\n    node_vp2grad_values = dict(zip(self.nodes(), vp2grad))\n    nx.set_node_attributes(self, node_vp2grad_values, 'gradient_vp2')\n\n    if not with_coordinates:\n        X = vp2grad[:, np.newaxis]\n        clustering = skc.AgglomerativeClustering(affinity='euclidean', connectivity=A, linkage='ward',\n                                                 n_clusters=number_of_clusters).fit(X)\n\n    if with_coordinates:\n        X = np.concatenate((self.node_coords, vp2grad[:, np.newaxis]), axis=1)\n        Xscaled = sk.preprocessing.MinMaxScaler().fit_transform(X)\n        clustering = skc.AgglomerativeClustering(affinity='euclidean', connectivity=A, linkage='ward',\n                                                 n_clusters=number_of_clusters).fit(Xscaled)\n\n    node_clustering_label = dict(zip(self.nodes(), np.transpose(clustering.labels_)))\n    nx.set_node_attributes(self, node_clustering_label, 'clustering_label')\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.BranchingGraph.compute_graph_eigenvectors","title":"compute_graph_eigenvectors","text":"<pre><code>compute_graph_eigenvectors(is_sparse=False, k=50)\n</code></pre> <p>Computes the eigenvalues and eigenvectors of the Laplacian matrix of the graph.</p> <p>Parameters:</p> <ul> <li> <code>is_sparse</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Indicates whether to perform the computation in sparse mode. If <code>False</code> (default), all eigenvalues and eigenvectors are calculated in dense mode.</p> </li> <li> <code>k</code>               (<code>int</code>, default:                   <code>50</code> )           \u2013            <p>The number of eigenvalues and eigenvectors to compute in sparse mode, if <code>is_sparse</code> is True. Ignored in dense mode. Default is <code>50</code>.</p> </li> </ul> Notes <p>This function calculates the eigenvalues and eigenvectors of the graph's Laplacian matrix. When <code>is_sparse</code> is set to <code>False</code>, a dense computation is performed using <code>numpy.linalg.eigh</code>, which computes all eigenvalues and eigenvectors. Otherwise, if <code>is_sparse</code> is set to <code>True</code>, the computation utilizes <code>scipy.sparse.linalg.eigsh</code>, which is suitable for large sparse matrices.</p> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def compute_graph_eigenvectors(self, is_sparse=False, k=50):\n    \"\"\"Computes the eigenvalues and eigenvectors of the Laplacian matrix of the graph.\n\n    Parameters\n    ----------\n    is_sparse : bool, optional\n        Indicates whether to perform the computation in sparse mode. If ``False`` (default),\n        all eigenvalues and eigenvectors are calculated in dense mode.\n    k : int, optional\n        The number of eigenvalues and eigenvectors to compute in sparse mode, if `is_sparse`\n        is True. Ignored in dense mode. Default is ``50``.\n\n    Notes\n    -----\n    This function calculates the eigenvalues and eigenvectors of the graph's Laplacian\n    matrix. When `is_sparse` is set to `False`, a dense computation is performed using\n    `numpy.linalg.eigh`, which computes all eigenvalues and eigenvectors. Otherwise,\n    if `is_sparse` is set to `True`, the computation utilizes `scipy.sparse.linalg.eigsh`,\n    which is suitable for large sparse matrices.\n    \"\"\"\n    # Appli Laplacien\n    L = nx.laplacian_matrix(self, weight='weight')\n    L = L.toarray()\n    print(L.shape)\n\n    # if isinstance(L, np.ndarray):\n    if not is_sparse:\n        # Calcul vecteurs propres\n        # Utilisation de eigsh impossible lorsque le graphe est petit.\n        # eigh calcul tous les vecteurs propres.\n        self.keigenval, self.keigenvec = np.linalg.eigh(L)\n    else:\n        self.keigenval, self.keigenvec = spsp.linalg.eigsh(L, k=k, sigma=0, which='LM')\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.BranchingGraph.export_eigenvectors_on_pointcloud","title":"export_eigenvectors_on_pointcloud","text":"<pre><code>export_eigenvectors_on_pointcloud(path='.', k=50)\n</code></pre> <p>Export the eigenvectors of a graph to individual point cloud files.</p> <p>This method selects the first <code>k</code> eigenvectors computed on the graph and exports them as point clouds. The point cloud includes the node coordinates from the graph concatenated with the values of each individual eigenvector. Each eigenvector is saved as a separate TXT file in the specified output directory.</p> <p>Parameters:</p> <ul> <li> <code>path</code>               (<code>str</code>, default:                   <code>'.'</code> )           \u2013            <p>The directory where the output files will be saved. Default is the current working directory (\"./\").</p> </li> <li> <code>k</code>               (<code>int</code>, default:                   <code>50</code> )           \u2013            <p>The number of eigenvectors to export. Default is 50.</p> </li> </ul> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def export_eigenvectors_on_pointcloud(self, path=\".\", k=50):\n    \"\"\"Export the eigenvectors of a graph to individual point cloud files.\n\n    This method selects the first `k` eigenvectors computed on the graph and\n    exports them as point clouds. The point cloud includes the node coordinates\n    from the graph concatenated with the values of each individual eigenvector.\n    Each eigenvector is saved as a separate TXT file in the specified output directory.\n\n    Parameters\n    ----------\n    path : str, optional\n        The directory where the output files will be saved. Default is the\n        current working directory (\"./\").\n    k : int, optional\n        The number of eigenvectors to export. Default is 50.\n\n    \"\"\"\n    if self.keigenvec is None:\n        self.compute_graph_eigenvectors()\n\n    keigenvec = np.asarray(self.keigenvec[:, :k])\n    # print(np.shape(keigenvec))\n    # print(np.shape(C))\n    # Concat\u00e9nation avec les labels (vecteurs propres)\n    # Faire boucle pour sortir tous les nuages de points associ\u00e9s \u00e0 chaque vecteur propre.\n    for i in range(k):\n        # keigenvecK = keigenvec[:, i].reshape(keigenvec.shape[0], 1)\n        # print(np.shape(keigenvecK))\n        pcdtabclassif = np.concatenate((self.node_coords, keigenvec[:, i][:, np.newaxis]), axis=1)\n        # Sortie de tous les nuages\n        filename = 'testchain' + str(i)\n        print(filename)\n        np.savetxt(path + \"/\" + filename + '.txt', pcdtabclassif, delimiter=\",\")\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.BranchingGraph.init_main_stem","title":"init_main_stem","text":"<pre><code>init_main_stem(stem_size=100)\n</code></pre> <p>Initialize the main stem of the graph, including nodes, edges, and attributes. This function sets up a linear chain (main stem) in the graph with the specified number of nodes.</p> <p>Parameters:</p> <ul> <li> <code>stem_size</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The number of nodes in the main stem.</p> </li> </ul> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def init_main_stem(self, stem_size=100):\n    \"\"\"\n    Initialize the main stem of the graph, including nodes, edges, and attributes.\n    This function sets up a linear chain (main stem) in the graph with the specified number of nodes.\n\n    Parameters\n    ----------\n    stem_size : int\n        The number of nodes in the main stem.\n    \"\"\"\n    # Create a list of node IDs for the main stem\n    list_nodes = [i for i in range(stem_size)]\n    # Add the nodes of the stem to the graph\n    self.add_nodes_from(list_nodes)\n\n    # Determine the branch ID for the main stem\n    # If branch_nodes is non-empty, the new branch ID is the max key + 1, otherwise use 0\n    branch_id = np.max(list(self.branch_nodes.keys())) + 1 if len(self.branch_nodes) &gt; 0 else 0\n    # Assign all nodes of the main stem to the corresponding branch ID\n    self.branch_nodes[branch_id] = list_nodes\n    # Set linking node for the main stem to the first node (node 0)\n    self.branch_linking_node[branch_id] = 0\n    # Set branch order for the main stem to 0 (main stem is the primary chain)\n    self.branch_order[branch_id] = 0\n\n    # Assign the branch ID as a node attribute for all nodes in the main stem\n    nx.set_node_attributes(\n        self, dict(zip(list_nodes, [branch_id for _ in list_nodes])), 'branch_id'\n    )\n    # Assign the branch order as a node attribute for all nodes in the main stem\n    nx.set_node_attributes(\n        self, dict(zip(list_nodes, [self.branch_order[branch_id] for _ in list_nodes])), 'branch_order'\n    )\n\n    # Create a list of edges to form a linear chain by connecting each node to the next\n    list_edge = [(i, i + 1) for i in range(stem_size - 1)]\n    # Add the edges to the graph\n    self.add_edges_from(list_edge)\n    # Create 3D coordinates for the nodes, spaced 1 unit apart along the z-axis\n    # The x and y coordinates are set to 0\n    self.node_coords = np.asarray([[0, 0, i] for i in range(stem_size)])\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.save_eigenval_plot","title":"save_eigenval_plot","text":"<pre><code>save_eigenval_plot(eigenval, filename='ValeursPropres.png')\n</code></pre> <p>Saves a plot of eigenvalues to a file.</p> <p>This function generates a plot of the provided eigenvalues. The eigenvalues will be plotted as blue circles, and the x-axis corresponds to the range of their transposed indices. The size of the plot and layout adjustments are preset before saving the figure to the specified filename.</p> <p>Parameters:</p> <ul> <li> <code>eigenval</code>               (<code>array - like</code>)           \u2013            <p>The eigenvalues to be plotted. Each column in <code>eigenval</code> represents a set of eigenvalues whose transposed indices are used as the x-axis.</p> </li> <li> <code>filename</code>               (<code>str</code>, default:                   <code>'ValeursPropres.png'</code> )           \u2013            <p>The filename of the image file where the plot is saved. Default is \"ValeursPropres.png\".</p> </li> </ul> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def save_eigenval_plot(eigenval, filename=\"ValeursPropres.png\"):\n    \"\"\"Saves a plot of eigenvalues to a file.\n\n    This function generates a plot of the provided eigenvalues. The eigenvalues\n    will be plotted as blue circles, and the x-axis corresponds to the range of\n    their transposed indices. The size of the plot and layout adjustments are\n    preset before saving the figure to the specified filename.\n\n    Parameters\n    ----------\n    eigenval : array-like\n        The eigenvalues to be plotted. Each column in `eigenval` represents a\n        set of eigenvalues whose transposed indices are used as the x-axis.\n    filename : str, optional\n        The filename of the image file where the plot is saved. Default is \"ValeursPropres.png\".\n    \"\"\"\n    figureval = plt.figure(0)\n    figureval.clf()\n    figureval.gca().plot(range(len(np.transpose(eigenval))), np.transpose(eigenval), 'bo')\n    figureval.set_size_inches(20, 10)\n    figureval.subplots_adjust(wspace=0, hspace=0)\n    figureval.tight_layout()\n    figureval.savefig(filename)\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.save_eigenval_plot_G","title":"save_eigenval_plot_G","text":"<pre><code>save_eigenval_plot_G(branching_graph, filename='ValeursPropres.png')\n</code></pre> <p>Save the eigenvalue plot of a graph to a specified file.</p> <p>This function saves a plot of the eigenvalues of the graph associated with <code>branching_graph</code>. If the eigenvalues are not yet computed, it calculates them first. The eigenvalue plot is created using matplotlib and stored in a file with the specified or default filename.</p> <p>Parameters:</p> <ul> <li> <code>branching_graph</code>               (<code>Graph</code>)           \u2013            <p>The graph object whose eigenvalues are to be plotted. It is expected to have an attribute <code>keigenval</code> that contains its eigenvalues and a method <code>compute_graph_eigenvectors()</code> for computing those eigenvalues if necessary.</p> </li> <li> <code>filename</code>               (<code>str</code>, default:                   <code>'ValeursPropres.png'</code> )           \u2013            <p>The name of the file where the eigenvalue plot will be saved. Defaults to \"ValeursPropres.png\".</p> </li> </ul> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def save_eigenval_plot_G(branching_graph, filename=\"ValeursPropres.png\"):\n    \"\"\"Save the eigenvalue plot of a graph to a specified file.\n\n    This function saves a plot of the eigenvalues of the graph associated with\n    `branching_graph`. If the eigenvalues are not yet computed, it calculates them\n    first. The eigenvalue plot is created using matplotlib and stored in a file\n    with the specified or default filename.\n\n    Parameters\n    ----------\n    branching_graph : Graph\n        The graph object whose eigenvalues are to be plotted. It is expected to\n        have an attribute `keigenval` that contains its eigenvalues and a method\n        `compute_graph_eigenvectors()` for computing those eigenvalues if necessary.\n    filename : str, optional\n        The name of the file where the eigenvalue plot will be saved. Defaults to\n        \"ValeursPropres.png\".\n    \"\"\"\n    if branching_graph.keigenval is None:\n        branching_graph.compute_graph_eigenvectors()\n    save_eigenval_plot(branching_graph.keigenval, filename)\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.save_eigenvec_plot","title":"save_eigenvec_plot","text":"<pre><code>save_eigenvec_plot(branching_graph, sort_values=True, filename='eigenvectors.png')\n</code></pre> <p>Generates and saves a plot of eigenvectors from a branching graph.</p> <p>This function processes the eigenvectors of the given branching graph, sorts them based on specified criteria, and creates a subplot visualization of the eigenvectors. The generated plot is then saved to a file.</p> <p>Parameters:</p> <ul> <li> <code>branching_graph</code>               (<code>object</code>)           \u2013            <p>An object representing the branching graph. It is expected to have the attribute <code>keigenvec</code> for precomputed eigenvectors or the method <code>compute_graph_eigenvectors</code> if the eigenvectors need to be computed.</p> </li> <li> <code>sort_values</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>A flag indicating whether eigenvectors should be sorted. By default, it is set to True.</p> </li> <li> <code>filename</code>               (<code>str</code>, default:                   <code>'eigenvectors.png'</code> )           \u2013            <p>The name of the file where the eigenvector plot will be saved. The default value is \"eigenvectors.png\".</p> </li> </ul> Notes <p>The function creates a figure with multiple subplots, where each subplot represents an eigenvector visualized as a 1D line plot. A maximum of 50 eigenvectors is considered and plotted, depending on the size of <code>keigenvec</code>.</p> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def save_eigenvec_plot(branching_graph, sort_values=True, filename=\"eigenvectors.png\"):\n    \"\"\"Generates and saves a plot of eigenvectors from a branching graph.\n\n    This function processes the eigenvectors of the given branching graph,\n    sorts them based on specified criteria, and creates a subplot visualization\n    of the eigenvectors. The generated plot is then saved to a file.\n\n    Parameters\n    ----------\n    branching_graph : object\n        An object representing the branching graph. It is expected to\n        have the attribute `keigenvec` for precomputed eigenvectors\n        or the method `compute_graph_eigenvectors` if the eigenvectors\n        need to be computed.\n    sort_values : bool, optional\n        A flag indicating whether eigenvectors should be sorted. By default,\n        it is set to True.\n    filename : str, optional\n        The name of the file where the eigenvector plot will be saved.\n        The default value is \"eigenvectors.png\".\n\n    Notes\n    -----\n    The function creates a figure with multiple subplots, where each subplot\n    represents an eigenvector visualized as a 1D line plot. A maximum of 50\n    eigenvectors is considered and plotted, depending on the size of `keigenvec`.\n    \"\"\"\n    if branching_graph.keigenvec is None:\n        branching_graph.compute_graph_eigenvectors()\n    figure = plt.figure(0)\n    figure.clf()\n    keigenvec = branching_graph.keigenvec[:, :50]\n    if sort_values:\n        keigenvec = keigenvec[keigenvec[:, 1].argsort()]\n    for i_vec, vec in enumerate(np.transpose(np.around(keigenvec, 10))):\n        figure.add_subplot(5, 10, i_vec + 1)\n        figure.gca().set_title(\"Eigenvector \" + str(i_vec + 1))\n        figure.gca().plot(range(len(vec)), vec, color='blue')\n    figure.set_size_inches(20, 10)\n    figure.subplots_adjust(wspace=0, hspace=0)\n    figure.tight_layout()\n    figure.savefig(filename)\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.save_eigenvector_value_along_stem_plot","title":"save_eigenvector_value_along_stem_plot","text":"<pre><code>save_eigenvector_value_along_stem_plot(branching_graph, k=2, filename='eigenvector_along_stem.png')\n</code></pre> <p>Save the plot of eigenvector values along the stem of a branching graph.</p> <p>This function visualizes the eigenvector values along the stem for different branches of a branching graph. It creates a plot where nodes of branches are distributed according to their positions along the x-axis, and their corresponding eigenvector values are displayed on the y-axis. Branches are colored based on their order, and zero-crossing points (nodes where eigenvector values cross zero) are highlighted.</p> <p>Parameters:</p> <ul> <li> <code>branching_graph</code>               (<code>object</code>)           \u2013            <p>The branching graph structure containing nodes and branches. It must provide the following attributes: - <code>nodes</code>: A dictionary-like structure where node data can be accessed and modified. - <code>branch_order</code>: A dictionary mapping branch IDs to their respective branch order. - <code>branch_linking_node</code>: A dictionary defining the linking nodes for each branch. - <code>branch_nodes</code>: A dictionary mapping branch IDs to their respective nodes.</p> <p>Additionally, the graph must support the method <code>add_eigenvector_value_as_attribute(k)</code>, which adds the eigenvector values as attributes to each node.</p> </li> <li> <code>k</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>The eigenvector index to be used for plotting. Defaults to 2.</p> </li> <li> <code>filename</code>               (<code>str</code>, default:                   <code>'eigenvector_along_stem.png'</code> )           \u2013            <p>The name of the file to save the generated plot. Defaults to \"eigenvector_along_stem.png\".</p> </li> </ul> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def save_eigenvector_value_along_stem_plot(branching_graph, k=2, filename=\"eigenvector_along_stem.png\"):\n    \"\"\"\n    Save the plot of eigenvector values along the stem of a branching graph.\n\n    This function visualizes the eigenvector values along the stem for different\n    branches of a branching graph. It creates a plot where nodes of branches are\n    distributed according to their positions along the x-axis, and their corresponding\n    eigenvector values are displayed on the y-axis. Branches are colored based on their\n    order, and zero-crossing points (nodes where eigenvector values cross zero) are\n    highlighted.\n\n    Parameters\n    ----------\n    branching_graph : object\n        The branching graph structure containing nodes and branches. It must provide the\n        following attributes:\n        - `nodes`: A dictionary-like structure where node data can be accessed and modified.\n        - `branch_order`: A dictionary mapping branch IDs to their respective branch order.\n        - `branch_linking_node`: A dictionary defining the linking nodes for each branch.\n        - `branch_nodes`: A dictionary mapping branch IDs to their respective nodes.\n\n        Additionally, the graph must support the method `add_eigenvector_value_as_attribute(k)`,\n        which adds the eigenvector values as attributes to each node.\n\n    k : int, optional\n        The eigenvector index to be used for plotting. Defaults to 2.\n\n    filename : str, optional\n        The name of the file to save the generated plot. Defaults to \"eigenvector_along_stem.png\".\n    \"\"\"\n    if not 'eigenvector_' + str(k) in branching_graph.nodes[0]:\n        branching_graph.add_eigenvector_value_as_attribute(k)\n\n    figure = plt.figure(0)\n    figure.clf()\n\n    order_colors = {0: 'darkred', 1: 'darkgoldenrod', 2: 'chartreuse', 3: 'darkcyan'}\n\n    node_x = {}\n    for branch_id in np.sort(list(branching_graph.branch_order.keys())):\n        link = branching_graph.branch_linking_node[branch_id]\n        link_x = node_x[link] if link in node_x else 0\n        branch_node_x = [link_x + 1 + (i - np.min(branching_graph.branch_nodes[branch_id])) for i in\n                         branching_graph.branch_nodes[branch_id]]\n        node_x.update(dict(zip(branching_graph.branch_nodes[branch_id], branch_node_x)))\n\n        branch_node_y = [branching_graph.nodes[i]['eigenvector_' + str(k)] for i in\n                         branching_graph.branch_nodes[branch_id]]\n\n        zero_nodes = np.array(branching_graph.branch_nodes[branch_id])[:-1][\n            np.array(branch_node_y)[:-1] * np.array(branch_node_y)[1:] &lt; 0]\n\n        for i in zero_nodes:\n            figure.gca().scatter(np.mean(branch_node_x[i:i + 2]), np.mean(branch_node_y[i:i + 2]), color='k')\n\n        branch_order = branching_graph.branch_order[branch_id]\n        figure.gca().plot(branch_node_x, branch_node_y, color=order_colors[branch_order])\n\n    figure.set_size_inches(20, 10)\n    figure.subplots_adjust(wspace=0, hspace=0)\n    figure.tight_layout()\n    figure.savefig(filename)\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.save_graph_plot","title":"save_graph_plot","text":"<pre><code>save_graph_plot(branching_graph, attribute_names=[None], colormap='jet', node_size=10, attribute_as_size=False, plot_zeros=True, filename='graph.png')\n</code></pre> <p>Generates and saves a plot of a graph with customizable node attributes and layout.</p> <p>The function creates a visualization of the input graph with options to customize node colors based on attributes, specify node sizes, and include zero crossings in attribute plots. The generated graph layout is derived using the Kamada-Kawai method. Plots can be saved to a specified filename.</p> <p>Parameters:</p> <ul> <li> <code>branching_graph</code>               (<code>Graph</code>)           \u2013            <p>The graph to be plotted. Each node may have attributes to be visualized.</p> </li> <li> <code>attribute_names</code>               (<code>list of str or None</code>, default:                   <code>[None]</code> )           \u2013            <p>List of node attribute names to visualize. If None or an attribute name is not found in a node, default coloring is applied. Defaults to [None].</p> </li> <li> <code>colormap</code>               (<code>str</code>, default:                   <code>'jet'</code> )           \u2013            <p>The name of the matplotlib colormap to use for coloring the nodes. Defaults to 'jet'.</p> </li> <li> <code>node_size</code>               (<code>int or float</code>, default:                   <code>10</code> )           \u2013            <p>The default size of the nodes in the plot. Actual sizes may vary depending on <code>attribute_as_size</code>. Defaults to 10.</p> </li> <li> <code>attribute_as_size</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, scales node sizes based on the absolute values of the provided attribute. Otherwise, uses <code>node_size</code> for all nodes. Defaults to False.</p> </li> <li> <code>plot_zeros</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True and the attribute name starts with 'eigenvector_', plots scatter points at the location of zero crossings on edges. Defaults to True.</p> </li> <li> <code>filename</code>               (<code>str</code>, default:                   <code>'graph.png'</code> )           \u2013            <p>File path or name where the plotted graph will be saved as an image. Defaults to 'graph.png'.</p> </li> </ul> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def save_graph_plot(branching_graph, attribute_names=[None], colormap='jet', node_size=10, attribute_as_size=False,\n                    plot_zeros=True, filename=\"graph.png\"):\n    \"\"\"Generates and saves a plot of a graph with customizable node attributes and layout.\n\n    The function creates a visualization of the input graph with options to customize\n    node colors based on attributes, specify node sizes, and include zero crossings in\n    attribute plots. The generated graph layout is derived using the Kamada-Kawai method.\n    Plots can be saved to a specified filename.\n\n    Parameters\n    ----------\n    branching_graph : networkx.Graph\n        The graph to be plotted. Each node may have attributes to be visualized.\n    attribute_names : list of str or None, optional\n        List of node attribute names to visualize. If None or an attribute name is not\n        found in a node, default coloring is applied. Defaults to [None].\n    colormap : str, optional\n        The name of the matplotlib colormap to use for coloring the nodes. Defaults to 'jet'.\n    node_size : int or float, optional\n        The default size of the nodes in the plot. Actual sizes may vary depending on\n        `attribute_as_size`. Defaults to 10.\n    attribute_as_size : bool, optional\n        If True, scales node sizes based on the absolute values of the provided attribute.\n        Otherwise, uses `node_size` for all nodes. Defaults to False.\n    plot_zeros : bool, optional\n        If True and the attribute name starts with 'eigenvector_', plots scatter\n        points at the location of zero crossings on edges. Defaults to True.\n    filename : str, optional\n        File path or name where the plotted graph will be saved as an image. Defaults to 'graph.png'.\n\n    \"\"\"\n    figure = plt.figure(0)\n    figure.clf()\n\n    graph_layout = nx.kamada_kawai_layout(branching_graph)\n\n    for i_a, attribute_name in enumerate(attribute_names):\n\n        figure.add_subplot(1, len(attribute_names), i_a + 1)\n\n        if attribute_name is None or attribute_name not in branching_graph.nodes[0]:\n            node_color = [0 for _ in branching_graph.nodes()]\n            node_sizes = node_size\n        else:\n            node_color = [branching_graph.nodes[i][attribute_name] for i in branching_graph.nodes()]\n            if attribute_as_size:\n                node_sizes = [node_size * (np.abs(branching_graph.nodes[i][attribute_name]) / np.max(\n                    [np.abs(branching_graph.nodes[j][attribute_name]) for j in branching_graph.nodes()])) for i in\n                              branching_graph.nodes()]\n            else:\n                node_sizes = node_size\n\n        nx.drawing.nx_pylab.draw_networkx(branching_graph,\n                                          ax=figure.gca(),\n                                          pos=graph_layout,\n                                          with_labels=False,\n                                          node_size=node_sizes,\n                                          node_color=node_color,\n                                          cmap=plt.get_cmap(colormap))\n\n        if attribute_name.startswith('eigenvector_') and plot_zeros:\n            zero_edges = np.array(branching_graph.edges())[np.prod(\n                [[branching_graph.nodes[i][attribute_name] for i in e] for e in np.array(branching_graph.edges)],\n                axis=1) &lt; 0]\n\n            for e in zero_edges:\n                edge_points = np.array([graph_layout[i] for i in e])\n                figure.gca().scatter(np.mean(edge_points[:, 0]), np.mean(edge_points[:, 1]), color='k')\n\n        figure.gca().set_title(attribute_name, size=24)\n\n    figure.set_size_inches(10 * len(attribute_names), 10)\n    figure.subplots_adjust(wspace=0, hspace=0)\n    figure.tight_layout()\n    figure.savefig(filename)\n</code></pre>"},{"location":"reference/spectral_clustering/branching_graph/#spectral_clustering.branching_graph.save_single_eigenvec_plot","title":"save_single_eigenvec_plot","text":"<pre><code>save_single_eigenvec_plot(branching_graph, k=2, sort_values=True, filename=None)\n</code></pre> <p>Generates and saves a plot for a specified eigenvector of a branching graph.</p> <p>This function visualizes a specified eigenvector of the given branching graph. Eigenvectors are useful for understanding structural or spectral properties of the graph. The function provides an option to sort the eigenvector values to potentially reveal relationships among graph nodes. The resulting plot is color-coded based on the branch IDs of the graph nodes and is saved to a specified or default file.</p> <p>Parameters:</p> <ul> <li> <code>branching_graph</code>               (<code>object</code>)           \u2013            <p>An object representing the branching graph that includes eigenvector data and branch ID information in the node attributes. The object must have a <code>keigenvec</code> property (or compute it through its functionality).</p> </li> <li> <code>k</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>The index of the eigenvector to be plotted (indexed from 1), by default 2.</p> </li> <li> <code>sort_values</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to sort the eigenvector values and associated node branches, by default True.</p> </li> <li> <code>filename</code>               (<code>str or None</code>, default:                   <code>None</code> )           \u2013            <p>The destination filename for saving the plot. If None, a default filename <code>eigenvector_k.png</code> is used, where <code>k</code> is the specified eigenvector index.</p> </li> </ul> Source code in <code>spectral_clustering/branching_graph.py</code> <pre><code>def save_single_eigenvec_plot(branching_graph, k=2, sort_values=True, filename=None):\n    \"\"\"Generates and saves a plot for a specified eigenvector of a branching graph.\n\n    This function visualizes a specified eigenvector of the given branching graph.\n    Eigenvectors are useful for understanding structural or spectral properties\n    of the graph. The function provides an option to sort the eigenvector values\n    to potentially reveal relationships among graph nodes. The resulting plot\n    is color-coded based on the branch IDs of the graph nodes and is saved to\n    a specified or default file.\n\n    Parameters\n    ----------\n    branching_graph : object\n        An object representing the branching graph that includes eigenvector\n        data and branch ID information in the node attributes. The object must\n        have a `keigenvec` property (or compute it through its functionality).\n    k : int, optional\n        The index of the eigenvector to be plotted (indexed from 1), by default 2.\n    sort_values : bool, optional\n        Whether to sort the eigenvector values and associated node branches, by\n        default True.\n    filename : str or None, optional\n        The destination filename for saving the plot. If None, a default\n        filename `eigenvector_k.png` is used, where `k` is the specified\n        eigenvector index.\n    \"\"\"\n    if branching_graph.keigenvec is None:\n        branching_graph.compute_graph_eigenvectors()\n    figure = plt.figure(0)\n    figure.clf()\n    vec = branching_graph.keigenvec[:, k - 1]\n    branches = np.array([branching_graph.nodes[i]['branch_id'] for i in branching_graph.nodes])\n    if sort_values:\n        vec = vec[branching_graph.keigenvec[:, 1].argsort()]\n        branches = branches[branching_graph.keigenvec[:, 1].argsort()]\n    figure.gca().set_title(\"Eigenvector \" + str(k))\n    # figure.gca().plot(range(len(vec)),vec,color='blue')\n    figure.gca().scatter(range(len(vec)), vec, c=branches, cmap='jet')\n    figure.set_size_inches(10, 10)\n    figure.subplots_adjust(wspace=0, hspace=0)\n    figure.tight_layout()\n    if filename is None:\n        filename = \"eigenvector_\" + str(k) + \".png\"\n    figure.savefig(filename)\n</code></pre>"},{"location":"reference/spectral_clustering/constraint_program/","title":"constraint_program","text":""},{"location":"reference/spectral_clustering/dijkstra_segmentation/","title":"dijkstra_segmentation","text":""},{"location":"reference/spectral_clustering/dijkstra_segmentation/#spectral_clustering.dijkstra_segmentation.actugraph","title":"actugraph","text":"<pre><code>actugraph(G)\n</code></pre> <p>Calculates the weight of graph edges based on the commute-time distance using eigenvalues and eigenvectors of the graph Laplacian matrix.</p> <p>This function computes the Laplacian matrix of the graph, calculates its eigenvalues and eigenvectors, and updates the weights of the edges in the graph using the commute-time distance. The commute-time distance is derived from the eigenvectors and eigenvalues of the Laplacian matrix.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>The input graph on which computations will be performed. The graph can have weighted or unweighted edges, and it will be updated with new weights based on the computed commute-time distances.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Graph</code>           \u2013            <p>A modified version of the input graph with updated edge weights. Each edge weight represents the commute-time distance between its endpoints.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>TypeError</code>             \u2013            <p>If the input <code>G</code> is not a <code>networkx.Graph</code>.</p> </li> </ul> Source code in <code>spectral_clustering/dijkstra_segmentation.py</code> <pre><code>def actugraph(G):\n    \"\"\"\n    Calculates the weight of graph edges based on the commute-time distance using eigenvalues\n    and eigenvectors of the graph Laplacian matrix.\n\n    This function computes the Laplacian matrix of the graph, calculates its eigenvalues\n    and eigenvectors, and updates the weights of the edges in the graph using the\n    commute-time distance. The commute-time distance is derived from the eigenvectors\n    and eigenvalues of the Laplacian matrix.\n\n    Parameters\n    ----------\n    G : networkx.Graph\n        The input graph on which computations will be performed.\n        The graph can have weighted or unweighted edges, and it will be updated\n        with new weights based on the computed commute-time distances.\n\n    Returns\n    -------\n    networkx.Graph\n        A modified version of the input graph with updated edge weights. Each edge\n        weight represents the commute-time distance between its endpoints.\n\n    Raises\n    ------\n    TypeError\n        If the input `G` is not a `networkx.Graph`.\n    \"\"\"\n    Lcsr = nx.laplacian_matrix(G, weight='weight')\n    Lcsr = spsp.csr_matrix.asfptype(Lcsr)\n    # k nombre de vecteurs propres que l'on veut calculer\n    k = 20\n    keigenval, keigenvec = spsp.linalg.eigsh(Lcsr, k=k, sigma=0, which='LM')\n    eigenval = keigenval.reshape(keigenval.shape[0], 1)\n    # Actualisation du graphe pour obtenir les poids en fonction de la commute-time distance\n    arcs = G.edges\n    arcs = iter(arcs)\n    arcs = tuple(arcs)\n    nbe_arcs = G.number_of_edges()\n    for t in range(nbe_arcs):\n        pt1 = arcs[t][0]\n        pt2 = arcs[t][1]\n        Somme = 0\n        for j in range(1, k):\n            Somme = Somme + (pow(keigenvec[pt1, j] - keigenvec[pt2, j], 2) / eigenval[j])\n        CommuteDist = np.sqrt(Somme)\n        G[pt1][pt2]['weight'] = CommuteDist\n    return G\n</code></pre>"},{"location":"reference/spectral_clustering/dijkstra_segmentation/#spectral_clustering.dijkstra_segmentation.affichesegm","title":"affichesegm","text":"<pre><code>affichesegm(pcd, segmentdict, c)\n</code></pre> <p>Visualizes intermediate results, specifically line segments.</p> <p>This function builds a graph representation of the segments and visualizes the graph along with the original point cloud.</p> <p>Parameters:</p> <ul> <li> <code>pcd</code>               (<code>PointCloud</code>)           \u2013            <p>The input point cloud to which the segments belong.</p> </li> <li> <code>segmentdict</code>               (<code>dict</code>)           \u2013            <p>A dictionary where keys are segment indices and values are lists of indices representing the line segments in the graph.</p> </li> <li> <code>c</code>               (<code>int</code>)           \u2013            <p>The number of distinct segments in the graph.</p> </li> </ul> Notes <p>This function uses Open3D to render point clouds and geometry and uses NetworkX to build the graph based on the segment information. Line segments are visualized along with the point cloud based on the provided input.</p> Source code in <code>spectral_clustering/dijkstra_segmentation.py</code> <pre><code>def affichesegm(pcd, segmentdict, c):\n    \"\"\"Visualizes intermediate results, specifically line segments.\n\n    This function builds a graph representation of the segments and visualizes the graph\n    along with the original point cloud.\n\n    Parameters\n    ----------\n    pcd : o3d.geometry.PointCloud\n        The input point cloud to which the segments belong.\n    segmentdict : dict\n        A dictionary where keys are segment indices and values are lists of\n        indices representing the line segments in the graph.\n    c : int\n        The number of distinct segments in the graph.\n\n    Notes\n    -----\n    This function uses Open3D to render point clouds and geometry and uses\n    NetworkX to build the graph based on the segment information. Line segments\n    are visualized along with the point cloud based on the provided input.\n    \"\"\"\n    # affichage du r\u00e9sultat interm\u00e9diaire, c'est-\u00e0-dire des segments.\n    Gaffichage = nx.Graph()\n    pts = np.array(pcd.points)\n    N = len(pcd.points)\n    for i in range(N):\n        Gaffichage.add_node(i, pos=pts[i])\n    for i in range(1, c):\n        nx.add_path(Gaffichage, segmentdict[i])\n    edgelist = Gaffichage.edges\n    print(Gaffichage.edges)\n    cloption = o3d.visualization.RenderOption()\n    graph = o3d.geometry.LineSet()\n    graph.points = o3d.utility.Vector3dVector(pts)\n    graph.lines = o3d.utility.Vector2iVector(edgelist)\n    o3d.visualization.draw_geometries([graph, pcd])\n</code></pre>"},{"location":"reference/spectral_clustering/dijkstra_segmentation/#spectral_clustering.dijkstra_segmentation.densiftige","title":"densiftige","text":"<pre><code>densiftige(G, segmsource, ptsource, ptarrivee, pathsupp=5)\n</code></pre> <p>Densifies a segment of the given graph by adding alternate shorter paths between the source and target nodes.</p> <p>This method focuses on minimizing the error of misclassifying points belonging to the segment as those in branches, potentially reducing inconsistencies in the graph representation.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>The input graph representing the network structure.</p> </li> <li> <code>segmsource</code>               (<code>list</code>)           \u2013            <p>The main segment to be densified, represented as a list of nodes forming the segment in the graph.</p> </li> <li> <code>ptsource</code>               (<code>any</code>)           \u2013            <p>The starting node for the segment in the graph.</p> </li> <li> <code>ptarrivee</code>               (<code>any</code>)           \u2013            <p>The target node for the segment in the graph.</p> </li> <li> <code>pathsupp</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>The number of additional shorter paths to compute and densify the segment with, by default 5.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>The updated segment with added shorter paths forming a densified structure.</p> </li> </ul> Source code in <code>spectral_clustering/dijkstra_segmentation.py</code> <pre><code>def densiftige(G, segmsource, ptsource, ptarrivee, pathsupp=5):\n    \"\"\"Densifies a segment of the given graph by adding alternate shorter paths between the source and target nodes.\n\n    This method focuses on minimizing the error of misclassifying points belonging to the segment as those in branches,\n    potentially reducing inconsistencies in the graph representation.\n\n    Parameters\n    ----------\n    G : networkx.Graph\n        The input graph representing the network structure.\n    segmsource : list\n        The main segment to be densified, represented as a list of nodes forming\n        the segment in the graph.\n    ptsource : any\n        The starting node for the segment in the graph.\n    ptarrivee : any\n        The target node for the segment in the graph.\n    pathsupp : int, optional\n        The number of additional shorter paths to compute and densify the segment\n        with, by default 5.\n\n    Returns\n    -------\n    list\n        The updated segment with added shorter paths forming a densified structure.\n    \"\"\"\n    # L'objectif ici est de densifier le segment 1, de la tige en ajoutant d'autres plus courts chemins dans cette tige.\n    # L'erreur du nombre de points consid\u00e9r\u00e9s en branches alors qu'ils sont dans la tige devrait \u00eatre diminu\u00e9e.\n    # Il faudra peut-\u00eatre consid\u00e9rer le m\u00eame processus pour les branches, \u00e0 voir.\n    i = 1\n    Gdel = G.__class__()\n    Gdel.add_nodes_from(G)\n    Gdel.add_edges_from(G.edges)\n\n    Gdel.remove_nodes_from(segmsource[1:len(segmsource) - 1])\n    while i &lt; pathsupp:\n        segmsupp = nx.dijkstra_path(Gdel, ptsource, ptarrivee, weight='weight')\n        segmsource = segmsource + segmsupp[1:len(segmsupp) - 1]\n        print(segmsupp)\n        print(ptarrivee)\n        print(ptsource)\n        Gdel.remove_nodes_from(segmsupp[1:len(segmsupp) - 1])\n        i = i + 1\n        print(i)\n    return segmsource\n</code></pre>"},{"location":"reference/spectral_clustering/dijkstra_segmentation/#spectral_clustering.dijkstra_segmentation.initdijkstra","title":"initdijkstra","text":"<pre><code>initdijkstra(G)\n</code></pre> <p>Initializes the first segment of the graph using Dijkstra's algorithm.</p> <p>This function randomly selects a starting node from the graph, computes the shortest path distances from the selected node to all other nodes, and determines the farthest endpoint based on these distances. It then repeats the process starting from the farthest endpoint to determine another distant endpoint. Finally, it computes the shortest path between the two farthest endpoints and returns the path along with the source and destination nodes.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>A graph representation, where nodes are connected by weighted edges.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>The shortest path (as a sequence of nodes) between the final source and destination nodes with maximum distance calculated using Dijkstra's algorithm.</p> </li> <li> <code>int or str</code>           \u2013            <p>The node corresponding to the starting point (farthest from the randomly chosen node initially).</p> </li> <li> <code>int or str</code>           \u2013            <p>The node corresponding to the endpoint (farthest from the source node).</p> </li> </ul> Source code in <code>spectral_clustering/dijkstra_segmentation.py</code> <pre><code>def initdijkstra(G):\n    \"\"\"Initializes the first segment of the graph using Dijkstra's algorithm.\n\n    This function randomly selects a starting node from the graph, computes the shortest path\n    distances from the selected node to all other nodes, and determines the farthest endpoint\n    based on these distances. It then repeats the process starting from the farthest endpoint\n    to determine another distant endpoint. Finally, it computes the shortest path between the\n    two farthest endpoints and returns the path along with the source and destination nodes.\n\n    Parameters\n    ----------\n    G : networkx.Graph\n        A graph representation, where nodes are connected by weighted edges.\n\n    Returns\n    -------\n    list\n        The shortest path (as a sequence of nodes) between the final source and destination\n        nodes with maximum distance calculated using Dijkstra's algorithm.\n    int or str\n        The node corresponding to the starting point (farthest from the randomly chosen node initially).\n    int or str\n        The node corresponding to the endpoint (farthest from the source node).\n    \"\"\"\n    # initialisation du premier segment\n    # Choix d'un point al\u00e9atoire dans le graphe\n    random_node = choice(list(G.nodes))\n    # Stockage de tous les poids des plus courts chemins vers tous les autres points du graphe\n    dict = {}\n    dict = nx.single_source_dijkstra_path_length(G, random_node, weight='weight')\n    # Isolation du point le plus \u00e9loign\u00e9 au point choisi al\u00e9atoirement\n    # S\u00e9lection du point associ\u00e9 au plus long chemin des plus courts chemins\n    ptsource = max(dict.items(), key=operator.itemgetter(1))[0]\n    # Stockage de tous les poids des plus courts chemin entre le pr\u00e9c\u00e9dent point et l'ensemble des points du graphe\n    dict = nx.single_source_dijkstra_path_length(G, ptsource, weight='weight')\n    # Isolation du point le plus \u00e9loign\u00e9\n    ptarrivee = max(dict.items(), key=operator.itemgetter(1))[0]\n    # Obtention du chemin entre le point source et le point d'arriv\u00e9e finaux\n    segmsource = nx.dijkstra_path(G, ptsource, ptarrivee, weight='weight')\n    return segmsource, ptsource, ptarrivee\n</code></pre>"},{"location":"reference/spectral_clustering/dijkstra_segmentation/#spectral_clustering.dijkstra_segmentation.initdijkstralitt","title":"initdijkstralitt","text":"<pre><code>initdijkstralitt(G)\n</code></pre> <p>Initializes the first segment in a graph using Dijkstra's algorithm.</p> <p>This function selects a random node from the graph and computes a segment (based on shortest paths and their lengths) between two nodes. Specifically, it identifies the two most distant nodes from each other in terms of shortest path weights and determines a direct path connecting them.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>A graph represented as a NetworkX graph instance. The graph's edges must have a \"weight\" attribute to compute shortest path weights.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>A list of nodes representing the shortest path (based on edge weights) between two most distant nodes in the graph.</p> </li> </ul> Source code in <code>spectral_clustering/dijkstra_segmentation.py</code> <pre><code>def initdijkstralitt(G):\n    \"\"\"Initializes the first segment in a graph using Dijkstra's algorithm.\n\n    This function selects a random node from the graph and computes a segment\n    (based on shortest paths and their lengths) between two nodes. Specifically,\n    it identifies the two most distant nodes from each other in terms of shortest\n    path weights and determines a direct path connecting them.\n\n    Parameters\n    ----------\n    G : networkx.Graph\n        A graph represented as a NetworkX graph instance. The graph's edges\n        must have a \"weight\" attribute to compute shortest path weights.\n\n    Returns\n    -------\n    list\n        A list of nodes representing the shortest path (based on edge weights)\n        between two most distant nodes in the graph.\n\n    \"\"\"\n    # initialisation du premier segment\n    # Choix d'un point al\u00e9atoire dans le graphe\n    random_node = choice(list(G.nodes))\n    # Stockage de tous les poids des plus courts chemins vers tous les autres points du graphe\n    dict = nx.single_source_dijkstra_path_length(G, random_node, weight='weight')\n    # Isolation du point le plus \u00e9loign\u00e9 au point choisi al\u00e9atoirement\n    # S\u00e9lection du point associ\u00e9 au plus long chemin des plus courts chemins\n    ptsource = max(dict.items(), key=operator.itemgetter(1))[0]\n    # Stockage de tous les poids des plus courts chemin entre le pr\u00e9c\u00e9dent point et l'ensemble des points du graphe\n    dict = nx.single_source_dijkstra_path_length(G, ptsource, weight='weight')\n    # Isolation du point le plus \u00e9loign\u00e9\n    ptarrivee = max(dict.items(), key=operator.itemgetter(1))[0]\n    # Obtention du chemin entre le point source et le point d'arriv\u00e9e finaux\n    segmsource = nx.dijkstra_path(G, ptsource, ptarrivee, weight='weight')\n    return segmsource\n</code></pre>"},{"location":"reference/spectral_clustering/dijkstra_segmentation/#spectral_clustering.dijkstra_segmentation.segmdijkstra","title":"segmdijkstra","text":"<pre><code>segmdijkstra(G, segmsource, prop=0.25)\n</code></pre> <p>Calculates the segmentation of a network graph using an iterative approach based on Dijkstra's algorithm and evaluates the connectivity of graph nodes. The function returns the dictionary of path segments and the count of segments before the stopping condition is met.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>The input graph on which the segmentation is performed. The graph should be weighted, with weights specified via the 'weight' attribute on edges.</p> </li> <li> <code>segmsource</code>               (<code>list</code>)           \u2013            <p>A list specifying the source nodes from which the segmentation paths are initialized.</p> </li> <li> <code>prop</code>               (<code>float</code>, default:                   <code>0.25</code> )           \u2013            <p>A propagation threshold value used to determine the stopping condition of the segmentation process. The default value is 0.25.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>A dictionary where keys are the segment numbers, and values are lists of nodes that form the paths for each segment.</p> </li> <li> <code>int</code>           \u2013            <p>The total number of segments that were created before the stopping condition was satisfied.</p> </li> </ul> Source code in <code>spectral_clustering/dijkstra_segmentation.py</code> <pre><code>def segmdijkstra(G, segmsource, prop=0.25):\n    \"\"\"\n    Calculates the segmentation of a network graph using an iterative approach\n    based on Dijkstra's algorithm and evaluates the connectivity of graph nodes.\n    The function returns the dictionary of path segments and the count of segments\n    before the stopping condition is met.\n\n    Parameters\n    ----------\n    G : networkx.Graph\n        The input graph on which the segmentation is performed. The graph should\n        be weighted, with weights specified via the 'weight' attribute on edges.\n    segmsource : list\n        A list specifying the source nodes from which the segmentation paths\n        are initialized.\n    prop : float, optional\n        A propagation threshold value used to determine the stopping condition\n        of the segmentation process. The default value is 0.25.\n\n    Returns\n    -------\n    dict\n        A dictionary where keys are the segment numbers, and values are lists of nodes that\n        form the paths for each segment.\n    int\n        The total number of segments that were created before the stopping condition was satisfied.\n    \"\"\"\n    # It\u00e9rateur\n    i = 1\n    longueur = True\n    # initialisation dictionnaire de segments/chemins\n    segmentdict = {}\n    segmentdict[i] = segmsource\n    # D\u00e9but boucle permettant de d\u00e9crire l'ensemble du graphe via des chemins sur ce dernier\n    while longueur:\n        chemintot = []\n        # Concat\u00e9nation des chemins pour obtenir une seule liste utilisable par les fonctions nx dijkstra Segment(1..i)\n        for Seg, chemin in segmentdict.items():\n            chemintot = chemintot + chemin\n        # Transformation de la liste obtenue en set\n        setsegments = set(chemintot)\n        # Calcul des chemins les plus courts vers les autres nodes du graphe\n        dict = nx.multi_source_dijkstra_path_length(G, setsegments, weight='weight')\n        # S\u00e9lection du point d'arrivee qui n\u00e9cessite de prendre le chemin le plus lourd en pond\u00e9ration\n        ptarrivee = max(dict.items(), key=operator.itemgetter(1))[0]\n        # Obtention du chemin le plus long. Prise du point source, stockage.\n        length, path = nx.multi_source_dijkstra(G, setsegments, ptarrivee)\n        print(length)\n        if i == 1:\n            ref = length\n        if length &lt; prop * ref:\n            longueur = False\n            c = i\n        else:\n            segmentdict[i + 1] = path\n            p = path[0]\n            # Fin boucle, incr\u00e9mentation i\n            i = i + 1\n    return segmentdict, c\n</code></pre>"},{"location":"reference/spectral_clustering/dijkstra_segmentation/#spectral_clustering.dijkstra_segmentation.segmdijkstralitt","title":"segmdijkstralitt","text":"<pre><code>segmdijkstralitt(G, segmsource, c)\n</code></pre> <p>Compute segmented paths within a graph using Dijkstra's shortest path algorithm.</p> <p>This function iteratively calculates segmented paths within the given graph. At each step, it identifies a new segment based on the longest weighted path from a multi-source Dijkstra's search on the graph, starting from the combined set of nodes in already identified segments. The function also updates and reorganizes existing segments to account for the newly identified segment.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>The graph on which the segmented Dijkstra algorithm will be applied. The graph must have a 'weight' attribute defined for its edges.</p> </li> <li> <code>segmsource</code>               (<code>list</code>)           \u2013            <p>A list of nodes representing the source segment(s) within the graph. Initial segments for the segmentation process.</p> </li> <li> <code>c</code>               (<code>int</code>)           \u2013            <p>The number of iterations to perform, which defines the level of segmentation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>A dictionary where keys are segment ids (integers starting from 1) and values are lists of nodes representing the segments identified at each iteration.</p> </li> </ul> Source code in <code>spectral_clustering/dijkstra_segmentation.py</code> <pre><code>def segmdijkstralitt(G, segmsource, c):\n    \"\"\"Compute segmented paths within a graph using Dijkstra's shortest path algorithm.\n\n    This function iteratively calculates segmented paths within the given graph.\n    At each step, it identifies a new segment based on the longest weighted path\n    from a multi-source Dijkstra's search on the graph, starting from the combined\n    set of nodes in already identified segments. The function also updates and\n    reorganizes existing segments to account for the newly identified segment.\n\n    Parameters\n    ----------\n    G : networkx.Graph\n        The graph on which the segmented Dijkstra algorithm will be applied.\n        The graph must have a 'weight' attribute defined for its edges.\n    segmsource : list\n        A list of nodes representing the source segment(s) within the graph.\n        Initial segments for the segmentation process.\n    c : int\n        The number of iterations to perform, which defines the level of segmentation.\n\n    Returns\n    -------\n    dict\n        A dictionary where keys are segment ids (integers starting from 1) and\n        values are lists of nodes representing the segments identified at each\n        iteration.\n    \"\"\"\n    # It\u00e9rateur\n    i = 1\n    # initialisation dictionnaire de segments/chemins\n    segmentdict = {}\n    segmentdict[i] = segmsource\n    # D\u00e9but boucle permettant de d\u00e9crire l'ensemble du graphe via des chemins sur ce dernier\n    while i &lt; c:\n        chemintot = []\n        # Concat\u00e9nation des chemins pour obtenir une seule liste utilisable par les fonctions nx dijkstra Segment(1..i)\n        for Seg, chemin in segmentdict.items():\n            chemintot = chemintot + chemin\n        # Transformation de la liste obtenue en set\n        setsegments = set(chemintot)\n        # Calcul des chemins les plus courts vers les autres nodes du graphe\n        dict = nx.multi_source_dijkstra_path_length(G, setsegments, weight='weight')\n        # S\u00e9lection du point d'arrivee qui n\u00e9cessite de prendre le chemin le plus lourd en pond\u00e9ration\n        ptarrivee = max(dict.items(), key=operator.itemgetter(1))[0]\n        # Obtention du chemin le plus long. Prise du point source, stockage.\n        length, path = nx.multi_source_dijkstra(G, setsegments, ptarrivee)\n        segmentdict[i + 1] = path\n        p = path[0]\n        # retrouver le segment auquel p appartient\n        j = 1\n        ind = -1\n        while ind == -1 and j &lt;= i:\n            try:\n                ind = segmentdict[j].index(p)\n            except ValueError:\n                ind = -1\n            j = j + 1\n        j = j - 1\n        # Enl\u00e8ve tous les points successifs du Segment[j] de p \u00e0 l'un des bouts et les ajoute au segment[i+2]\n        indexp = segmentdict[j].index(p)\n        segmentdict[i + 2] = segmentdict[j][:indexp]\n        segmentdict[j] = segmentdict[j][indexp:]\n        # Fin boucle, incr\u00e9mentation i\n        i = i + 2\n    return segmentdict\n</code></pre>"},{"location":"reference/spectral_clustering/dijkstra_segmentation/#spectral_clustering.dijkstra_segmentation.sortienuagesegm","title":"sortienuagesegm","text":"<pre><code>sortienuagesegm(pcd, G, segmentdict, c)\n</code></pre> <p>Sorts points in a point cloud based on their shortest paths in a graph, assigns labels to them, and saves the results to a file.</p> <p>The function assigns a classification label to each point in a given point cloud based on the shortest path distances computed from a set of initial segments within a graph. Labels are determined by the segments the points are closest to. If a point cannot be classified, it is assigned a default label <code>c</code>. The resulting labeled point cloud is saved as a text file.</p> <p>Parameters:</p> <ul> <li> <code>pcd</code>               (<code>PointCloud</code>)           \u2013            <p>The input point cloud object, which contains the 3D points to be classified.</p> </li> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>A graph where the shortest paths are computed. Nodes represent points, and edges have weights indicating distances.</p> </li> <li> <code>segmentdict</code>               (<code>dict</code>)           \u2013            <p>A dictionary representing segments. Keys are integers, and values are lists of integers representing node indices in the graph, which define segments considered for classification.</p> </li> <li> <code>c</code>               (<code>int</code>)           \u2013            <p>The default class label assigned to points that cannot be associated with any segment.</p> </li> </ul> Notes <p>The function modifies the point labels by computing the shortest path from a set of segments in the graph to every point in the point cloud. For points that belong to more than one segment, it labels them based on their closest segment sequence in the search process.</p> <p>The labeled point cloud is saved as a comma-separated text file named 'pcdclassifdijkstra3.txt'. The result includes the 3D coordinates of points and their corresponding labels.</p> <p>This function assumes that no duplicate edges with differing weights exist in the graph and that the provided point cloud is valid with a consistent structure.</p> Source code in <code>spectral_clustering/dijkstra_segmentation.py</code> <pre><code>def sortienuagesegm(pcd, G, segmentdict, c):\n    \"\"\"\n    Sorts points in a point cloud based on their shortest paths in a graph,\n    assigns labels to them, and saves the results to a file.\n\n    The function assigns a classification label to each point in a given\n    point cloud based on the shortest path distances computed from a set\n    of initial segments within a graph. Labels are determined by the segments\n    the points are closest to. If a point cannot be classified, it is assigned\n    a default label `c`. The resulting labeled point cloud is saved as a text\n    file.\n\n    Parameters\n    ----------\n    pcd : o3d.geometry.PointCloud\n        The input point cloud object, which contains the 3D points to be classified.\n    G : networkx.Graph\n        A graph where the shortest paths are computed. Nodes represent points, and\n        edges have weights indicating distances.\n    segmentdict : dict\n        A dictionary representing segments. Keys are integers, and values\n        are lists of integers representing node indices in the graph, which\n        define segments considered for classification.\n    c : int\n        The default class label assigned to points that cannot be associated\n        with any segment.\n\n    Notes\n    -----\n    The function modifies the point labels by computing the shortest path from a set\n    of segments in the graph to every point in the point cloud. For points that belong\n    to more than one segment, it labels them based on their closest segment sequence\n    in the search process.\n\n    The labeled point cloud is saved as a comma-separated text file named\n    'pcdclassifdijkstra3.txt'. The result includes the 3D coordinates of points\n    and their corresponding labels.\n\n    This function assumes that no duplicate edges with differing weights exist\n    in the graph and that the provided point cloud is valid with a consistent\n    structure.\n    \"\"\"\n    label = []\n    chemintot = []\n    N = len(pcd.points)\n    for Seg, chemin in segmentdict.items():\n        chemintot = chemintot + chemin\n    # Transformation de la liste obtenue en set\n    setsegments = set(chemintot)\n    length, path = nx.multi_source_dijkstra(G, setsegments, weight='weight')\n    for p in range(N):\n        if p in length:\n            # S\u00e9lection du chemin qui concerne le point d'int\u00e9r\u00eat\n            j = 1\n            ind = -1\n            if length[p] == 0:\n                parrive = p\n            else:\n                parrive = path[p][0]\n            while ind == -1 and j &lt; c:\n                try:\n                    ind = segmentdict[j].index(parrive)\n                except ValueError:\n                    ind = -1\n                j = j + 1\n            j = j - 1\n            label = label + [j]\n        else:\n            label = label + [c]\n\n    label = np.asarray(label)\n    label = np.asarray(label.reshape(np.asarray(pcd.points).shape[0], 1), dtype=np.float64)\n    pcdtabclassif = np.concatenate([np.asarray(pcd.points), label], axis=1)\n    np.savetxt('pcdclassifdijkstra3.txt', pcdtabclassif, delimiter=\",\")\n</code></pre>"},{"location":"reference/spectral_clustering/display_and_export/","title":"display_and_export","text":""},{"location":"reference/spectral_clustering/display_and_export/#spectral_clustering.display_and_export.display_and_export_graph_of_fiedler_vector","title":"display_and_export_graph_of_fiedler_vector","text":"<pre><code>display_and_export_graph_of_fiedler_vector(pcd_g, filename='fiedler_vector.png', sorted_by_fiedler_vector=True)\n</code></pre> <p>Displays and exports a plot of the Fiedler vector.</p> <p>Parameters:</p> <ul> <li> <code>pcd_g</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The graph containing Fiedler vector data.</p> </li> <li> <code>filename</code>               (<code>str or Path</code>, default:                   <code>'fiedler_vector.png'</code> )           \u2013            <p>The file name for saving the output plot.</p> </li> <li> <code>sorted_by_fiedler_vector</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to sort the data by the Fiedler vector values.</p> </li> </ul> Source code in <code>spectral_clustering/display_and_export.py</code> <pre><code>def display_and_export_graph_of_fiedler_vector(pcd_g, filename=\"fiedler_vector.png\", sorted_by_fiedler_vector=True):\n    \"\"\"Displays and exports a plot of the Fiedler vector.\n\n    Parameters\n    ----------\n    pcd_g : spectral_clustering.pointcloudgraph.PointCloudGraph\n        The graph containing Fiedler vector data.\n    filename : str or pathlib.Path, optional\n        The file name for saving the output plot.\n    sorted_by_fiedler_vector : bool, optional\n        Whether to sort the data by the Fiedler vector values.\n    \"\"\"\n    vp2 = pcd_g.keigenvec[:, 1]\n    pcd_vp2 = np.concatenate([pcd_g.nodes_coords, vp2[:, np.newaxis]], axis=1)\n    pcd_vp2_sort_by_vp2 = pcd_vp2[pcd_vp2[:, 3].argsort()]\n    figure = plt.figure(0)\n    figure.clf()\n    figure.gca().set_title(\"fiedler vector\")\n    if sorted_by_fiedler_vector:\n        figure.gca().scatter(range(len(pcd_vp2_sort_by_vp2)), pcd_vp2_sort_by_vp2[:, 3], color='blue')\n    else:\n        figure.gca().scatter(range(len(pcd_vp2)), pcd_vp2[:, 3], color='blue')\n    figure.set_size_inches(10, 10)\n    figure.subplots_adjust(wspace=0, hspace=0)\n    figure.tight_layout()\n    figure.savefig(filename)\n    print(\"Export du vecteur propre 2\")\n</code></pre>"},{"location":"reference/spectral_clustering/display_and_export/#spectral_clustering.display_and_export.display_and_export_graph_of_gradient_of_fiedler_vector","title":"display_and_export_graph_of_gradient_of_fiedler_vector","text":"<pre><code>display_and_export_graph_of_gradient_of_fiedler_vector(pcd_g, filename='Gradient_of_fiedler_vector.png', sorted_by_fiedler_vector=True, sorted_by_gradient=False)\n</code></pre> <p>Displays and exports a plot of the gradient of the Fiedler vector.</p> <p>Parameters:</p> <ul> <li> <code>pcd_g</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The graph containing Fiedler vector gradient data.</p> </li> <li> <code>filename</code>               (<code>str or Path</code>, default:                   <code>'Gradient_of_fiedler_vector.png'</code> )           \u2013            <p>The file name for saving the output plot.</p> </li> <li> <code>sorted_by_fiedler_vector</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to sort the data by the Fiedler vector values.</p> </li> <li> <code>sorted_by_gradient</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to sort the data by the gradient values.</p> </li> </ul> Source code in <code>spectral_clustering/display_and_export.py</code> <pre><code>def display_and_export_graph_of_gradient_of_fiedler_vector(pcd_g, filename=\"Gradient_of_fiedler_vector.png\",\n                                                           sorted_by_fiedler_vector=True, sorted_by_gradient=False):\n    \"\"\"Displays and exports a plot of the gradient of the Fiedler vector.\n\n    Parameters\n    ----------\n    pcd_g : spectral_clustering.pointcloudgraph.PointCloudGraph\n        The graph containing Fiedler vector gradient data.\n    filename : str or pathlib.Path, optional\n        The file name for saving the output plot.\n    sorted_by_fiedler_vector : bool, optional\n        Whether to sort the data by the Fiedler vector values.\n    sorted_by_gradient : bool, optional\n        Whether to sort the data by the gradient values.\n    \"\"\"\n    vp2 = pcd_g.keigenvec[:, 1]\n    pcd_vp2 = np.concatenate([pcd_g.nodes_coords, vp2[:, np.newaxis]], axis=1)\n    pcd_vp2_grad_vp2 = np.concatenate([pcd_vp2, pcd_g.gradient_on_fiedler], axis=1)\n    pcd_vp2_grad_vp2_sort_by_vp2 = pcd_vp2_grad_vp2[pcd_vp2_grad_vp2[:, 3].argsort()]\n    pcd_vp2_grad_vp2_sort_by_grad = pcd_vp2_grad_vp2[pcd_vp2_grad_vp2[:, 4].argsort()]\n    figure = plt.figure(1)\n    figure.clf()\n    figure.gca().set_title(\"Gradient of fiedler vector\")\n    if sorted_by_fiedler_vector and not sorted_by_gradient:\n        figure.gca().scatter(range(len(pcd_vp2_grad_vp2_sort_by_vp2)), pcd_vp2_grad_vp2_sort_by_vp2[:, 4], color='blue')\n    elif not sorted_by_fiedler_vector and not sorted_by_gradient:\n        figure.gca().scatter(range(len(pcd_vp2_grad_vp2)), pcd_vp2_grad_vp2[:, 4], color='blue')\n    if sorted_by_gradient:\n        figure.gca().scatter(range(len(pcd_vp2_grad_vp2_sort_by_vp2)), pcd_vp2_grad_vp2_sort_by_grad[:, 4],\n                             color='blue')\n    figure.set_size_inches(10, 10)\n    figure.subplots_adjust(wspace=0, hspace=0)\n    figure.tight_layout()\n    figure.savefig(filename)\n    print(\"Export du gradient\")\n</code></pre>"},{"location":"reference/spectral_clustering/display_and_export/#spectral_clustering.display_and_export.display_and_export_quotient_graph_matplotlib","title":"display_and_export_quotient_graph_matplotlib","text":"<pre><code>display_and_export_quotient_graph_matplotlib(qg, node_sizes=20, name='quotient_graph_matplotlib', data_on_nodes='intra_class_node_number', data=True, attributekmeans4clusters=False, round=False, directory='.')\n</code></pre> <p>Generates a matplotlib visualization for the given quotient graph and exports it to a file.</p> <p>Visualizes the input graph using NetworkX's drawing functions with matplotlib. The appearance of the graph, including node colors, labels, and sizes, can be customized based on the given parameters. The plot is saved to the specified file.</p> <p>Parameters:</p> <ul> <li> <code>qg</code>               (<code>QuotientGraph</code>)           \u2013            <p>The input graph to be visualized and exported.</p> </li> <li> <code>node_sizes</code>               (<code>int</code>, default:                   <code>20</code> )           \u2013            <p>Size of the nodes in the plot, by default <code>20</code>.</p> </li> <li> <code>name</code>               (<code>str</code>, default:                   <code>'quotient_graph_matplotlib'</code> )           \u2013            <p>The name of the file where the graph visualization plot is saved.</p> </li> <li> <code>data_on_nodes</code>               (<code>str</code>, default:                   <code>'intra_class_node_number'</code> )           \u2013            <p>The name of the attribute on the nodes to be displayed as labels, by default 'intra_class_node_number'.</p> </li> <li> <code>data</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Determines whether to use node-specific data attributes in visualization, by default <code>True</code>.</p> </li> <li> <code>attributekmeans4clusters</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, the visualization integrates clustering-specific attributes and uses k-means related coloring, by default <code>False</code>.</p> </li> <li> <code>round</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If <code>True</code>, rounds the node attribute values for display, by default <code>False</code>.</p> </li> <li> <code>directory</code>               (<code>str or Path</code>, default:                   <code>'.'</code> )           \u2013            <p>A path to the output directory. Defaults to the current working directory.</p> </li> </ul> Source code in <code>spectral_clustering/display_and_export.py</code> <pre><code>def display_and_export_quotient_graph_matplotlib(qg, node_sizes=20, name='quotient_graph_matplotlib',\n                                                 data_on_nodes='intra_class_node_number', data=True,\n                                                 attributekmeans4clusters=False, round=False,\n                                                 directory=\".\"):\n    \"\"\"Generates a matplotlib visualization for the given quotient graph and exports it to a file.\n\n    Visualizes the input graph using NetworkX's drawing functions with matplotlib. The appearance of the\n    graph, including node colors, labels, and sizes, can be customized based on the given parameters.\n    The plot is saved to the specified file.\n\n    Parameters\n    ----------\n    qg : spectral_clustering.quotientgraph.QuotientGraph\n        The input graph to be visualized and exported.\n    node_sizes : int, optional\n        Size of the nodes in the plot, by default ``20``.\n    name : str, optional\n        The name of the file where the graph visualization plot is saved.\n    data_on_nodes : str, optional\n        The name of the attribute on the nodes to be displayed as labels, by default\n        'intra_class_node_number'.\n    data : bool, optional\n        Determines whether to use node-specific data attributes in visualization, by default ``True``.\n    attributekmeans4clusters : bool, optional\n        If ``True``, the visualization integrates clustering-specific attributes and uses k-means\n        related coloring, by default ``False``.\n    round : bool, optional\n        If ``True``, rounds the node attribute values for display, by default ``False``.\n    directory : str or pathlib.Path, optional\n        A path to the output directory. Defaults to the current working directory.\n    \"\"\"\n    figure = plt.figure(0)\n    figure.clf()\n    graph_layout = nx.kamada_kawai_layout(qg)\n    colormap = 'jet'\n\n    if attributekmeans4clusters and data:\n        labels_from_attributes = dict(qg.nodes(data=data_on_nodes))\n        # Rounding the data to allow an easy display\n        for dict_value in labels_from_attributes:\n            labels_from_attributes[dict_value] = round(labels_from_attributes[dict_value], 2)\n        node_color_from_attribute = dict(qg.nodes(data='seed_colors')).values()\n        node_color = [qg.nodes[i]['kmeans_labels'] / 4 for i in qg.nodes()]\n        nx.drawing.nx_pylab.draw_networkx(qg,\n                                          ax=figure.gca(),\n                                          pos=graph_layout,\n                                          with_labels=True,\n                                          node_size=node_sizes,\n                                          node_color=node_color_from_attribute,\n                                          labels=labels_from_attributes,\n                                          cmap=plt.get_cmap(colormap))\n\n    elif attributekmeans4clusters is False and data is False:\n        nx.drawing.nx_pylab.draw_networkx(qg,\n                                          ax=figure.gca(),\n                                          pos=graph_layout,\n                                          with_labels=False,\n                                          node_size=node_sizes,\n                                          node_color=\"r\",\n                                          cmap=plt.get_cmap(colormap))\n\n    elif attributekmeans4clusters is False and data:\n        labels_from_attributes = dict(qg.nodes(data=data_on_nodes))\n        # Rounding the data to allow an easy display\n        for dict_value in labels_from_attributes:\n            if data_on_nodes != 'semantic_label':\n                if round is True:\n                    labels_from_attributes[dict_value] = round(labels_from_attributes[dict_value], 2)\n        nx.drawing.nx_pylab.draw_networkx(qg,\n                                          ax=figure.gca(),\n                                          pos=graph_layout,\n                                          with_labels=True,\n                                          node_size=node_sizes,\n                                          node_color=\"r\",\n                                          labels=labels_from_attributes,\n                                          cmap=plt.get_cmap(colormap))\n\n    # nx.drawing.nx_pylab.draw_networkx_edge_labels(quotient_graph, pos=graph_layout, font_size=20, font_family=\"sans-sherif\")\n\n    figure.subplots_adjust(wspace=0, hspace=0)\n    figure.tight_layout()\n    directory = Path(directory)\n    fname = name + '_' + data_on_nodes + '.png'\n    figure.savefig(directory / fname)\n    print(\"Export du graphe quotient matplotlib\")\n</code></pre>"},{"location":"reference/spectral_clustering/display_and_export/#spectral_clustering.display_and_export.display_gradient_vector_field","title":"display_gradient_vector_field","text":"<pre><code>display_gradient_vector_field(pcd_g, normalized=True, scale=1.0, filename='gradient_vectorfield_3d.png')\n</code></pre> <p>Display the gradient vector field of a 3D topology.</p> <p>This function visualizes the gradient vector field of a provided topology using arrows as glyphs in a 3D representation. It supports configurable vector normalization, glyph scaling, and output filename for saving the visualization as an image.</p> <p>Parameters:</p> <ul> <li> <code>pcd_g</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The topology graph object, containing nodes with associated coordinates and gradient data.</p> </li> <li> <code>normalized</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Specifies whether the vectors should be normalized. If <code>True</code>, the scaled direction gradient on the Fiedler vector is used. Otherwise, the original gradient is scaled with the direction gradient on the Fiedler vector.</p> </li> <li> <code>scale</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Factor by which the arrow glyphs representing the gradient vectors should be scaled. Defaults to <code>1.0</code>.</p> </li> <li> <code>filename</code>               (<code>str or Path</code>, default:                   <code>'gradient_vectorfield_3d.png'</code> )           \u2013            <p>The name of the output image file where the visualization will be saved. Defaults to <code>'gradient_vectorfield_3d.png'</code>.</p> </li> </ul> Source code in <code>spectral_clustering/display_and_export.py</code> <pre><code>def display_gradient_vector_field(pcd_g, normalized=True, scale=1., filename=\"gradient_vectorfield_3d.png\"):\n    \"\"\"Display the gradient vector field of a 3D topology.\n\n    This function visualizes the gradient vector field of a provided topology using\n    arrows as glyphs in a 3D representation. It supports configurable vector\n    normalization, glyph scaling, and output filename for saving the visualization\n    as an image.\n\n    Parameters\n    ----------\n    pcd_g : spectral_clustering.pointcloudgraph.PointCloudGraph\n        The topology graph object, containing nodes with associated coordinates and gradient data.\n    normalized : bool, optional\n        Specifies whether the vectors should be normalized. If ``True``, the scaled\n        direction gradient on the Fiedler vector is used. Otherwise, the original\n        gradient is scaled with the direction gradient on the Fiedler vector.\n    scale : float, optional\n        Factor by which the arrow glyphs representing the gradient vectors should\n        be scaled. Defaults to ``1.0``.\n    filename : str or pathlib.Path, optional\n        The name of the output image file where the visualization will be saved.\n        Defaults to ``'gradient_vectorfield_3d.png'``.\n    \"\"\"\n    from cellcomplex.property_topomesh.creation import vertex_topomesh\n    from cellcomplex.property_topomesh.visualization.vtk_actor_topomesh import VtkActorTopomesh\n    from visu_core.vtk.display import vtk_display_actors, vtk_save_screenshot_actors\n\n    n_points = pcd_g.nodes_coords.shape[0]\n\n    topomesh = vertex_topomesh(dict(zip(range(n_points), pcd_g.nodes_coords)))\n\n    if normalized:\n        vectors = pcd_g.direction_gradient_on_fiedler_scaled\n    if normalized is False:\n        vectors = pcd_g.gradient_on_fiedler * pcd_g.direction_gradient_on_fiedler_scaled\n\n    topomesh.update_wisp_property('vector', 0, dict(zip(range(n_points), vectors)))\n\n    actors = []\n\n    vector_actor = VtkActorTopomesh(topomesh, degree=0, property_name='vector')\n    vector_actor.vector_glyph = 'arrow'\n    vector_actor.glyph_scale = scale\n    vector_actor.update(colormap='Reds', value_range=(0, 0))\n    actors += [vector_actor]\n\n    # Change of background\n    ren, _, _ = vtk_display_actors(actors, background=(0.9, 0.9, 0.9))\n    cam = ren.GetActiveCamera()\n    vtk_save_screenshot_actors(actors, image_filename=filename, camera=cam)\n</code></pre>"},{"location":"reference/spectral_clustering/display_and_export/#spectral_clustering.display_and_export.draw_quotientgraph_cellcomplex","title":"draw_quotientgraph_cellcomplex","text":"<pre><code>draw_quotientgraph_cellcomplex(pcd, qg, pcd_g, color_attribute='quotient_graph_node', filename='graph_and_quotientgraph_3d.png')\n</code></pre> <p>Draws and visualizes a cell complex derived from a quotient graph in 3D visualization.</p> <p>The method creates a topomesh representation of the input quotient graph, assigns vertex colors based on specified attributes, calculates edge properties (e.g., length), and renders the visualization. It allows customization of glyph type, color maps, and visual output filename.</p> <p>Parameters:</p> <ul> <li> <code>pcd</code>               (<code>PointCloud or ndarray</code>)           \u2013            <p>Point cloud data, either as an Open3D PointCloud object or a NumPy array containing point coordinates. If provided as Open3D PointCloud, the points are extracted and used as input.</p> </li> <li> <code>qg</code>               (<code>QuotientGraph</code>)           \u2013            <p>Quotient graph describing the cell complex structure. The graph should contain nodes and edges associated with the geometric representation of the input data.</p> </li> <li> <code>pcd_g</code>               (<code>PointCloudGraph</code>)           \u2013            <p>Graph specifying additional properties such as positions ('pos') and the visualization attributes for nodes in 3D. This graph is used to represent the original structure.</p> </li> <li> <code>color_attribute</code>               (<code>str</code>, default:                   <code>'quotient_graph_node'</code> )           \u2013            <p>Name of the property to be used for coloring the vertex glyphs. Defaults to <code>'quotient_graph_node'</code>. It can be changed to any node attribute present in the input quotient graph.</p> </li> <li> <code>filename</code>               (<code>str or Path</code>, default:                   <code>'graph_and_quotientgraph_3d.png'</code> )           \u2013            <p>Path and name of the file where the rendered 3D visualization will be saved as a screenshot. Defaults to <code>'graph_and_quotientgraph_3d.png'</code>.</p> </li> </ul> Source code in <code>spectral_clustering/display_and_export.py</code> <pre><code>def draw_quotientgraph_cellcomplex(pcd, qg, pcd_g, color_attribute='quotient_graph_node',\n                                   filename='graph_and_quotientgraph_3d.png'):\n    \"\"\"Draws and visualizes a cell complex derived from a quotient graph in 3D visualization.\n\n    The method creates a topomesh representation of the input quotient graph, assigns vertex colors based on\n    specified attributes, calculates edge properties (e.g., length), and renders the visualization.\n    It allows customization of glyph type, color maps, and visual output filename.\n\n    Parameters\n    ----------\n    pcd : open3d.geometry.PointCloud or numpy.ndarray\n        Point cloud data, either as an Open3D PointCloud object or a NumPy array containing\n        point coordinates. If provided as Open3D PointCloud, the points are extracted and used\n        as input.\n    qg : spectral_clustering.quotientgraph.QuotientGraph\n        Quotient graph describing the cell complex structure. The graph should contain nodes\n        and edges associated with the geometric representation of the input data.\n    pcd_g : spectral_clustering.pointcloudgraph.PointCloudGraph\n        Graph specifying additional properties such as positions ('pos') and the visualization\n        attributes for nodes in 3D. This graph is used to represent the original structure.\n    color_attribute : str, optional\n        Name of the property to be used for coloring the vertex glyphs. Defaults to\n        ``'quotient_graph_node'``. It can be changed to any node attribute present in the input\n        quotient graph.\n    filename : str or pathlib.Path, optional\n        Path and name of the file where the rendered 3D visualization will be saved as a\n        screenshot. Defaults to ``'graph_and_quotientgraph_3d.png'``.\n    \"\"\"\n    if type(pcd) is o3d.geometry.PointCloud:\n        pcdtab = np.asarray(pcd.points)\n    else:\n        pcdtab = pcd\n    # s, t = np.meshgrid(np.arange(len(pcdtab)), np.arange(len(pcdtab)))\n    # sources = s[simatrix &gt; 0]\n    # targets = t[simatrix &gt; 0]\n    # sources, targets = sources[sources &lt; targets], targets[sources &lt; targets]\n\n    from cellcomplex.property_topomesh.creation import vertex_topomesh, edge_topomesh\n    from cellcomplex.property_topomesh.analysis import compute_topomesh_property\n    from cellcomplex.property_topomesh.visualization.vtk_actor_topomesh import VtkActorTopomesh\n    from visu_core.vtk.display import vtk_display_actors, vtk_save_screenshot_actors\n\n    topomesh = edge_topomesh(np.array([e for e in qg.edges if e[0] != e[1]]),\n                             dict(zip(np.asarray([n for n in qg.nodes]), pcdtab)))\n\n    if color_attribute == 'quotient_graph_node':\n        topomesh.update_wisp_property('quotient_graph_node', 0, dict(zip([n for n in qg.nodes], [n for n in qg.nodes])))\n    else:\n        topomesh.update_wisp_property(color_attribute, 0,\n                                      dict(\n                                          zip([n for n in qg.nodes], [qg.nodes[n][color_attribute] for n in qg.nodes])))\n\n    compute_topomesh_property(topomesh, 'length', 1)\n\n    actors = []\n\n    edge_actor = VtkActorTopomesh()\n    edge_actor.set_topomesh(topomesh, 1, property_name='length')\n    edge_actor.line_glyph = 'tube'\n    edge_actor.glyph_scale = 0.33\n    edge_actor.update(colormap=\"gray\")\n    actors += [edge_actor]\n\n    vertex_actor = VtkActorTopomesh(topomesh, 0, property_name=color_attribute)\n    # vertex_actor.point_glyph = 'point'\n    vertex_actor.point_glyph = 'sphere'\n    vertex_actor.glyph_scale = 2\n    vertex_actor.update(colormap=\"jet\")\n    actors += [vertex_actor]\n\n    graph_topomesh = vertex_topomesh(dict(zip([n for n in pcd_g.nodes], [pcd_g.nodes[n]['pos'] for n in pcd_g.nodes])))\n    graph_topomesh.update_wisp_property(color_attribute, 0, dict(\n        zip([n for n in pcd_g.nodes], [pcd_g.nodes[n][color_attribute] for n in pcd_g.nodes])))\n    point_cloud_actor = VtkActorTopomesh(graph_topomesh, 0, property_name=color_attribute)\n    point_cloud_actor.point_glyph = 'point'\n    point_cloud_actor.update(colormap=\"jet\")\n    actors += [point_cloud_actor]\n\n    ren, _, _ = vtk_display_actors(actors, background=(0.9, 0.9, 0.9))\n    cam = ren.GetActiveCamera()\n    vtk_save_screenshot_actors(actors, image_filename=filename, camera=cam)\n</code></pre>"},{"location":"reference/spectral_clustering/display_and_export/#spectral_clustering.display_and_export.draw_quotientgraph_matplotlib_3D","title":"draw_quotientgraph_matplotlib_3D","text":"<pre><code>draw_quotientgraph_matplotlib_3D(nodes_coords_moy, qg)\n</code></pre> <p>Draws a 3D visualization of a quotient graph using Matplotlib.</p> <p>The function takes in the 3D coordinates of nodes and a quotient graph object, and visualizes the nodes and edges of the graph in three dimensions.</p> <p>Parameters:</p> <ul> <li> <code>nodes_coords_moy</code>               (<code>ndarray</code>)           \u2013            <p>A 2D numpy array of shape <code>(n, 3)</code>, where n represents the number of graph nodes. Each row corresponds to the 3D coordinates of a node.</p> </li> <li> <code>qg</code>               (<code>QuotientGraph</code>)           \u2013            <p>A quotient graph to be visualized.</p> </li> </ul> Notes <p>The function uses a matplotlib 3D scatter plot to render the nodes of the graph and draws lines connecting the nodes to represent edges. Node coordinates are specified in the <code>nodes_coords_moy</code> parameter, while edge connectivity is derived from the <code>QG</code> graph structure.</p> Source code in <code>spectral_clustering/display_and_export.py</code> <pre><code>def draw_quotientgraph_matplotlib_3D(nodes_coords_moy, qg):\n    \"\"\"Draws a 3D visualization of a quotient graph using Matplotlib.\n\n    The function takes in the 3D coordinates of nodes and a quotient graph object, and visualizes the\n    nodes and edges of the graph in three dimensions.\n\n    Parameters\n    ----------\n    nodes_coords_moy : numpy.ndarray\n        A 2D numpy array of shape `(n, 3)`, where n represents the number of graph nodes.\n        Each row corresponds to the 3D coordinates of a node.\n    qg : spectral_clustering.quotientgraph.QuotientGraph\n        A quotient graph to be visualized.\n\n    Notes\n    -----\n    The function uses a matplotlib 3D scatter plot to render the nodes of the graph\n    and draws lines connecting the nodes to represent edges. Node coordinates are\n    specified in the `nodes_coords_moy` parameter, while edge connectivity is\n    derived from the `QG` graph structure.\n    \"\"\"\n    from mpl_toolkits.mplot3d import Axes3D\n\n    with plt.style.context(('ggplot')):\n        fig = plt.figure(figsize=(10, 7))\n        ax = Axes3D(fig)\n        for i in range(nodes_coords_moy.shape[0]):\n            xi = nodes_coords_moy[i, 0]\n            yi = nodes_coords_moy[i, 1]\n            zi = nodes_coords_moy[i, 2]\n\n            ax.scatter(xi, yi, zi, s=10 ** 2, edgecolors='k', alpha=0.7)\n\n        for i, j in enumerate(qg.edges()):\n            corresp = dict(zip(qg.nodes, range(len(qg.nodes))))\n            x = np.array((nodes_coords_moy[corresp[j[0]], 0], nodes_coords_moy[corresp[j[1]], 0]))\n            y = np.array((nodes_coords_moy[corresp[j[0]], 1], nodes_coords_moy[corresp[j[1]], 1]))\n            z = np.array((nodes_coords_moy[corresp[j[0]], 2], nodes_coords_moy[corresp[j[1]], 2]))\n            ax.plot(x, y, z, c='black', alpha=0.5)\n        ax.view_init(elev=30)\n        ax.set_axis_off()\n        plt.show()\n</code></pre>"},{"location":"reference/spectral_clustering/display_and_export/#spectral_clustering.display_and_export.export_anything_on_point_cloud","title":"export_anything_on_point_cloud","text":"<pre><code>export_anything_on_point_cloud(pcd_g, attribute, filename='pcd_attribute.txt')\n</code></pre> <p>Exports a specified attribute to the point cloud.</p> <p>Parameters:</p> <ul> <li> <code>pcd_g</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The graph containing nodes coordinates.</p> </li> <li> <code>attribute</code>               (<code>ndarray</code>)           \u2013            <p>An array representing the attribute values to export.</p> </li> <li> <code>filename</code>               (<code>str or Path</code>, default:                   <code>'pcd_attribute.txt'</code> )           \u2013            <p>The name of the output file.</p> </li> </ul> Source code in <code>spectral_clustering/display_and_export.py</code> <pre><code>def export_anything_on_point_cloud(pcd_g, attribute, filename=\"pcd_attribute.txt\"):\n    \"\"\"Exports a specified attribute to the point cloud.\n\n    Parameters\n    ----------\n    pcd_g : spectral_clustering.pointcloudgraph.PointCloudGraph\n        The graph containing nodes coordinates.\n    attribute : ndarray\n        An array representing the attribute values to export.\n    filename : str or pathlib.Path, optional\n        The name of the output file.\n    \"\"\"\n    if attribute.ndim == 1:\n        attribute = attribute[:, np.newaxis]\n    pcd_attribute = np.concatenate([pcd_g.nodes_coords, attribute], axis=1)\n    np.savetxt(filename, pcd_attribute, delimiter=\",\")\n    print(\"Export du nuage avec les attributs demand\u00e9s\")\n</code></pre>"},{"location":"reference/spectral_clustering/display_and_export/#spectral_clustering.display_and_export.export_clustering_labels_on_point_cloud","title":"export_clustering_labels_on_point_cloud","text":"<pre><code>export_clustering_labels_on_point_cloud(pcd_g, filename='pcd_clustered.txt')\n</code></pre> <p>Exports clustering labels of a graph to a point cloud.</p> <p>Parameters:</p> <ul> <li> <code>pcd_g</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The graph containing nodes coordinates and clustering labels.</p> </li> <li> <code>filename</code>               (<code>str or Path</code>, default:                   <code>'pcd_clustered.txt'</code> )           \u2013            <p>The file name for the output.</p> </li> </ul> Source code in <code>spectral_clustering/display_and_export.py</code> <pre><code>def export_clustering_labels_on_point_cloud(pcd_g, filename=\"pcd_clustered.txt\"):\n    \"\"\"Exports clustering labels of a graph to a point cloud.\n\n    Parameters\n    ----------\n    pcd_g : spectral_clustering.pointcloudgraph.PointCloudGraph\n        The graph containing nodes coordinates and clustering labels.\n    filename : str or pathlib.Path, optional\n        The file name for the output.\n    \"\"\"\n    pcd_clusters = np.concatenate([pcd_g.nodes_coords, pcd_g.clustering_labels], axis=1)\n    np.savetxt(filename, pcd_clusters, delimiter=\",\")\n    print(\"Export du nuage avec les labels de cluster\")\n</code></pre>"},{"location":"reference/spectral_clustering/display_and_export/#spectral_clustering.display_and_export.export_fiedler_vector_on_pointcloud","title":"export_fiedler_vector_on_pointcloud","text":"<pre><code>export_fiedler_vector_on_pointcloud(G, filename='pcd_vp2.txt')\n</code></pre> <p>Exports the Fiedler vector to a point cloud.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The graph containing nodes coordinates and Fiedler vector data.</p> </li> <li> <code>filename</code>               (<code>str or Path</code>, default:                   <code>'pcd_vp2.txt'</code> )           \u2013            <p>The file name for the output.</p> </li> </ul> Source code in <code>spectral_clustering/display_and_export.py</code> <pre><code>def export_fiedler_vector_on_pointcloud(G, filename=\"pcd_vp2.txt\"):\n    \"\"\"Exports the Fiedler vector to a point cloud.\n\n    Parameters\n    ----------\n    G : spectral_clustering.pointcloudgraph.PointCloudGraph\n        The graph containing nodes coordinates and Fiedler vector data.\n    filename : str or pathlib.Path, optional\n        The file name for the output.\n    \"\"\"\n    vp2 = G.keigenvec[:, 1]\n    pcd_vp2 = np.concatenate([G.nodes_coords, vp2[:, np.newaxis]], axis=1)\n    np.savetxt(filename, pcd_vp2, delimiter=\",\")\n    print(\"Export du nuage avec le vecteur propre 2\")\n</code></pre>"},{"location":"reference/spectral_clustering/display_and_export/#spectral_clustering.display_and_export.export_gradient_of_fiedler_vector_on_pointcloud","title":"export_gradient_of_fiedler_vector_on_pointcloud","text":"<pre><code>export_gradient_of_fiedler_vector_on_pointcloud(pcd_g, filename='pcd_vp2_grad.txt')\n</code></pre> <p>Exports the gradient of the Fiedler vector to a point cloud.</p> <p>Parameters:</p> <ul> <li> <code>pcd_g</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The graph containing nodes coordinates and fiedler gradient data.</p> </li> <li> <code>filename</code>               (<code>str</code>, default:                   <code>'pcd_vp2_grad.txt'</code> )           \u2013            <p>The file name for the output.</p> </li> </ul> Source code in <code>spectral_clustering/display_and_export.py</code> <pre><code>def export_gradient_of_fiedler_vector_on_pointcloud(pcd_g, filename=\"pcd_vp2_grad.txt\"):\n    \"\"\"Exports the gradient of the Fiedler vector to a point cloud.\n\n    Parameters\n    ----------\n    pcd_g : spectral_clustering.pointcloudgraph.PointCloudGraph\n        The graph containing nodes coordinates and fiedler gradient data.\n    filename : str, optional\n        The file name for the output.\n    \"\"\"\n    pcd_vp2_grad = np.concatenate([pcd_g.nodes_coords, pcd_g.gradient_on_fiedler], axis=1)\n    np.savetxt(filename, pcd_vp2_grad, delimiter=\",\")\n    print(\"Export du nuage avec gradient du vecteur propre 2\")\n</code></pre>"},{"location":"reference/spectral_clustering/display_and_export/#spectral_clustering.display_and_export.export_quotient_graph_attribute_on_point_cloud","title":"export_quotient_graph_attribute_on_point_cloud","text":"<pre><code>export_quotient_graph_attribute_on_point_cloud(qg, attribute, name='', directory='.')\n</code></pre> <p>Exports attributes from a quotient graph to a point cloud.</p> <p>Parameters:</p> <ul> <li> <code>qg</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph containing point cloud and attribute data.</p> </li> <li> <code>attribute</code>               (<code>str</code>)           \u2013            <p>The attribute from the quotient graph nodes to be exported.</p> </li> <li> <code>name</code>               (<code>str</code>, default:                   <code>''</code> )           \u2013            <p>A suffix to append to the output file name.</p> </li> <li> <code>directory</code>               (<code>str or Path</code>, default:                   <code>'.'</code> )           \u2013            <p>A path to the output directory. Defaults to the current working directory.</p> </li> </ul> Source code in <code>spectral_clustering/display_and_export.py</code> <pre><code>def export_quotient_graph_attribute_on_point_cloud(qg, attribute, name='', directory=\".\"):\n    \"\"\"Exports attributes from a quotient graph to a point cloud.\n\n    Parameters\n    ----------\n    qg : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph containing point cloud and attribute data.\n    attribute : str\n        The attribute from the quotient graph nodes to be exported.\n    name : str, optional\n        A suffix to append to the output file name.\n    directory : str or pathlib.Path, optional\n        A path to the output directory. Defaults to the current working directory.\n    \"\"\"\n    labels_from_qg = np.zeros((len(qg.point_cloud_graph), 4))\n    i = 0\n    G = qg.point_cloud_graph\n    for n in G.nodes:\n        labels_from_qg[i, 0:3] = G.nodes[n]['pos']\n        labels_from_qg[i, 3] = qg.nodes[G.nodes[n]['quotient_graph_node']][attribute]\n        i += 1\n    directory = Path(directory)\n    fname = 'pcd_' + attribute + name + '.txt'\n    np.savetxt(directory / fname, labels_from_qg, delimiter=\",\")\n</code></pre>"},{"location":"reference/spectral_clustering/display_and_export/#spectral_clustering.display_and_export.export_some_graph_attributes_on_point_cloud","title":"export_some_graph_attributes_on_point_cloud","text":"<pre><code>export_some_graph_attributes_on_point_cloud(pcd_g, graph_attribute='quotient_graph_node', filename='graph_attribute.txt')\n</code></pre> <p>Exports specific graph attributes to a point cloud.</p> <p>Parameters:</p> <ul> <li> <code>pcd_g</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The graph containing nodes and the requested attribute.</p> </li> <li> <code>graph_attribute</code>               (<code>str</code>, default:                   <code>'quotient_graph_node'</code> )           \u2013            <p>The name of the graph attribute to export.</p> </li> <li> <code>filename</code>               (<code>str or Path</code>, default:                   <code>'graph_attribute.txt'</code> )           \u2013            <p>The file name for the output.</p> </li> </ul> Source code in <code>spectral_clustering/display_and_export.py</code> <pre><code>def export_some_graph_attributes_on_point_cloud(pcd_g, graph_attribute='quotient_graph_node',\n                                                filename='graph_attribute.txt'):\n    \"\"\"Exports specific graph attributes to a point cloud.\n\n    Parameters\n    ----------\n    pcd_g : spectral_clustering.pointcloudgraph.PointCloudGraph\n        The graph containing nodes and the requested attribute.\n    graph_attribute : str, optional\n        The name of the graph attribute to export.\n    filename : str or pathlib.Path, optional\n        The file name for the output.\n    \"\"\"\n    G = pcd_g\n    new_classif = np.asarray(list((dict(G.nodes(data=graph_attribute)).values())))\n    new_classif = new_classif[:, np.newaxis]\n    export_anything_on_point_cloud(G, attribute=new_classif, filename=filename)\n</code></pre>"},{"location":"reference/spectral_clustering/evaluation/","title":"evaluation","text":""},{"location":"reference/spectral_clustering/evaluation/#spectral_clustering.evaluation.change_labels","title":"change_labels","text":"<pre><code>change_labels(file_semantic_results='script/pcd_viterbi_classsemantic_final.txt', name_model='name_model', class_limb=1, class_mainstem=3, class_petiol=5, class_branch=6, class_apex=4)\n</code></pre> <p>Modifies the semantic labels of a 3D point cloud dataset based on predefined class mappings and saves the updated labels to a new file.</p> <p>This function loads a set of 3D coordinates along with their semantic class labels from a text file. It updates the labels based on a mapping defined by the parameters and writes the modified labels into a new output file corresponding to the provided model name.</p> <p>Parameters:</p> <ul> <li> <code>file_semantic_results</code>               (<code>str</code>, default:                   <code>'script/pcd_viterbi_classsemantic_final.txt'</code> )           \u2013            <p>Path to the input file containing the 3D point cloud coordinates and semantic labels. The file should have comma-separated values with four columns: x-coordinates, y-coordinates, z-coordinates, and semantic labels.</p> </li> <li> <code>name_model</code>               (<code>str</code>, default:                   <code>'name_model'</code> )           \u2013            <p>A string used for naming the output file containing the modified labels.</p> </li> <li> <code>class_limb</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The numeric class label representing \"limb\" in the dataset.</p> </li> <li> <code>class_mainstem</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The numeric class label representing \"mainstem\" in the dataset.</p> </li> <li> <code>class_petiol</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>The numeric class label representing \"petiol\" in the dataset.</p> </li> <li> <code>class_branch</code>               (<code>int</code>, default:                   <code>6</code> )           \u2013            <p>The numeric class label representing \"branch\" in the dataset.</p> </li> <li> <code>class_apex</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>The numeric class label representing \"apex\" in the dataset.</p> </li> </ul> Source code in <code>spectral_clustering/evaluation.py</code> <pre><code>def change_labels(file_semantic_results=\"script/pcd_viterbi_classsemantic_final.txt\",\n                  name_model='name_model',\n                  class_limb=1, class_mainstem=3, class_petiol=5, class_branch=6, class_apex=4):\n    \"\"\"\n    Modifies the semantic labels of a 3D point cloud dataset based on predefined class mappings and saves the updated\n    labels to a new file.\n\n    This function loads a set of 3D coordinates along with their semantic class labels from a text file. It updates the\n    labels based on a mapping defined by the parameters and writes the modified labels into a new output file corresponding\n    to the provided model name.\n\n    Parameters\n    ----------\n    file_semantic_results : str\n        Path to the input file containing the 3D point cloud coordinates and semantic labels. The file should have\n        comma-separated values with four columns: x-coordinates, y-coordinates, z-coordinates, and semantic labels.\n    name_model : str\n        A string used for naming the output file containing the modified labels.\n    class_limb : int\n        The numeric class label representing \"limb\" in the dataset.\n    class_mainstem : int\n        The numeric class label representing \"mainstem\" in the dataset.\n    class_petiol : int\n        The numeric class label representing \"petiol\" in the dataset.\n    class_branch : int\n        The numeric class label representing \"branch\" in the dataset.\n    class_apex : int\n        The numeric class label representing \"apex\" in the dataset.\n    \"\"\"\n    xc, yc, zc, labelsc = np.loadtxt(fname=file_semantic_results, delimiter=',', unpack=True)\n    for i in range(len(labelsc)):\n        if labelsc[i] == class_branch:\n            new = class_mainstem\n            labelsc[i] = new\n        elif labelsc[i] == class_apex:\n            new = class_limb\n            labelsc[i] = new\n        elif labelsc[i] == class_petiol:\n            new = class_mainstem\n            labelsc[i] = new\n\n    label_final = np.concatenate((xc[:, np.newaxis], yc[:, np.newaxis], zc[:, np.newaxis], labelsc[:, np.newaxis]),\n                                 axis=1)\n    np.savetxt('Label_final' + name_model + '.txt', label_final, delimiter=' ', fmt='%f')\n</code></pre>"},{"location":"reference/spectral_clustering/evaluation/#spectral_clustering.evaluation.compute_recall_precision_IoU","title":"compute_recall_precision_IoU","text":"<pre><code>compute_recall_precision_IoU(file_semantic_results='script/pcd_viterbi_classsemantic_final.txt', file_ground_truth_coord='script/cheno_virtuel_coordinates.txt', file_ground_truth_labels='script/cheno_virtuel_labels.txt', name_model='name_model', limb_gt=2, cotyledon_gt=3, main_stem_gt=1, petiole_gt=4, class_limb=1, class_mainstem=3, class_petiol=5, class_branch=6, class_apex=4)\n</code></pre> <p>Compute recall, precision, and IoU (Intersection over Union) metrics for evaluating the semantic segmentation model's performance. It involves comparing semantic segmentation results produced by the model with ground truth labels, adjusts the label mappings, and computes various performance metrics like recall, precision, IoU, overall accuracy, mean IoU, and F1-score. Additionally, confusion matrices and evaluation results are saved to output text files.</p> <p>Parameters:</p> <ul> <li> <code>file_semantic_results</code>               (<code>str</code>, default:                   <code>\"script/pcd_viterbi_classsemantic_final.txt\"</code> )           \u2013            <p>Path to the file containing semantic segmentation results, with x, y, z coordinates and predicted labels.</p> </li> <li> <code>file_ground_truth_coord</code>               (<code>str</code>, default:                   <code>\"script/cheno_virtuel_coordinates.txt\"</code> )           \u2013            <p>Path to the file containing ground truth 3D coordinates x, y, and z.</p> </li> <li> <code>file_ground_truth_labels</code>               (<code>str</code>, default:                   <code>\"script/cheno_virtuel_labels.txt\"</code> )           \u2013            <p>Path to the file containing ground truth labels corresponding to the coordinates.</p> </li> <li> <code>name_model</code>               (<code>str</code>, default:                   <code>'name_model'</code> )           \u2013            <p>Base name for output files to store results.</p> </li> <li> <code>limb_gt</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>Ground truth label value for the limb.</p> </li> <li> <code>cotyledon_gt</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>Ground truth label value for the cotyledon.</p> </li> <li> <code>main_stem_gt</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Ground truth label value for the main stem.</p> </li> <li> <code>petiole_gt</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>Ground truth label value for the petiole.</p> </li> <li> <code>class_limb</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Prediction label value for the limb.</p> </li> <li> <code>class_mainstem</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>Prediction label value for the main stem.</p> </li> <li> <code>class_petiol</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Prediction label value for the petiole.</p> </li> <li> <code>class_branch</code>               (<code>int</code>, default:                   <code>6</code> )           \u2013            <p>Prediction label value for the branch.</p> </li> <li> <code>class_apex</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>Prediction label value for the apex.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>FileNotFoundError</code>             \u2013            <p>If any of the input file paths does not exist.</p> </li> <li> <code>ValueError</code>             \u2013            <p>If the data in the provided files is not in the expected format.</p> </li> </ul> Notes <p>The procedure saves the following output files:     - 'Ground_truth_virtual<code>name_model</code>.txt': Adjusted ground truth data.     - 'Ground_truth_final<code>name_model</code>.txt': Final ground truth labels adjusted.     - 'Label_final<code>name_model</code>.txt': Predicted labels adjusted.     - '<code>name_model</code>scikit_cm': Confusion matrix.     - '<code>name_model</code>eval.txt': Evaluation metrics (TP, FP, FN, Recall, Precision, IoU, etc.). - The function ensures that predicted labels are remapped to align with ground truth   labels before metric computation. - Mean IoU is calculated as the average IoU across all unique ground truth labels. - Accuracy and F1-score are computed using standard metrics for binary/multi-class   classification. - The confusion matrix is generated using the sklearn <code>confusion_matrix</code> function,   and saved to a file.</p> Source code in <code>spectral_clustering/evaluation.py</code> <pre><code>def compute_recall_precision_IoU(file_semantic_results=\"script/pcd_viterbi_classsemantic_final.txt\",\n                                 file_ground_truth_coord=\"script/cheno_virtuel_coordinates.txt\",\n                                 file_ground_truth_labels=\"script/cheno_virtuel_labels.txt\",\n                                 name_model='name_model',\n                                 limb_gt=2, cotyledon_gt=3, main_stem_gt=1, petiole_gt=4,\n                                 class_limb=1, class_mainstem=3, class_petiol=5, class_branch=6, class_apex=4):\n    \"\"\"\n    Compute recall, precision, and IoU (Intersection over Union) metrics for evaluating the\n    semantic segmentation model's performance. It involves comparing semantic segmentation\n    results produced by the model with ground truth labels, adjusts the label mappings, and\n    computes various performance metrics like recall, precision, IoU, overall accuracy,\n    mean IoU, and F1-score. Additionally, confusion matrices and evaluation results\n    are saved to output text files.\n\n    Parameters\n    ----------\n    file_semantic_results : str, default=\"script/pcd_viterbi_classsemantic_final.txt\"\n        Path to the file containing semantic segmentation results, with x, y, z\n        coordinates and predicted labels.\n    file_ground_truth_coord : str, default=\"script/cheno_virtuel_coordinates.txt\"\n        Path to the file containing ground truth 3D coordinates x, y, and z.\n    file_ground_truth_labels : str, default=\"script/cheno_virtuel_labels.txt\"\n        Path to the file containing ground truth labels corresponding to the coordinates.\n    name_model : str, default='name_model'\n        Base name for output files to store results.\n    limb_gt : int, default=2\n        Ground truth label value for the limb.\n    cotyledon_gt : int, default=3\n        Ground truth label value for the cotyledon.\n    main_stem_gt : int, default=1\n        Ground truth label value for the main stem.\n    petiole_gt : int, default=4\n        Ground truth label value for the petiole.\n    class_limb : int, default=1\n        Prediction label value for the limb.\n    class_mainstem : int, default=3\n        Prediction label value for the main stem.\n    class_petiol : int, default=5\n        Prediction label value for the petiole.\n    class_branch : int, default=6\n        Prediction label value for the branch.\n    class_apex : int, default=4\n        Prediction label value for the apex.\n\n    Raises\n    ------\n    FileNotFoundError\n        If any of the input file paths does not exist.\n\n    ValueError\n        If the data in the provided files is not in the expected format.\n\n    Notes\n    -----\n    The procedure saves the following output files:\n        - 'Ground_truth_virtual`name_model`.txt': Adjusted ground truth data.\n        - 'Ground_truth_final`name_model`.txt': Final ground truth labels adjusted.\n        - 'Label_final`name_model`.txt': Predicted labels adjusted.\n        - '`name_model`scikit_cm': Confusion matrix.\n        - '`name_model`eval.txt': Evaluation metrics (TP, FP, FN, Recall, Precision, IoU, etc.).\n    - The function ensures that predicted labels are remapped to align with ground truth\n      labels before metric computation.\n    - Mean IoU is calculated as the average IoU across all unique ground truth labels.\n    - Accuracy and F1-score are computed using standard metrics for binary/multi-class\n      classification.\n    - The confusion matrix is generated using the sklearn `confusion_matrix` function,\n      and saved to a file.\n    \"\"\"\n    xc, yc, zc, labelsc = np.loadtxt(fname=file_semantic_results, delimiter=',', unpack=True)\n    xt, yt, zt = np.loadtxt(fname=file_ground_truth_coord, delimiter=',', unpack=True)\n    labelst = np.loadtxt(fname=file_ground_truth_labels, delimiter=',', unpack=True)\n    exp = np.concatenate((xt[:, np.newaxis], yt[:, np.newaxis], zt[:, np.newaxis], labelst[:, np.newaxis]), axis=1)\n    np.savetxt('Ground_truth_virtual' + name_model + '.txt', exp, delimiter=' ', fmt='%f')\n\n    # creation d'une liste ground truth correspondant aux labels.\n    label_gt_end = copy.deepcopy(labelst)\n    for i in range(len(label_gt_end)):\n        if label_gt_end[i] == limb_gt:\n            new = class_limb\n        elif label_gt_end[i] == main_stem_gt:\n            new = class_mainstem\n        elif label_gt_end[i] == petiole_gt:\n            new = class_petiol\n        # elif label_gt_end[i] == petiole_gt:\n        #    new = class_mainstem\n        elif label_gt_end[i] == cotyledon_gt:\n            new = class_limb\n        label_gt_end[i] = new\n\n    gt_final = np.concatenate((xt[:, np.newaxis], yt[:, np.newaxis], zt[:, np.newaxis], label_gt_end[:, np.newaxis]),\n                              axis=1)\n    np.savetxt('Ground_truth_final' + name_model + '.txt', gt_final, delimiter=' ', fmt='%f')\n    # ici j'ai trop de diff\u00e9rents labels par rapport \u00e0 la v\u00e9rit\u00e9 terrain, a enlever si c'est ok entre les deux\n\n    for i in range(len(labelsc)):\n        if labelsc[i] == class_branch:\n            new = class_mainstem\n            labelsc[i] = new\n        elif labelsc[i] == class_apex:\n            new = class_limb\n            labelsc[i] = new\n        # elif labelsc[i] == class_petiol:\n        #    new = class_mainstem\n        #    labelsc[i] = new\n\n    label_final = np.concatenate((xt[:, np.newaxis], yt[:, np.newaxis], zt[:, np.newaxis], labelsc[:, np.newaxis]),\n                                 axis=1)\n    np.savetxt('Label_final' + name_model + '.txt', label_final, delimiter=' ', fmt='%f')\n\n    mres = np.zeros((len(set(label_gt_end)) + 4, 8))\n    # mres[0, 1] = 'TP'\n    # mres[0, 2] = 'FN'\n    # mres[0, 3] = 'FP'\n    # mres[0, 4] = 'Re'\n    # mres[0, 5] = 'Pr'\n    # mres[0, 6] = 'IoU'\n    # faire une v\u00e9rification que les coordoonn\u00e9es correspondent ?\n    TP = dict()\n    FN = dict()\n    FP = dict()\n    TN = dict()\n    a = 1\n    for i in set(label_gt_end):\n        TP[i] = 0\n        FN[i] = 0\n        FP[i] = 0\n        TN[i] = 0\n        mres[a, 0] = i\n        a += 1\n\n    for i in range(len(labelsc)):\n        labelgiven = labelsc[i]\n        labeltruth = label_gt_end[i]\n        if labelsc[i] == label_gt_end[i]:\n            TP[labelgiven] += 1\n        else:\n            FP[labelgiven] += 1\n            FN[labeltruth] += 1\n        for c in set(label_gt_end):\n            if c != labelsc[i] and c != label_gt_end[i]:\n                TN[c] += 1\n\n    Re = dict()\n    Pr = dict()\n    IoU = dict()\n    TPtot = 0\n    FNtot = 0\n    FPtot = 0\n    TNtot = 0\n    MIoU = 0\n    for i in set(label_gt_end):\n        Re[i] = (TP[i]) / (TP[i] + FN[i])\n        Pr[i] = (TP[i]) / (TP[i] + FP[i])\n        IoU[i] = (TP[i]) / (TP[i] + FN[i] + FP[i])\n        TPtot += TP[i]\n        FNtot += FN[i]\n        FPtot += FP[i]\n        TNtot += TN[i]\n        MIoU += IoU[i]\n\n    MIoU /= len(set(label_gt_end))\n    totalacc = (TPtot + TNtot) / (TPtot + TNtot + FPtot + FNtot)\n    f1_score = TPtot / (TPtot + 0.5 * (FNtot + FPtot))\n\n    a = 1\n    for i in set(label_gt_end):\n        mres[a, 1] = TP[i]\n        mres[a, 2] = FN[i]\n        mres[a, 3] = FP[i]\n        mres[a, 4] = TN[i]\n        mres[a, 5] = Re[i]\n        mres[a, 6] = Pr[i]\n        mres[a, 7] = IoU[i]\n        a += 1\n    mres[len(set(label_gt_end)) + 1, 1] = TPtot\n    mres[len(set(label_gt_end)) + 1, 2] = FNtot\n    mres[len(set(label_gt_end)) + 1, 3] = FPtot\n    mres[len(set(label_gt_end)) + 1, 4] = TNtot\n    mres[len(set(label_gt_end)) + 1, 7] = MIoU\n    mres[len(set(label_gt_end)) + 2, 1] = totalacc\n    mres[len(set(label_gt_end)) + 3, 1] = f1_score\n\n    cm = metrics.confusion_matrix(label_gt_end, labelsc)\n    np.savetxt(name_model + 'scikit_cm', cm, fmt='%.4e')\n    np.savetxt(name_model + 'eval.txt', mres, fmt='%.4e')\n</code></pre>"},{"location":"reference/spectral_clustering/evaluation/#spectral_clustering.evaluation.compute_recall_precision_IoU_real_plants","title":"compute_recall_precision_IoU_real_plants","text":"<pre><code>compute_recall_precision_IoU_real_plants(file_semantic_results='script/pcd_viterbi_classsemantic_final.txt', file_instance_results='script/pcd_viterbi_classsemantic_final.txt', file_ground_truth='script/cheno_virtuel_coordinates.txt', name_model='name', class_limb=1, class_mainstem=3, class_petiol=5, class_branch=6, class_apex=4)\n</code></pre> <p>Computes various evaluation metrics such as recall, precision, IoU (Intersection over Union), and other classification, clustering, and region-based measures, for a 3D plant dataset that is segmented using semantic and instance labels compared against ground truth data.</p> <p>This function takes file paths of input data (semantic results, instance results, and ground truth), model names, and specific classification category IDs, and performs the following tasks: - Reads the input files and processes them into semantic and instance labels. - Adjusts and relabels certain class labels based on predefined thresholds. - Computes various metrics including TP, FP, FN, TN, precision, recall, IoU, and adjusts confusion matrices. - Outputs standardized data formats for the ground truth, predicted labels, and summary evaluation   metrics to files.</p> <p>Parameters:</p> <ul> <li> <code>file_semantic_results</code>               (<code>str</code>, default:                   <code>'script/pcd_viterbi_classsemantic_final.txt'</code> )           \u2013            <p>Path to the input file containing semantic classification results. Defaults to \"script/pcd_viterbi_classsemantic_final.txt\".</p> </li> <li> <code>file_instance_results</code>               (<code>str</code>, default:                   <code>'script/pcd_viterbi_classsemantic_final.txt'</code> )           \u2013            <p>Path to the input file containing instance classification results. Defaults to \"script/pcd_viterbi_classsemantic_final.txt\".</p> </li> <li> <code>file_ground_truth</code>               (<code>str</code>, default:                   <code>'script/cheno_virtuel_coordinates.txt'</code> )           \u2013            <p>Path to the input file containing ground truth coordinate data. Defaults to \"script/cheno_virtuel_coordinates.txt\".</p> </li> <li> <code>name_model</code>               (<code>str</code>, default:                   <code>'name'</code> )           \u2013            <p>Name of the model being processed and evaluated. Outputs will include this name in their filenames. Defaults to \"name\".</p> </li> <li> <code>class_limb</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>ID value representing the limb class (used for relabeling). Defaults to 1.</p> </li> <li> <code>class_mainstem</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>ID value representing the main stem class (used for relabeling). Defaults to 3.</p> </li> <li> <code>class_petiol</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>ID value representing the petiol class (used for relabeling). Defaults to 5.</p> </li> <li> <code>class_branch</code>               (<code>int</code>, default:                   <code>6</code> )           \u2013            <p>ID value representing the branch class (used for relabeling). Defaults to 6.</p> </li> <li> <code>class_apex</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>ID value representing the apex class (used for relabeling). Defaults to 4.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            </li> </ul> Notes <ul> <li>The function outputs several files containing processed data and results:</li> <li>Ground truth in standardized format with predicted classifications relabeled.</li> <li>Metrics related to clustering and classification performance, including precision, recall,     IoU, confusion matrix, and an F1 score.</li> <li> <p>Summary results are written to evaluation files using the provided <code>name_model</code>.</p> </li> <li> <p>All thresholds for relabeling are predefined and hardcoded within the function for specific   plant segmentation studies. Adjust these thresholds carefully if applying the function to   datasets with different formats or labeling conventions.</p> </li> <li> <p>The function leverages scikit-learn's metrics module for the computation of clustering and   classification scores.</p> </li> <li> <p>Outputs are saved in plaintext or numerical formats (e.g., <code>.txt</code>), making them suitable for   importing into statistical or visualization tools for downstream analysis.</p> </li> </ul> Source code in <code>spectral_clustering/evaluation.py</code> <pre><code>def compute_recall_precision_IoU_real_plants(file_semantic_results=\"script/pcd_viterbi_classsemantic_final.txt\",\n                                             file_instance_results=\"script/pcd_viterbi_classsemantic_final.txt\",\n                                             file_ground_truth=\"script/cheno_virtuel_coordinates.txt\",\n                                             name_model=\"name\",\n                                             class_limb=1, class_mainstem=3, class_petiol=5, class_branch=6,\n                                             class_apex=4):\n    \"\"\"\n    Computes various evaluation metrics such as recall, precision, IoU (Intersection over Union),\n    and other classification, clustering, and region-based measures, for a 3D plant dataset that is\n    segmented using semantic and instance labels compared against ground truth data.\n\n    This function takes file paths of input data (semantic results, instance results, and ground truth),\n    model names, and specific classification category IDs, and performs the following tasks:\n    - Reads the input files and processes them into semantic and instance labels.\n    - Adjusts and relabels certain class labels based on predefined thresholds.\n    - Computes various metrics including TP, FP, FN, TN, precision, recall, IoU, and adjusts confusion matrices.\n    - Outputs standardized data formats for the ground truth, predicted labels, and summary evaluation\n      metrics to files.\n\n    Parameters\n    ----------\n    file_semantic_results : str, optional\n        Path to the input file containing semantic classification results.\n        Defaults to \"script/pcd_viterbi_classsemantic_final.txt\".\n    file_instance_results : str, optional\n        Path to the input file containing instance classification results.\n        Defaults to \"script/pcd_viterbi_classsemantic_final.txt\".\n    file_ground_truth : str, optional\n        Path to the input file containing ground truth coordinate data.\n        Defaults to \"script/cheno_virtuel_coordinates.txt\".\n    name_model : str, optional\n        Name of the model being processed and evaluated. Outputs will include this name in their filenames.\n        Defaults to \"name\".\n    class_limb : int, optional\n        ID value representing the limb class (used for relabeling). Defaults to 1.\n    class_mainstem : int, optional\n        ID value representing the main stem class (used for relabeling). Defaults to 3.\n    class_petiol : int, optional\n        ID value representing the petiol class (used for relabeling). Defaults to 5.\n    class_branch : int, optional\n        ID value representing the branch class (used for relabeling). Defaults to 6.\n    class_apex : int, optional\n        ID value representing the apex class (used for relabeling). Defaults to 4.\n\n    Returns\n    -------\n    None\n\n    Notes\n    -----\n    - The function outputs several files containing processed data and results:\n      - Ground truth in standardized format with predicted classifications relabeled.\n      - Metrics related to clustering and classification performance, including precision, recall,\n        IoU, confusion matrix, and an F1 score.\n      - Summary results are written to evaluation files using the provided `name_model`.\n\n    - All thresholds for relabeling are predefined and hardcoded within the function for specific\n      plant segmentation studies. Adjust these thresholds carefully if applying the function to\n      datasets with different formats or labeling conventions.\n\n    - The function leverages scikit-learn's metrics module for the computation of clustering and\n      classification scores.\n\n    - Outputs are saved in plaintext or numerical formats (e.g., `.txt`), making them suitable for\n      importing into statistical or visualization tools for downstream analysis.\n    \"\"\"\n    xc, yc, zc, labelsc = np.loadtxt(fname=file_semantic_results, delimiter=',', unpack=True)\n    xc, yc, zc, labelinstance = np.loadtxt(fname=file_instance_results, delimiter=',', unpack=True)\n    xt, yt, zt, labelst, np2, c1, c2, c3 = np.loadtxt(fname=file_ground_truth, delimiter=',', unpack=True)\n    exp = np.concatenate((xt[:, np.newaxis], yt[:, np.newaxis], zt[:, np.newaxis], labelst[:, np.newaxis]), axis=1)\n    np.savetxt('Ground_truth_' + name_model + '.txt', exp, delimiter=' ', fmt='%f')\n\n    rand = metrics.cluster.rand_score(labelst, labelinstance)\n    print(\"rand\")\n    print(rand)\n    rand_adj = metrics.cluster.adjusted_rand_score(labelst, labelinstance)\n    print(\"rand_adjusted\")\n    print(rand_adj)\n    mutual = metrics.adjusted_mutual_info_score(labelst, labelinstance)\n    print(\"adjusted_mutual_info_score\")\n    print(mutual)\n    comp = metrics.completeness_score(labelst, labelinstance)\n    print(\"completeness_score\")\n    print(comp)\n    fowlkes = metrics.fowlkes_mallows_score(labelst, labelinstance)\n    print(\"fowlkes_mallows_score\")\n    print(fowlkes)\n    homogeneity = metrics.homogeneity_score(labelst, labelinstance)\n    print(\"homogeneity_score\")\n    print(homogeneity)\n\n    # creation d'une liste ground truth correspondant aux labels.\n    label_gt_end = copy.deepcopy(labelst)\n    for i in range(len(label_gt_end)):\n        if 399 &lt; label_gt_end[i] &lt; 500:\n            new = class_limb\n        elif label_gt_end[i] == 0:\n            new = class_mainstem\n        elif 199 &lt; label_gt_end[i] &lt; 300:\n            new = class_petiol\n        elif 299 &lt; label_gt_end[i] &lt; 399:\n            new = class_apex\n        elif 99 &lt; label_gt_end[i] &lt; 199:\n            new = class_branch\n        elif 999 &lt; label_gt_end[i]:\n            new = class_limb\n        label_gt_end[i] = new\n\n    gt_final = np.concatenate((xt[:, np.newaxis], yt[:, np.newaxis], zt[:, np.newaxis], label_gt_end[:, np.newaxis]),\n                              axis=1)\n    np.savetxt('Ground_truth_final' + name_model + '.txt', gt_final, delimiter=' ', fmt='%f')\n    # ici j'ai trop de diff\u00e9rents labels par rapport \u00e0 la v\u00e9rit\u00e9 terrain, a enlever si c'est ok entre les deux\n    \"\"\"\n    for i in range(len(labelsc)):\n        if labelsc[i] == class_branch:\n            new = class_mainstem\n            labelsc[i] = new\n        elif labelsc[i] == class_apex:\n            new = class_limb\n            labelsc[i] = new\n        #elif labelsc[i] == class_petiol:\n        #    new = class_mainstem\n        #    labelsc[i] = new\n    \"\"\"\n    if set(label_gt_end) &gt; set(labelsc):\n        list = set(label_gt_end)\n    else:\n        list = set(labelsc)\n    label_final = np.concatenate((xt[:, np.newaxis], yt[:, np.newaxis], zt[:, np.newaxis], labelsc[:, np.newaxis]),\n                                 axis=1)\n    np.savetxt('Label_final' + name_model + '.txt', label_final, delimiter=' ', fmt='%f')\n\n    mres = np.zeros(((len(list)) + 4, 8))\n    # mres[0, 1] = 'TP'\n    # mres[0, 2] = 'FN'\n    # mres[0, 3] = 'FP'\n    # mres[0, 4] = 'Re'\n    # mres[0, 5] = 'Pr'\n    # mres[0, 6] = 'IoU'\n    # faire une v\u00e9rification que les coordoonn\u00e9es correspondent ?\n    TP = dict()\n    FN = dict()\n    FP = dict()\n    TN = dict()\n    a = 1\n\n    for i in list:\n        TP[i] = 0\n        FN[i] = 0\n        FP[i] = 0\n        TN[i] = 0\n        mres[a, 0] = i\n        a += 1\n\n    for i in range(len(labelsc)):\n        labelgiven = labelsc[i]\n        labeltruth = label_gt_end[i]\n        if labelsc[i] == label_gt_end[i]:\n            TP[labelgiven] += 1\n        else:\n            FP[labelgiven] += 1\n            FN[labeltruth] += 1\n        for c in set(label_gt_end):\n            if c != labelsc[i] and c != label_gt_end[i]:\n                TN[c] += 1\n\n    Re = dict()\n    Pr = dict()\n    IoU = dict()\n    TPtot = 0\n    FNtot = 0\n    FPtot = 0\n    TNtot = 0\n    MIoU = 0\n    for i in set(label_gt_end):\n        Re[i] = (TP[i]) / (TP[i] + FN[i])\n        Pr[i] = (TP[i]) / (TP[i] + FP[i])\n        IoU[i] = (TP[i]) / (TP[i] + FN[i] + FP[i])\n        TPtot += TP[i]\n        FNtot += FN[i]\n        FPtot += FP[i]\n        TNtot += TN[i]\n        MIoU += IoU[i]\n\n    MIoU /= len(set(label_gt_end))\n    totalacc = (TPtot + TNtot) / (TPtot + TNtot + FPtot + FNtot)\n    f1_score = TPtot / (TPtot + 0.5 * (FNtot + FPtot))\n\n    a = 1\n    for i in set(label_gt_end):\n        mres[a, 1] = TP[i]\n        mres[a, 2] = FN[i]\n        mres[a, 3] = FP[i]\n        mres[a, 4] = TN[i]\n        mres[a, 5] = Re[i]\n        mres[a, 6] = Pr[i]\n        mres[a, 7] = IoU[i]\n        a += 1\n    mres[len(list) + 1, 1] = TPtot\n    mres[len(list) + 1, 2] = FNtot\n    mres[len(list) + 1, 3] = FPtot\n    mres[len(list) + 1, 4] = TNtot\n    mres[len(list) + 1, 7] = MIoU\n    mres[len(list) + 2, 1] = totalacc\n    mres[len(list) + 3, 1] = f1_score\n\n    cm = metrics.confusion_matrix(label_gt_end, labelsc)\n    np.savetxt(name_model + 'scikit_cm', cm, fmt='%.4e')\n    np.savetxt(name_model + 'eval.txt', mres, fmt='%.4e')\n</code></pre>"},{"location":"reference/spectral_clustering/evaluation/#spectral_clustering.evaluation.count_number_limbs_apex_etc","title":"count_number_limbs_apex_etc","text":"<pre><code>count_number_limbs_apex_etc(qg, class_apex=4, class_limb=1, attribute='viterbi_class')\n</code></pre> <p>Counts the number of nodes classified as 'limb' and 'apex' based on a given attribute in a graph structure.</p> <p>This function iterates over the nodes of a given graph, evaluates their data based on a specified attribute, and counts the nodes that match the classification for 'apex' and 'limb'. Returns a tuple of integers representing the count of 'apex' nodes and 'limb' nodes respectively.</p> <p>Parameters:</p> <ul> <li> <code>qg</code>               (<code>QuotientGraph</code>)           \u2013            <p>A graph object where each node contains data as a dictionary, accessed with the <code>attribute</code> parameter. The nodes are analyzed to determine if the provided <code>attribute</code> matches the classifications for 'apex' or 'limb'.</p> </li> <li> <code>class_apex</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>The value of the attribute that classifies a node as an 'apex' node. Defaults to 4.</p> </li> <li> <code>class_limb</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The value of the attribute that classifies a node as a 'limb' node. Defaults to 1.</p> </li> <li> <code>attribute</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The key name of the attribute in the node data dictionaries used to categorize nodes as 'apex' or 'limb'. Defaults to 'viterbi_class'.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>tuple of int</code>           \u2013            <p>A tuple containing two integers: - The number of nodes classified as 'apex'. - The number of nodes classified as 'limb'.</p> </li> </ul> Source code in <code>spectral_clustering/evaluation.py</code> <pre><code>def count_number_limbs_apex_etc(qg, class_apex=4, class_limb=1, attribute='viterbi_class'):\n    \"\"\"\n    Counts the number of nodes classified as 'limb' and 'apex' based on a given attribute\n    in a graph structure.\n\n    This function iterates over the nodes of a given graph, evaluates their data based\n    on a specified attribute, and counts the nodes that match the classification for\n    'apex' and 'limb'. Returns a tuple of integers representing the count of 'apex'\n    nodes and 'limb' nodes respectively.\n\n    Parameters\n    ----------\n    qg : spectral_clustering.quotient_graph.QuotientGraph\n        A graph object where each node contains data as a dictionary, accessed with\n        the `attribute` parameter. The nodes are analyzed to determine if the provided\n        `attribute` matches the classifications for 'apex' or 'limb'.\n    class_apex : int, optional\n        The value of the attribute that classifies a node as an 'apex' node. Defaults to 4.\n    class_limb : int, optional\n        The value of the attribute that classifies a node as a 'limb' node. Defaults to 1.\n    attribute : str, optional\n        The key name of the attribute in the node data dictionaries used to categorize\n        nodes as 'apex' or 'limb'. Defaults to 'viterbi_class'.\n\n    Returns\n    -------\n    tuple of int\n        A tuple containing two integers:\n        - The number of nodes classified as 'apex'.\n        - The number of nodes classified as 'limb'.\n    \"\"\"\n    list_of_limb = [x for x, y in qg.nodes(data=True) if y[attribute] == class_limb]\n    list_of_apex = [x for x, y in qg.nodes(data=True) if y[attribute] == class_apex]\n\n    return (len(list_of_apex, len(list_of_limb)))\n</code></pre>"},{"location":"reference/spectral_clustering/evaluation/#spectral_clustering.evaluation.downsample_pcd","title":"downsample_pcd","text":"<pre><code>downsample_pcd(file_pcd='script/pcd_viterbi_classsemantic_final.txt', name_model='name_model')\n</code></pre> <p>Reduces the resolution of a point cloud by voxel down-sampling and saves the resulting down-sampled point cloud to a file.</p> <p>This function uses voxel grid down-sampling to reduce the density of points in the given point cloud file. Additionally, it traces approximate classes to maintain semantic information during the down-sampling process. The resulting down-sampled point cloud is saved in PLY format with a specified output file name.</p> <p>Parameters:</p> <ul> <li> <code>file_pcd</code>               (<code>str</code>, default:                   <code>'script/pcd_viterbi_classsemantic_final.txt'</code> )           \u2013            <p>The file path to the input point cloud (in PLY format). Default is \"script/pcd_viterbi_classsemantic_final.txt\".</p> </li> <li> <code>name_model</code>               (<code>str</code>, default:                   <code>'name_model'</code> )           \u2013            <p>The base name for the output down-sampled point cloud file. The output file will have the name \"down_sample.ply\". Source code in <code>spectral_clustering/evaluation.py</code> <pre><code>def downsample_pcd(file_pcd=\"script/pcd_viterbi_classsemantic_final.txt\",\n                   name_model='name_model'):\n    \"\"\"\n    Reduces the resolution of a point cloud by voxel down-sampling and saves the\n    resulting down-sampled point cloud to a file.\n\n    This function uses voxel grid down-sampling to reduce the density of points\n    in the given point cloud file. Additionally, it traces approximate classes to\n    maintain semantic information during the down-sampling process. The resulting\n    down-sampled point cloud is saved in PLY format with a specified output file name.\n\n    Parameters\n    ----------\n    file_pcd : str, optional\n        The file path to the input point cloud (in PLY format). Default is\n        \"script/pcd_viterbi_classsemantic_final.txt\".\n    name_model : str, optional\n        The base name for the output down-sampled point cloud file. The output\n        file will have the name \"&lt;name_model&gt;down_sample.ply\".\n    \"\"\"\n    pcd = o3d.io.read_point_cloud(file_pcd, format='ply')\n    downpcd = o3d.geometry.voxel_down_sample_and_trace(input=pcd, voxel_size=1.0, approximate_class=True)\n    o3d.io.write_point_cloud(name_model + \"down_sample.ply\", downpcd)\n</code></pre>"},{"location":"reference/spectral_clustering/evaluation/#spectral_clustering.evaluation.export_each_element_point_cloud","title":"export_each_element_point_cloud","text":"<pre><code>export_each_element_point_cloud(qg, class_to_export=1, attribute='viterbi_class', name='limb_piece')\n</code></pre> <p>Exports elements of a point cloud graph based on a specified class and attribute. For each matching element, the method identifies corresponding nodes, creates a subgraph, and saves positional data to a text file if the subgraph contains more than 50 nodes.</p> <p>Parameters:</p> <ul> <li> <code>qg</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph containing nodes and their associated attributes.</p> </li> <li> <code>class_to_export</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The specific class value in the <code>attribute</code> of the nodes of <code>gq</code> to export. Defaults to <code>1</code>.</p> </li> <li> <code>attribute</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The attribute of the nodes in <code>gq</code> to match against <code>class_to_export</code> for filtering. Defaults to <code>'viterbi_class'</code>.</p> </li> <li> <code>name</code>               (<code>str</code>, default:                   <code>'limb_piece'</code> )           \u2013            <p>The name used for the output file prefix. Defaults to <code>'limb_piece'</code>.</p> </li> </ul> Source code in <code>spectral_clustering/evaluation.py</code> <pre><code>def export_each_element_point_cloud(qg, class_to_export=1, attribute='viterbi_class', name='limb_piece'):\n    \"\"\"\n    Exports elements of a point cloud graph based on a specified class and attribute. For each matching element,\n    the method identifies corresponding nodes, creates a subgraph, and saves positional data\n    to a text file if the subgraph contains more than 50 nodes.\n\n    Parameters\n    ----------\n    qg : spectral_clustering.quotient_graph.QuotientGraph\n        The quotient graph containing nodes and their associated attributes.\n    class_to_export : int, optional\n        The specific class value in the `attribute` of the nodes of `gq` to export.\n        Defaults to ``1``.\n    attribute : str, optional\n        The attribute of the nodes in `gq` to match against `class_to_export`\n        for filtering. Defaults to ``'viterbi_class'``.\n    name : str, optional\n        The name used for the output file prefix. Defaults to ``'limb_piece'``.\n    \"\"\"\n    G = qg.point_cloud_graph\n    list = [x for x, y in qg.nodes(data=True) if y[attribute] == class_to_export]\n    for n in list:\n        list_points = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == n]\n        H = G.subgraph(list_points)\n        labels_from_qg = np.zeros((len(H.nodes), 3))\n        i = 0\n        if len(H.nodes) &gt; 50:\n            for n in H.nodes:\n                labels_from_qg[i, 0:3] = G.nodes[n]['pos']\n                i += 1\n            np.savetxt('pcd_' + name + str(n) + '_' + str(i) + '.txt', labels_from_qg, delimiter=\" \")\n</code></pre>"},{"location":"reference/spectral_clustering/evaluation/#spectral_clustering.evaluation.length_main_stem","title":"length_main_stem","text":"<pre><code>length_main_stem(qg, class_main_stem=3, attribute='viterbi_class')\n</code></pre> <p>Computes the length of the main stem in a graph.</p> <p>This function identifies the main stem of a given graph by analyzing node properties and relationships in a quotient graph and its subgraph. It finds the longest of shortest paths in the subgraph, computes its length, and visualizes the path. It leverages Dijkstra's algorithm to determine the longest path distance.</p> <p>Parameters:</p> <ul> <li> <code>qg</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph that contains nodes and their attributes used to identify the main stem.</p> </li> <li> <code>class_main_stem</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The class used to filter nodes in the quotient graph. Only nodes from <code>gq</code> with an attribute value matching this class are considered for the analysis. Defaults to <code>3</code>.</p> </li> <li> <code>attribute</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The name of the node attribute in <code>gq</code> used to categorize nodes for identifying the main stem. Defaults to <code>'viterbi_class'</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>           \u2013            <p>The length of the main stem, calculated as the sum of distances along the longest of shortest paths in the subgraph.</p> </li> </ul> Source code in <code>spectral_clustering/evaluation.py</code> <pre><code>def length_main_stem(qg, class_main_stem=3, attribute='viterbi_class'):\n    \"\"\"Computes the length of the main stem in a graph.\n\n    This function identifies the main stem of a given graph by analyzing node\n    properties and relationships in a quotient graph and its subgraph. It finds\n    the longest of shortest paths in the subgraph, computes its length, and visualizes\n    the path. It leverages Dijkstra's algorithm to determine the longest path distance.\n\n    Parameters\n    ----------\n    qg : spectral_clustering.quotient_graph.QuotientGraph\n        The quotient graph that contains nodes and their attributes used to identify\n        the main stem.\n    class_main_stem : int, optional\n        The class used to filter nodes in the quotient graph. Only nodes from\n        `gq` with an attribute value matching this class are considered for the\n        analysis. Defaults to ``3``.\n    attribute : str, optional\n        The name of the node attribute in `gq` used to categorize nodes for\n        identifying the main stem. Defaults to ``'viterbi_class'``.\n\n    Returns\n    -------\n    float\n        The length of the main stem, calculated as the sum of distances along\n        the longest of shortest paths in the subgraph.\n    \"\"\"\n    G = qg.point_cloud_graph\n    list_QG_nodes = [x for x, y in qg.nodes(data=True) if y[attribute] == class_main_stem]\n    # get all points from stem\n    list_G_nodes = list()\n    for qgn in list_QG_nodes:\n        add_list = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == qgn]\n        list_G_nodes += add_list\n    # make subgraph\n    print(list_G_nodes)\n    substem = G.subgraph(list_G_nodes)\n\n    # find longest of shortest paths\n    random_node = choice(list(substem.nodes))\n    dict = nx.single_source_dijkstra_path_length(substem, random_node, weight='distance')\n    ptsource = max(dict.items(), key=operator.itemgetter(1))[0]\n    # Stockage de tous les poids des plus courts chemin entre le pr\u00e9c\u00e9dent point et l'ensemble des points du graphe\n    dict = nx.single_source_dijkstra_path_length(substem, ptsource, weight='distance')\n    # Isolation du point le plus \u00e9loign\u00e9\n    ptarrivee = max(dict.items(), key=operator.itemgetter(1))[0]\n    # Obtention du chemin entre le point source et le point d'arriv\u00e9e finaux\n    segmsource = nx.dijkstra_path(substem, ptsource, ptarrivee, weight='distance')\n\n    Gaffichage = nx.Graph()\n    pts = np.array(G.pcd.points)\n    N = len(G.pcd.points)\n    for i in range(N):\n        Gaffichage.add_node(i, pos=pts[i])\n    nx.add_path(Gaffichage, segmsource)\n    edgelist = Gaffichage.edges\n\n    graph = o3d.geometry.LineSet()\n    graph.points = o3d.utility.Vector3dVector(pts)\n    graph.lines = o3d.utility.Vector2iVector(edgelist)\n    o3d.visualization.draw_geometries([graph, G.pcd])\n    # compute the length\n    l = 0\n    for i in range(len(segmsource) - 1):\n        l += G.edges[segmsource[i], segmsource[i + 1]][\"distance\"]\n\n    return l\n</code></pre>"},{"location":"reference/spectral_clustering/evaluation/#spectral_clustering.evaluation.resegment_apex_for_eval_and_export","title":"resegment_apex_for_eval_and_export","text":"<pre><code>resegment_apex_for_eval_and_export(qg, class_apex=4, attribute='viterbi_class', name='apex_piece', lim=30)\n</code></pre> <p>Resegments specific nodes in a quotient graph for evaluation and export purposes.</p> <p>This function operates on a quotient graph (QG) to identify specific nodes based on their attributes and class values. It performs resegmentation for nodes matching specified criteria using k-means clustering. Furthermore, it leverages elbow methods, computes maxima if required, and exports the resegmented data.</p> <p>Parameters:</p> <ul> <li> <code>qg</code>               (<code>QuotientGraph</code>)           \u2013            <p>A quotient graph on which resegmentation and transformations will be performed.</p> </li> <li> <code>class_apex</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>The value of the <code>attribute</code> to identify nodes in the quotient graph for resegmentation. Default is <code>4</code>.</p> </li> <li> <code>attribute</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>Node attribute to match for identifying nodes for resegmentation. Default is <code>'viterbi_class'</code>.</p> </li> <li> <code>name</code>               (<code>str</code>, default:                   <code>'apex_piece'</code> )           \u2013            <p>Base name used for exporting file outputs of resegmented labels. Default is <code>'apex_piece'</code>.</p> </li> <li> <code>lim</code>               (<code>int</code>, default:                   <code>30</code> )           \u2013            <p>Threshold to limit the number of nodes resegmented. If the number of nodes in the subgraph exceeds this value, resegmentation is performed. Default is <code>30</code>.</p> </li> </ul> Notes <ul> <li>This function assumes that the quotient graph (QG) has been preprocessed   and contains required information such as local Fiedler extrema counts   for nodes.</li> <li>Node positions and direction gradients are used internally during the   k-means clustering process.</li> <li>File exports are automatically handled for each resegmented apex. Resulting   files contain label data produced by k-means clustering.</li> </ul> Source code in <code>spectral_clustering/evaluation.py</code> <pre><code>def resegment_apex_for_eval_and_export(qg, class_apex=4, attribute='viterbi_class', name='apex_piece', lim=30):\n    \"\"\"Resegments specific nodes in a quotient graph for evaluation and export purposes.\n\n    This function operates on a quotient graph (QG) to identify specific nodes\n    based on their attributes and class values. It performs resegmentation for\n    nodes matching specified criteria using k-means clustering. Furthermore, it\n    leverages elbow methods, computes maxima if required, and exports the\n    resegmented data.\n\n    Parameters\n    ----------\n    qg : spectral_clustering.quotient_graph.QuotientGraph\n        A quotient graph on which resegmentation and transformations will be\n        performed.\n    class_apex : int, optional\n        The value of the `attribute` to identify nodes in the quotient graph for\n        resegmentation. Default is ``4``.\n    attribute : str, optional\n        Node attribute to match for identifying nodes for resegmentation.\n        Default is ``'viterbi_class'``.\n    name : str, optional\n        Base name used for exporting file outputs of resegmented labels.\n        Default is ``'apex_piece'``.\n    lim : int, optional\n        Threshold to limit the number of nodes resegmented. If the number of\n        nodes in the subgraph exceeds this value, resegmentation is performed.\n        Default is ``30``.\n\n    Notes\n    -----\n    - This function assumes that the quotient graph (QG) has been preprocessed\n      and contains required information such as local Fiedler extrema counts\n      for nodes.\n    - Node positions and direction gradients are used internally during the\n      k-means clustering process.\n    - File exports are automatically handled for each resegmented apex. Resulting\n      files contain label data produced by k-means clustering.\n\n    \"\"\"\n    list_of_apex = [x for x, y in qg.nodes(data=True) if y[attribute] == class_apex]\n    attribute_seg = 'direction_gradient'\n    # resegment with direction infos + elbow method\n    # for n in list_of_apex:\n    # resegment_nodes_with_elbow_method(QG, QG_nodes_to_rework=[n],\n    #                                  number_of_cluster_tested=20,\n    #                                  attribute='direction_gradient',\n    #                                  number_attribute=3,\n    #                                  standardization=False, numer=1, G_mod=False, export_div=True)\n\n    # Check if maximas has been computed or recompute them\n    qg.count_local_extremum_of_Fiedler()\n    # Resegment each apex with n = number of extremum and k-means ?\n    for n in list_of_apex:\n        number_clust = qg.nodes[n]['number_of_local_Fiedler_extremum']\n        sub = create_subgraphs_to_work(quotientgraph=qg, list_quotient_node_to_work=[n])\n        SG = sub\n        list_nodes = list(SG.nodes)\n        # creation of matrices to work with in the elbow_method package\n        if len(SG.nodes) &gt; number_clust and len(SG.nodes) &gt; lim:\n            Xcoord = np.zeros((len(SG), 3))\n            for u in range(len(SG)):\n                Xcoord[u] = SG.nodes[list(SG.nodes)[u]]['pos']\n            Xnorm = np.zeros((len(SG), 3))\n            for u in range(len(SG)):\n                Xnorm[u] = SG.nodes[list(SG.nodes)[u]][attribute_seg]\n\n            kmeans = KMeans(n_clusters=number_clust, init='k-means++', n_init=20, max_iter=300,\n                            tol=0.0001).fit(Xnorm)\n            kmeans_labels = kmeans.labels_[:, np.newaxis]\n\n            new_labels = np.zeros((len(SG.nodes), 4))\n            new_labels[:, 0:3] = Xcoord\n            for pt in range(len(list_nodes)):\n                new_labels[pt, 3] = kmeans_labels[pt]\n            np.savetxt('pcd_new_labels_' + str(n) + '.txt', new_labels, delimiter=\",\")\n            indices = np.argsort(new_labels[:, 3])\n            arr_temp = new_labels[indices]\n            arr_split = np.array_split(arr_temp, np.where(np.diff(arr_temp[:, 3]) != 0)[0] + 1)\n            v = 0\n            for arr in arr_split:\n                np.savetxt('pcd_new_labels_apex' + str(n) + '_' + str(v) + '.txt', arr, delimiter=\",\")\n                v += 1\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/","title":"point_cloud_graph","text":""},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph","title":"PointCloudGraph","text":"<pre><code>PointCloudGraph(G=None)\n</code></pre> <p>               Bases: <code>Graph</code></p> <p>A graph class representing point cloud data and providing various functionalities for graph processing.</p> <p>This class is designed to represent and manipulate a graph derived from point cloud data. It supports storing and processing graph-related attributes such as adjacency matrix, eigenvectors, and gradient information. The class enables operations including spectral graph analysis and gradient computation on specific signal vectors.</p> <p>Attributes:</p> <ul> <li> <code>nodes_coords</code>               (<code>ndarray or None</code>)           \u2013            <p>Coordinates of the nodes in the graph, derived from point cloud data. None if not initialized.</p> </li> <li> <code>laplacian</code>               (<code>ndarray or None</code>)           \u2013            <p>The Laplacian matrix of the graph. None if not computed.</p> </li> <li> <code>keigenvec</code>               (<code>ndarray or None</code>)           \u2013            <p>Array of eigenvectors of the graph Laplacian. None if not computed.</p> </li> <li> <code>keigenval</code>               (<code>ndarray or None</code>)           \u2013            <p>Array of eigenvalues of the graph Laplacian. None if not computed.</p> </li> <li> <code>gradient_on_fiedler</code>               (<code>ndarray or None</code>)           \u2013            <p>Gradient computed on the Fiedler vector of the graph. None if not computed.</p> </li> <li> <code>direction_gradient_on_fiedler_scaled</code>               (<code>ndarray or None</code>)           \u2013            <p>Scaled direction gradient computed on the Fiedler vector of the graph. None if not computed.</p> </li> <li> <code>clustering_labels</code>               (<code>ndarray or None</code>)           \u2013            <p>Labels for node clustering based on graph properties. None if not computed.</p> </li> <li> <code>clusters_leaves</code>               (<code>list or None</code>)           \u2013            <p>Leaf nodes in each cluster. None if not computed.</p> </li> <li> <code>kmeans_labels_gradient</code>               (<code>ndarray or None</code>)           \u2013            <p>Labels for k-means clustering applied to gradient data. None if not computed.</p> </li> <li> <code>minimum_local</code>               (<code>list or None</code>)           \u2013            <p>Local minima within a processed graph signal. None if not initialized.</p> </li> <li> <code>pcd</code>               (<code>PointCloud or None</code>)           \u2013            <p>Point cloud data associated with the graph. None if not provided or initialized.</p> </li> <li> <code>extrem_local_fiedler</code>               (<code>list or None</code>)           \u2013            <p>Local extrema computed on the Fiedler vector. None if not initialized.</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def __init__(self, G=None):\n    super().__init__(G)\n    if G is not None:\n        self.nodes_coords = np.array(list(dict(self.nodes(data='pos')).values()))\n    else:\n        self.nodes_coords = None\n\n    self.laplacian = None\n    self.keigenvec = None\n    self.keigenval = None\n    self.gradient_on_fiedler = None\n    self.direction_gradient_on_fiedler_scaled = None\n    self.clustering_labels = None\n    self.clusters_leaves = None\n    self.kmeans_labels_gradient = None\n    self.minimum_local = None\n    self.pcd = None\n    self.extrem_local_fiedler = None\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.add_anything_as_attribute","title":"add_anything_as_attribute","text":"<pre><code>add_anything_as_attribute(anything, name_of_the_new_attribute)\n</code></pre> <p>Assigns specified values as attributes to the nodes of a graph.</p> <p>This function adds attributes to the nodes of a graph by mapping the given values to the nodes based on their order, and then assigning these mapped values to a new attribute name provided by the user.</p> <p>Parameters:</p> <ul> <li> <code>anything</code>               (<code>list</code>)           \u2013            <p>A list of values corresponding to nodes of the graph. The values should be in the same order as the nodes for proper mapping.</p> </li> <li> <code>name_of_the_new_attribute</code>               (<code>str</code>)           \u2013            <p>The name of the new attribute that will be added to each node, with corresponding values from the input list.</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def add_anything_as_attribute(self, anything, name_of_the_new_attribute):\n    \"\"\"Assigns specified values as attributes to the nodes of a graph.\n\n    This function adds attributes to the nodes of a graph by mapping the given\n    values to the nodes based on their order, and then assigning these mapped\n    values to a new attribute name provided by the user.\n\n    Parameters\n    ----------\n    anything : list\n        A list of values corresponding to nodes of the graph. The values should\n        be in the same order as the nodes for proper mapping.\n    name_of_the_new_attribute : str\n        The name of the new attribute that will be added to each node, with\n        corresponding values from the input list.\n    \"\"\"\n    node_anything_values = dict(zip(self.nodes(), anything))\n    nx.set_node_attributes(self, node_anything_values, name_of_the_new_attribute)\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.add_coordinates_as_attribute_for_each_node","title":"add_coordinates_as_attribute_for_each_node","text":"<pre><code>add_coordinates_as_attribute_for_each_node()\n</code></pre> <p>Adds coordinates as attributes to each node in the graph.</p> <p>This method assigns the X, Y, and Z coordinates of each node in the graph as attributes named 'X_coordinate', 'Y_coordinate', and 'Z_coordinate', respectively. The node attributes are created by mapping the node IDs to their respective coordinate values in the provided coordinate data.</p> <p>Each node's X, Y, and Z coordinate values are extracted from <code>nodes_coords</code> and then applied as attributes to the nodes using NetworkX's <code>set_node_attributes</code> method.</p> Notes <p>This method assumes that the <code>nodes_coords</code> attribute is a NumPy array and that it contains node coordinate data in the format where:     - The first column represents the X coordinates.     - The second column represents the Y coordinates.     - The third column represents the Z coordinates. The number of nodes in the graph must match the number of rows in the <code>nodes_coords</code> array.</p> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def add_coordinates_as_attribute_for_each_node(self):\n    \"\"\"Adds coordinates as attributes to each node in the graph.\n\n    This method assigns the X, Y, and Z coordinates of each node in the graph\n    as attributes named 'X_coordinate', 'Y_coordinate', and 'Z_coordinate', respectively.\n    The node attributes are created by mapping the node IDs to their respective\n    coordinate values in the provided coordinate data.\n\n    Each node's X, Y, and Z coordinate values are extracted from `nodes_coords`\n    and then applied as attributes to the nodes using NetworkX's\n    `set_node_attributes` method.\n\n    Notes\n    -----\n    This method assumes that the `nodes_coords` attribute is a NumPy array and that\n    it contains node coordinate data in the format where:\n        - The first column represents the X coordinates.\n        - The second column represents the Y coordinates.\n        - The third column represents the Z coordinates.\n    The number of nodes in the graph must match the number of rows in the\n    `nodes_coords` array.\n    \"\"\"\n    nodes_coordinates_X = dict(zip(self.nodes(), self.nodes_coords[:, 0]))\n    nodes_coordinates_Y = dict(zip(self.nodes(), self.nodes_coords[:, 1]))\n    nodes_coordinates_Z = dict(zip(self.nodes(), self.nodes_coords[:, 2]))\n\n    nx.set_node_attributes(self, nodes_coordinates_X, 'X_coordinate')\n    nx.set_node_attributes(self, nodes_coordinates_Y, 'Y_coordinate')\n    nx.set_node_attributes(self, nodes_coordinates_Z, 'Z_coordinate')\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.add_eigenvector_value_as_attribute","title":"add_eigenvector_value_as_attribute","text":"<pre><code>add_eigenvector_value_as_attribute(k=2)\n</code></pre> <p>Adds the k-th eigenvector's values as a node attribute to the graph.</p> <p>This method assigns the values of the specified eigenvector from the precomputed eigenvector matrix <code>keigenvec</code> to the nodes of the graph. The attribute is stored under the name <code>'eigenvector_k'</code>, where <code>k</code> corresponds to the specified eigenvector index. It is required that the graph spectrum has been computed prior to using this method; otherwise, it will prompt the user to compute the spectrum.</p> <p>Parameters:</p> <ul> <li> <code>k</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>Index of the eigenvector to be added as a node attribute, starting from 1. Defaults to 2. Must be in the range of available eigenvectors in the precomputed eigenvector matrix <code>keigenvec</code>.</p> </li> </ul> Notes <p>This method modifies the graph in place by assigning the eigenvector values as node attributes. The spectrum of the graph must be computed before using this method, and the computed eigenvector matrix should be stored in the <code>keigenvec</code> attribute of the instance.</p> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def add_eigenvector_value_as_attribute(self, k=2):\n    \"\"\"Adds the k-th eigenvector's values as a node attribute to the graph.\n\n    This method assigns the values of the specified eigenvector from the\n    precomputed eigenvector matrix `keigenvec` to the nodes of the graph. The\n    attribute is stored under the name `'eigenvector_k'`, where `k` corresponds\n    to the specified eigenvector index. It is required that the graph spectrum\n    has been computed prior to using this method; otherwise, it will prompt\n    the user to compute the spectrum.\n\n    Parameters\n    ----------\n    k : int, optional\n        Index of the eigenvector to be added as a node attribute, starting\n        from 1. Defaults to 2. Must be in the range of available eigenvectors\n        in the precomputed eigenvector matrix `keigenvec`.\n\n    Notes\n    -----\n    This method modifies the graph in place by assigning the eigenvector values\n    as node attributes. The spectrum of the graph must be computed before using\n    this method, and the computed eigenvector matrix should be stored in the\n    `keigenvec` attribute of the instance.\n    \"\"\"\n    if self.keigenvec is None:\n        print(\"Compute the graph spectrum first !\")\n\n    node_eigenvector_values = dict(zip(self.nodes(), np.transpose(self.keigenvec[:, k - 1])))\n    nx.set_node_attributes(self, node_eigenvector_values, 'eigenvector_' + str(k))\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.add_gradient_of_fiedler_vector_as_attribute","title":"add_gradient_of_fiedler_vector_as_attribute","text":"<pre><code>add_gradient_of_fiedler_vector_as_attribute()\n</code></pre> <p>Adds the gradient of the Fiedler vector for each node as a node attribute.</p> <p>This method computes the gradient of the Fiedler vector and assigns it to a new node attribute called 'gradient_of_fiedler_vector' for all nodes in the graph. The gradient is given as a dictionary where the keys are node identifiers and the values are the gradient values corresponding to those nodes. This information can be useful for analyzing the structural properties of the graph.</p> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>This method does not return any value. It modifies the graph in place by adding a new node attribute.</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def add_gradient_of_fiedler_vector_as_attribute(self):\n    \"\"\"Adds the gradient of the Fiedler vector for each node as a node attribute.\n\n    This method computes the gradient of the Fiedler vector and assigns it to a\n    new node attribute called 'gradient_of_fiedler_vector' for all nodes in the graph.\n    The gradient is given as a dictionary where the keys are node identifiers and\n    the values are the gradient values corresponding to those nodes. This information\n    can be useful for analyzing the structural properties of the graph.\n\n    Returns\n    -------\n    None\n        This method does not return any value. It modifies the graph in place by\n        adding a new node attribute.\n    \"\"\"\n    node_gradient_fiedler_values = dict(zip(self.nodes(), np.transpose(self.gradient_on_fiedler)))\n    nx.set_node_attributes(self, node_gradient_fiedler_values, 'gradient_of_fiedler_vector')\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.clustering_by_fiedler","title":"clustering_by_fiedler","text":"<pre><code>clustering_by_fiedler(method='agglomerative', number_of_clusters=2, criteria=[], name_attribute='clustering_label')\n</code></pre> <p>Performs clustering on a graph using the specified method and criteria.</p> <p>This method applies clustering techniques to a graph using a given method (either 'agglomerative' or 'optics') based on the provided criteria. For the 'agglomerative' method, the graph's adjacency matrix is used as the connectivity constraint. The clustering labels generated are stored as node attributes within the graph.</p> <p>Parameters:</p> <ul> <li> <code>method</code>               (<code>str</code>, default:                   <code>'agglomerative'</code> )           \u2013            <p>The clustering method to be used. Accepted values are 'agglomerative' and 'optics'. Default is 'agglomerative'.</p> </li> <li> <code>number_of_clusters</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>The number of clusters to be formed. Only applicable when the method is 'agglomerative'. Default is 2.</p> </li> <li> <code>criteria</code>               (<code>list</code>, default:                   <code>[]</code> )           \u2013            <p>The criteria or feature matrix used as input for the clustering algorithm.</p> </li> <li> <code>name_attribute</code>               (<code>str</code>, default:                   <code>'clustering_label'</code> )           \u2013            <p>The attribute name to store the clustering labels in the graph nodes. Default is 'clustering_label'.</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def clustering_by_fiedler(self, method='agglomerative', number_of_clusters=2, criteria=[],\n                          name_attribute='clustering_label'):\n    \"\"\"Performs clustering on a graph using the specified method and criteria.\n\n    This method applies clustering techniques to a graph using a given method\n    (either 'agglomerative' or 'optics') based on the provided criteria. For\n    the 'agglomerative' method, the graph's adjacency matrix is used as the\n    connectivity constraint. The clustering labels generated are stored as\n    node attributes within the graph.\n\n    Parameters\n    ----------\n    method : str, optional\n        The clustering method to be used. Accepted values are 'agglomerative'\n        and 'optics'. Default is 'agglomerative'.\n    number_of_clusters : int, optional\n        The number of clusters to be formed. Only applicable when the method\n        is 'agglomerative'. Default is 2.\n    criteria : list\n        The criteria or feature matrix used as input for the clustering algorithm.\n    name_attribute : str, optional\n        The attribute name to store the clustering labels in the graph nodes.\n        Default is 'clustering_label'.\n\n    \"\"\"\n    X = criteria\n\n    if method == 'agglomerative':\n        A = nx.adjacency_matrix(self)\n        clustering = skc.AgglomerativeClustering(affinity='euclidean', connectivity=A, linkage='ward',\n                                                 n_clusters=number_of_clusters).fit(X)\n    if method == 'optics':\n        clustering = skc.OPTICS(min_samples=100).fit(X)\n\n    clustering_labels = clustering.labels_[:, np.newaxis]\n    for i in range(len(self.nodes)):\n        self.nodes[i][name_attribute] = clustering_labels[i]\n    self.clustering_labels\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.clustering_by_fiedler_and_agglomerative","title":"clustering_by_fiedler_and_agglomerative","text":"<pre><code>clustering_by_fiedler_and_agglomerative(number_of_clusters=2, criteria=[])\n</code></pre> <p>Clusters the nodes of the graph using Fiedler embeddings and an agglomerative clustering algorithm.</p> <p>This method applies the adjacency matrix of the graph to create clusters of nodes based on their similarity or proximity as determined by the provided <code>criteria</code>.</p> <p>Parameters:</p> <ul> <li> <code>number_of_clusters</code>               (<code>int</code>, default:                   <code>2</code> )           \u2013            <p>The number of clusters to form. Defaults to 2.</p> </li> <li> <code>criteria</code>               (<code>array - like</code>, default:                   <code>[]</code> )           \u2013            <p>The attributes or features of the nodes, which are used to compute the clustering.</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def clustering_by_fiedler_and_agglomerative(self, number_of_clusters=2, criteria=[]):\n    \"\"\"Clusters the nodes of the graph using Fiedler embeddings and an agglomerative clustering algorithm.\n\n    This method applies the adjacency matrix of the graph to create clusters of\n    nodes based on their similarity or proximity as determined by the provided `criteria`.\n\n    Parameters\n    ----------\n    number_of_clusters : int, optional\n        The number of clusters to form. Defaults to 2.\n    criteria : array-like\n        The attributes or features of the nodes, which are used to compute the clustering.\n    \"\"\"\n    A = nx.adjacency_matrix(self)\n    X = criteria\n    clustering = skc.AgglomerativeClustering(affinity='euclidean', connectivity=A, linkage='ward',\n                                             n_clusters=number_of_clusters).fit(X)\n\n    node_clustering_label = dict(zip(self.nodes(), np.transpose(clustering.labels_)))\n    nx.set_node_attributes(self, node_clustering_label, 'clustering_labels')\n    self.clustering_labels = clustering.labels_[:, np.newaxis]\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.clustering_by_fiedler_and_optics","title":"clustering_by_fiedler_and_optics","text":"<pre><code>clustering_by_fiedler_and_optics(criteria=[])\n</code></pre> <p>Clusters data points using Fiedler vector and OPTICS algorithm.</p> <p>This method applies the OPTICS clustering algorithm with a specified minimum number of samples (min_samples=100) on the given input criteria. The computed clustering labels are then used to assign an 'optics_label' to each node in the object's nodes list.</p> <p>Parameters:</p> <ul> <li> <code>criteria</code>               (<code>list</code>, default:                   <code>[]</code> )           \u2013            <p>A list of criteria representing data points, typically required by the OPTICS clustering algorithm for analysis and computation. Each element in the list corresponds to a feature vector representing a node.</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def clustering_by_fiedler_and_optics(self, criteria=[]):\n    \"\"\"Clusters data points using Fiedler vector and OPTICS algorithm.\n\n    This method applies the OPTICS clustering algorithm with a specified minimum number of samples\n    (min_samples=100) on the given input criteria. The computed clustering labels are then\n    used to assign an 'optics_label' to each node in the object's nodes list.\n\n    Parameters\n    ----------\n    criteria : list, optional\n        A list of criteria representing data points, typically required by the OPTICS clustering\n        algorithm for analysis and computation. Each element in the list corresponds to a feature\n        vector representing a node.\n    \"\"\"\n    X = criteria\n    clustering = skc.OPTICS(min_samples=100).fit(X)\n    clustering_labels = clustering.labels_[:, np.newaxis]\n    for i in range(len(self.nodes)):\n        self.nodes[i]['optics_label'] = clustering_labels[i]\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.clustering_by_kmeans_using_gradient_norm","title":"clustering_by_kmeans_using_gradient_norm","text":"<pre><code>clustering_by_kmeans_using_gradient_norm(export_in_labeled_point_cloud=False, number_of_clusters=4)\n</code></pre> <p>Performs K-means clustering on the gradient norm of the graph's Fiedler vector.</p> <p>This method applies the K-means clustering algorithm to nodes of a graph, based on their gradient norm values calculated on the graph's Fiedler vector. The number of clusters and the option to export the clustering results in a labeled point cloud file are configurable. The method also stores the clustering labels as node attributes in the graph.</p> <p>Parameters:</p> <ul> <li> <code>export_in_labeled_point_cloud</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, exports the clustering labels into a labeled point cloud file named 'kmeans_clusters.txt'. Defaults to False.</p> </li> <li> <code>number_of_clusters</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>The number of clusters to create using K-means. Defaults to 4.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>The coordinates of the cluster centers as determined by K-means.</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def clustering_by_kmeans_using_gradient_norm(self, export_in_labeled_point_cloud=False, number_of_clusters=4):\n    \"\"\"Performs K-means clustering on the gradient norm of the graph's Fiedler vector.\n\n    This method applies the K-means clustering algorithm to nodes of a graph,\n    based on their gradient norm values calculated on the graph's Fiedler\n    vector. The number of clusters and the option to export the clustering\n    results in a labeled point cloud file are configurable. The method also\n    stores the clustering labels as node attributes in the graph.\n\n    Parameters\n    ----------\n    export_in_labeled_point_cloud : bool, optional\n        If True, exports the clustering labels into a labeled point cloud\n        file named 'kmeans_clusters.txt'. Defaults to False.\n    number_of_clusters : int, optional\n        The number of clusters to create using K-means. Defaults to 4.\n\n    Returns\n    -------\n    numpy.ndarray\n        The coordinates of the cluster centers as determined by K-means.\n    \"\"\"\n    kmeans = skc.KMeans(n_clusters=number_of_clusters, init='k-means++', n_init=20, max_iter=300, tol=0.0001).fit(\n        self.gradient_on_fiedler)\n\n    if export_in_labeled_point_cloud is True:\n        export_anything_on_point_cloud(self, attribute=kmeans.labels_[:, np.newaxis],\n                                       filename='kmeans_clusters.txt')\n\n    kmeans_labels = kmeans.labels_[:, np.newaxis]\n    self.kmeans_labels_gradient = kmeans_labels\n\n    kmeans_labels_gradient_dict = dict(\n        zip(np.asarray(self.nodes()), np.transpose(np.asarray(self.kmeans_labels_gradient))[0]))\n    nx.set_node_attributes(self, kmeans_labels_gradient_dict, 'kmeans_labels')\n\n    return kmeans.cluster_centers_\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.compute_angles_from_gradient_directions","title":"compute_angles_from_gradient_directions","text":"<pre><code>compute_angles_from_gradient_directions(angle_computed='angle_max')\n</code></pre> <p>Computes and assigns a specified statistical value derived from gradient direction angles between a node and its neighbors to each node in the graph.</p> <p>The computation is performed based on the gradient direction of the current node and its neighbors. The user can specify the statistical value to be computed from the angles, such as maximum, mean, variance, standard deviation, or median.</p> <p>Parameters:</p> <ul> <li> <code>angle_computed</code>               (<code>str</code>, default:                   <code>'angle_max'</code> )           \u2013            <p>The type of statistical value to compute from the gradient direction angles. Acceptable values are: - 'angle_max': Maximum angle among all neighbors. - 'angle_mean': Mean of the angles. - 'angle_variance': Variance of the angles. - 'angle_standard_deviation': Standard deviation of the angles. - 'angle_median': Median of the angles. Default is 'angle_max'.</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def compute_angles_from_gradient_directions(self, angle_computed='angle_max'):\n    \"\"\"\n    Computes and assigns a specified statistical value derived from gradient direction angles\n    between a node and its neighbors to each node in the graph.\n\n    The computation is performed based on the gradient direction of the current node\n    and its neighbors. The user can specify the statistical value to be computed\n    from the angles, such as maximum, mean, variance, standard deviation, or median.\n\n    Parameters\n    ----------\n    angle_computed : str, optional\n        The type of statistical value to compute from the gradient direction angles.\n        Acceptable values are:\n        - 'angle_max': Maximum angle among all neighbors.\n        - 'angle_mean': Mean of the angles.\n        - 'angle_variance': Variance of the angles.\n        - 'angle_standard_deviation': Standard deviation of the angles.\n        - 'angle_median': Median of the angles.\n        Default is 'angle_max'.\n    \"\"\"\n    for u in self.nodes:\n        self.nodes[u][angle_computed] = 0\n\n    for i in self.nodes:\n        angles = []\n        for v in self[i]:\n            angle = utilsangle.angle(self.nodes[i]['direction_gradient'], self.nodes[v]['direction_gradient'],\n                                     degree=True)\n            angles.append(angle)\n        if angle_computed == 'angle_max':\n            print(max(angles))\n            self.nodes[i][angle_computed] = max(angles)\n        elif angle_computed == 'angle_mean':\n            self.nodes[i][angle_computed] = sum(angles) / len(angles)\n        elif angle_computed == 'angle_variance':\n            # mean = sum(angles) / len(angles)\n            # self.nodes[i][angle_computed] = sum ((a - mean) ** 2 for a in angles) / len(angles)\n            self.nodes[i][angle_computed] = np.var(angles)\n        elif angle_computed == 'angle_standard_deviation':\n            self.nodes[i][angle_computed] = st.stdev(angles)\n            # mean = sum(angles) / len(angles)\n            # self.nodes[i][angle_computed] = np.sqrt(sum((a - mean) ** 2 for a in angles) / len(angles))\n        elif angle_computed == 'angle_median':\n            self.nodes[i][angle_computed] = st.median(angles)\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.compute_gradient_of_fiedler_vector","title":"compute_gradient_of_fiedler_vector","text":"<pre><code>compute_gradient_of_fiedler_vector(method='simple')\n</code></pre> <p>Computes the gradient of the Fiedler vector for a graph using various methods.</p> <p>The Fiedler vector is used for a variety of graph analysis tasks, including spectral clustering and structure discovery. The gradient is computed based on adjacency relationships and associated weights depending on the chosen method.</p> <p>Parameters:</p> <ul> <li> <code>method</code>               (<code>str</code>, default:                   <code>'simple'</code> )           \u2013            <p>The method to compute the gradient of the Fiedler vector. It supports the following options: - 'simple': Computes the gradient as the difference between the maximum and minimum values of   the Fiedler vector in the neighborhood of each node. - 'simple_divided_by_distance': Computes the same as 'simple', but normalizes the gradient   values by the Euclidean distance between nodes corresponding to the maximum and minimum   values in the neighborhood. - 'simple_divided_by_distance_along_edges': Normalizes the gradient by summing Euclidean   distances along edges linking the nodes with the maximum, minimum, and central (current node)   Fiedler values. - 'by_laplacian_matrix_on_fiedler_signal': Uses the graph Laplacian matrix to compute the   gradient directly on the Fiedler vector. - 'by_weight': Computes the gradient using edge weights and Fiedler values. - 'by_fiedler_weight': Computes the gradient as the weighted difference of positional   displacements and Fiedler values between neighboring nodes.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an unsupported method is provided.</p> </li> <li> <code>AttributeError</code>             \u2013            <p>If any required attributes such as <code>keigenvec</code>, <code>nodes_coords</code>, or <code>laplacian</code> is missing on the object or improperly initialized.</p> </li> </ul> Notes <p>This function modifies several instance attributes, including: - <code>gradient_on_fiedler</code>: Stores the computed gradient tensor for the Fiedler vector. - <code>direction_gradient_on_fiedler_scaled</code>: Stores the normalized direction vectors of the computed   gradient for each node. - Direction gradient as an added attribute on the object.</p> <p>This function requires the graph to be represented in a NetworkX-compatible adjacency matrix or with node and edge attributes such as positional coordinates or weight information. Different methods may involve additional computational costs; for instance, distance-based normalizations loop over nodes and their neighborhoods, which could be computationally expensive for dense graphs.</p> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def compute_gradient_of_fiedler_vector(self, method='simple'):\n    \"\"\"Computes the gradient of the Fiedler vector for a graph using various methods.\n\n    The Fiedler vector is used for a variety of graph analysis tasks, including spectral clustering\n    and structure discovery.\n    The gradient is computed based on adjacency relationships and associated weights depending on the\n    chosen method.\n\n    Parameters\n    ----------\n    method : str, optional\n        The method to compute the gradient of the Fiedler vector. It supports the following options:\n        - 'simple': Computes the gradient as the difference between the maximum and minimum values of\n          the Fiedler vector in the neighborhood of each node.\n        - 'simple_divided_by_distance': Computes the same as 'simple', but normalizes the gradient\n          values by the Euclidean distance between nodes corresponding to the maximum and minimum\n          values in the neighborhood.\n        - 'simple_divided_by_distance_along_edges': Normalizes the gradient by summing Euclidean\n          distances along edges linking the nodes with the maximum, minimum, and central (current node)\n          Fiedler values.\n        - 'by_laplacian_matrix_on_fiedler_signal': Uses the graph Laplacian matrix to compute the\n          gradient directly on the Fiedler vector.\n        - 'by_weight': Computes the gradient using edge weights and Fiedler values.\n        - 'by_fiedler_weight': Computes the gradient as the weighted difference of positional\n          displacements and Fiedler values between neighboring nodes.\n\n    Raises\n    ------\n    ValueError\n        If an unsupported method is provided.\n    AttributeError\n        If any required attributes such as `keigenvec`, `nodes_coords`, or `laplacian` is missing on\n        the object or improperly initialized.\n\n    Notes\n    -----\n    This function modifies several instance attributes, including:\n    - `gradient_on_fiedler`: Stores the computed gradient tensor for the Fiedler vector.\n    - `direction_gradient_on_fiedler_scaled`: Stores the normalized direction vectors of the computed\n      gradient for each node.\n    - Direction gradient as an added attribute on the object.\n\n    This function requires the graph to be represented in a NetworkX-compatible adjacency matrix or with\n    node and edge attributes such as positional coordinates or weight information. Different methods\n    may involve additional computational costs; for instance, distance-based normalizations loop over\n    nodes and their neighborhoods, which could be computationally expensive for dense graphs.\n\n    \"\"\"\n    if method != 'by_fiedler_weight':\n        A = nx.adjacency_matrix(self).astype(float)\n        vp2 = np.asarray(self.keigenvec[:, 1])\n\n        vp2_matrix = A.copy()\n        vp2_matrix[A.nonzero()] = vp2[A.nonzero()[1]]\n\n        if method == 'simple':\n            node_neighbor_max_vp2_node = np.array(\n                [vp2_matrix[node].indices[np.argmax(vp2_matrix[node].data)] for node in range(A.shape[0])])\n            node_neighbor_min_vp2_node = np.array(\n                [vp2_matrix[node].indices[np.argmin(vp2_matrix[node].data)] for node in range(A.shape[0])])\n\n            # Second method fo gradient, just obtain the max and min value in the neighborhood.\n            node_neighbor_max_vp2 = np.array([vp2_matrix[node].data.max() for node in range(A.shape[0])])\n            node_neighbor_min_vp2 = np.array([vp2_matrix[node].data.min() for node in range(A.shape[0])])\n            vp2grad = node_neighbor_max_vp2 - node_neighbor_min_vp2\n\n            # First method not adapted to big clouds\n            # node_neighbor_max_vp2 = np.array([vp2[A[node].nonzero()[1]].max() for node in range(A.shape[0])])\n            # node_neighbor_min_vp2 = np.array([vp2[A[node].nonzero()[1]].min() for node in range(A.shape[0])])\n\n        if method == 'simple_divided_by_distance':\n            node_neighbor_max_vp2_node = np.array(\n                [vp2_matrix[node].indices[np.argmax(vp2_matrix[node].data)] for node in range(A.shape[0])])\n            node_neighbor_max_vp2 = np.array([vp2_matrix[node, neighbor_max_node] for node, neighbor_max_node in\n                                              zip(range(A.shape[0]), node_neighbor_max_vp2_node)])\n\n            node_neighbor_min_vp2_node = np.array(\n                [vp2_matrix[node].indices[np.argmin(vp2_matrix[node].data)] for node in range(A.shape[0])])\n            node_neighbor_min_vp2 = np.array([vp2_matrix[node, neighbor_min_node] for node, neighbor_min_node in\n                                              zip(range(A.shape[0]), node_neighbor_min_vp2_node)])\n\n            pcdtab = self.nodes_coords\n            vp2_max_min = (node_neighbor_max_vp2 - node_neighbor_min_vp2)\n\n            grad_weight = np.zeros(node_neighbor_min_vp2_node.shape[0])\n            for i in range(node_neighbor_min_vp2_node.shape[0]):\n                grad_weight[i] = sp.spatial.distance.euclidean(pcdtab[node_neighbor_max_vp2_node[i]].reshape(1, 3),\n                                                               pcdtab[node_neighbor_min_vp2_node[i]].reshape(1, 3))\n\n            vp2grad = np.divide(vp2_max_min, grad_weight)\n\n        if method == 'simple_divided_by_distance_along_edges':\n            node_neighbor_max_vp2_node = np.array(\n                [vp2_matrix[node].indices[np.argmax(vp2_matrix[node].data)] for node in range(A.shape[0])])\n            node_neighbor_max_vp2 = np.array([vp2_matrix[node, neighbor_max_node] for node, neighbor_max_node in\n                                              zip(range(A.shape[0]), node_neighbor_max_vp2_node)])\n\n            node_neighbor_min_vp2_node = np.array(\n                [vp2_matrix[node].indices[np.argmin(vp2_matrix[node].data)] for node in range(A.shape[0])])\n            node_neighbor_min_vp2 = np.array([vp2_matrix[node, neighbor_min_node] for node, neighbor_min_node in\n                                              zip(range(A.shape[0]), node_neighbor_min_vp2_node)])\n\n            pcdtab = self.nodes_coords\n            vp2_max_min = (node_neighbor_max_vp2 - node_neighbor_min_vp2)\n\n            grad_weight = np.zeros(node_neighbor_min_vp2_node.shape[0])\n            for i in range(node_neighbor_min_vp2_node.shape[0]):\n                grad_weight[i] = sp.spatial.distance.euclidean(pcdtab[node_neighbor_max_vp2_node[i]].reshape(1, 3),\n                                                               pcdtab[i].reshape(1, 3)) + \\\n                                 sp.spatial.distance.euclidean(pcdtab[i].reshape(1, 3),\n                                                               pcdtab[node_neighbor_min_vp2_node[i]].reshape(1, 3))\n\n            vp2grad = np.divide(vp2_max_min, grad_weight)\n\n        if method == 'by_laplacian_matrix_on_fiedler_signal':\n            vp2grad = self.laplacian.dot(vp2)\n\n        if method == 'by_weight':\n            node_neighbor_max_vp2_node = np.array(\n                [vp2_matrix[node].indices[np.argmax(vp2_matrix[node].data)] for node in range(A.shape[0])])\n            node_neighbor_max_vp2 = np.array([vp2_matrix[node, neighbor_max_node] for node, neighbor_max_node in\n                                              zip(range(A.shape[0]), node_neighbor_max_vp2_node)])\n\n            node_neighbor_min_vp2_node = np.array(\n                [vp2_matrix[node].indices[np.argmin(vp2_matrix[node].data)] for node in range(A.shape[0])])\n            node_neighbor_min_vp2 = np.array([vp2_matrix[node, neighbor_min_node] for node, neighbor_min_node in\n                                              zip(range(A.shape[0]), node_neighbor_min_vp2_node)])\n\n            wmax = np.zeros(node_neighbor_min_vp2.shape)\n            wmin = np.zeros(node_neighbor_max_vp2.shape)\n\n            for i in range(node_neighbor_min_vp2_node.shape[0]):\n                print(i)\n                wmax[i] = G.edges[node_neighbor_max_vp2_node[i], i]['weight']\n                print(wmax[i])\n                wmin[i] = G.edges[i, node_neighbor_min_vp2_node[i]]['weight']\n                print(wmin[i])\n\n            vp2grad = np.divide((wmin * node_neighbor_max_vp2[i] - wmax * node_neighbor_min_vp2[i]), wmax + wmin)\n\n        self.gradient_on_fiedler = vp2grad[:, np.newaxis]\n        self.direction_gradient_on_fiedler_scaled = create_normalized_vector_field(node_neighbor_max_vp2_node,\n                                                                                   node_neighbor_min_vp2_node,\n                                                                                   self.nodes_coords)\n        self.add_anything_as_attribute(self.direction_gradient_on_fiedler_scaled, 'direction_gradient')\n\n    else:\n        if method == 'by_fiedler_weight':\n            vp2grad = np.zeros((len(self), 1))\n            vp2dir = np.zeros((len(self), 3))\n            line = 0\n            for n in self.nodes:\n                grad = 0\n                for v in self[n]:\n                    grad += (self.nodes[n]['eigenvector_2'] - self.nodes[v]['eigenvector_2']) * \\\n                            (self.nodes[n]['pos'] - self.nodes[v]['pos']) / np.linalg.norm(\n                        self.nodes[n]['pos'] - self.nodes[v]['pos'])\n                self.nodes[n]['norm_gradient'] = np.linalg.norm(grad)\n                self.nodes[n]['direction_gradient'] = grad / np.linalg.norm(grad)\n                self.nodes[n]['vector_gradient'] = grad\n                self.nodes[n]['vector_gradient4'] = np.append(self.nodes[n]['direction_gradient'],\n                                                              self.nodes[n]['norm_gradient'])\n                vp2grad[line] = self.nodes[n]['norm_gradient']\n                vp2dir[line, :] = self.nodes[n]['direction_gradient']\n                line += 1\n            self.gradient_on_fiedler = vp2grad\n            self.direction_gradient_on_fiedler_scaled = vp2dir\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.compute_graph_eigenvectors","title":"compute_graph_eigenvectors","text":"<pre><code>compute_graph_eigenvectors(is_sparse=True, k=50, smallest_first=True, laplacian_type='classical')\n</code></pre> <p>Computes the eigenvectors of the graph's Laplacian matrix.</p> <p>This method calculates the eigenvalues and eigenvectors of the graph's Laplacian matrix. It uses either a sparse or dense matrix representation based on the input parameters and retains the desired number of smallest or largest eigenvectors as specified. The computed eigenvectors and eigenvalues are stored as attributes of the graph, and the eigenvector values are added as attributes to graph nodes.</p> <p>Before computation, the graph Laplacian is generated if it does not already exist. The <code>graph_spectrum</code> function is used to perform the spectral decomposition. Finally, node attributes are updated using the computed eigenvector values.</p> <p>Parameters:</p> <ul> <li> <code>is_sparse</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Determines if the sparse representation of the graph's Laplacian is used during the computation. If set to True, a sparse implementation is applied. Default is True.</p> </li> <li> <code>k</code>               (<code>int</code>, default:                   <code>50</code> )           \u2013            <p>The number of eigenvalues and eigenvectors to compute. For example, if set to 50, the 50 smallest (or largest) eigenvalues are selected based on the <code>smallest_first</code> parameter. Default is 50.</p> </li> <li> <code>smallest_first</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Indicates whether the k smallest or largest eigenvalues are computed. If True, the k smallest eigenvalues (and corresponding eigenvectors) are computed. Default is True.</p> </li> <li> <code>laplacian_type</code>               (<code>str</code>, default:                   <code>'classical'</code> )           \u2013            <p>The type of graph Laplacian to compute. Options could include \"classical\" or other variations depending on the implementation of <code>compute_graph_laplacian</code> and <code>graph_spectrum</code>. Default is \"classical\".</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def compute_graph_eigenvectors(self, is_sparse=True, k=50, smallest_first=True, laplacian_type='classical'):\n    \"\"\"Computes the eigenvectors of the graph's Laplacian matrix.\n\n    This method calculates the eigenvalues and eigenvectors of the\n    graph's Laplacian matrix. It uses either a sparse or dense matrix representation\n    based on the input parameters and retains the desired number of smallest or largest\n    eigenvectors as specified. The computed eigenvectors and eigenvalues are stored\n    as attributes of the graph, and the eigenvector values are added as attributes\n    to graph nodes.\n\n    Before computation, the graph Laplacian is generated if it does not already\n    exist. The `graph_spectrum` function is used to perform the spectral\n    decomposition. Finally, node attributes are updated using the computed\n    eigenvector values.\n\n    Parameters\n    ----------\n    is_sparse : bool, optional\n        Determines if the sparse representation of the graph's Laplacian is used\n        during the computation. If set to True, a sparse implementation is applied.\n        Default is True.\n    k : int, optional\n        The number of eigenvalues and eigenvectors to compute. For example, if\n        set to 50, the 50 smallest (or largest) eigenvalues are selected based on\n        the `smallest_first` parameter. Default is 50.\n    smallest_first : bool, optional\n        Indicates whether the k smallest or largest eigenvalues are computed. If\n        True, the k smallest eigenvalues (and corresponding eigenvectors) are\n        computed. Default is True.\n    laplacian_type : str, optional\n        The type of graph Laplacian to compute. Options could include \"classical\"\n        or other variations depending on the implementation of `compute_graph_laplacian`\n        and `graph_spectrum`. Default is \"classical\".\n    \"\"\"\n    if self.laplacian is None:\n        self.compute_graph_laplacian(laplacian_type=laplacian_type)\n    keigenval, keigenvec = graph_spectrum(nx.Graph(self), sparse=is_sparse, k=k, smallest_first=smallest_first,\n                                          laplacian_type=laplacian_type, laplacian=self.laplacian)\n    self.keigenvec = keigenvec\n    self.keigenval = keigenval\n\n    self.add_eigenvector_value_as_attribute()\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.compute_graph_laplacian","title":"compute_graph_laplacian","text":"<pre><code>compute_graph_laplacian(laplacian_type='classical')\n</code></pre> <p>Compute the graph Laplacian for the graph object.</p> <p>This method computes the Laplacian matrix of a graph represented by the current object using the specified type of Laplacian. The computed Laplacian differentiate various aspects of graph structure depending upon the <code>laplacian_type</code> parameter value provided.</p> <p>The resulting Laplacian is stored in the <code>laplacian</code> attribute of the object for subsequent graph-based analysis.</p> <p>Parameters:</p> <ul> <li> <code>laplacian_type</code>           \u2013            <p>The type of Laplacian matrix to compute. Default is 'classical'. Other options include normalized or non-standard Laplacians depending on the library capabilities or analysis requirements.</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def compute_graph_laplacian(self, laplacian_type='classical'):\n    \"\"\"Compute the graph Laplacian for the graph object.\n\n    This method computes the Laplacian matrix of a graph represented by the\n    current object using the specified type of Laplacian. The computed Laplacian\n    differentiate various aspects of graph structure depending upon the `laplacian_type`\n    parameter value provided.\n\n    The resulting Laplacian is stored in the `laplacian` attribute of the object\n    for subsequent graph-based analysis.\n\n    Parameters\n    ----------\n    laplacian_type: str, optional\n        The type of Laplacian matrix to compute. Default is 'classical'. Other\n        options include normalized or non-standard Laplacians depending on the\n        library capabilities or analysis requirements.\n    \"\"\"\n    L = graph_laplacian(nx.Graph(self), laplacian_type)\n    self.laplacian = L\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.find_local_extremum_of_Fiedler","title":"find_local_extremum_of_Fiedler","text":"<pre><code>find_local_extremum_of_Fiedler()\n</code></pre> <p>Identifies the nodes in the graph that are local extrema based on the second-smallest eigenvector (Fiedler vector) of the graph's Laplacian matrix.</p> <p>Nodes are compared to their immediate neighbors to determine whether they are local maxima or minima.</p> <p>Attributes:</p> <ul> <li> <code>extrem_local_fiedler</code>               (<code>list</code>)           \u2013            <p>Contains the IDs of nodes identified as local extrema based on the Fiedler vector values. Updated after the function is executed.</p> </li> </ul> Notes <p>Each node in the graph is evaluated by comparing its eigenvector_2 value to those of its neighbors. Nodes are marked as local extrema if their eigenvector_2 value is higher or lower than all of their neighbors. The property <code>extrem_local_Fiedler</code> is updated for each node to indicate its status (1 if it is a local extremum, 0 otherwise).</p> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def find_local_extremum_of_Fiedler(self):\n    \"\"\"Identifies the nodes in the graph that are local extrema based on the second-smallest eigenvector\n    (Fiedler vector) of the graph's Laplacian matrix.\n\n    Nodes are compared to their immediate neighbors to determine whether they are local maxima or minima.\n\n    Attributes\n    ----------\n    extrem_local_fiedler : list\n        Contains the IDs of nodes identified as local extrema based on the\n        Fiedler vector values. Updated after the function is executed.\n\n    Notes\n    -----\n    Each node in the graph is evaluated by comparing its eigenvector_2 value\n    to those of its neighbors. Nodes are marked as local extrema if their\n    eigenvector_2 value is higher or lower than all of their neighbors. The\n    property `extrem_local_Fiedler` is updated for each node to indicate its\n    status (1 if it is a local extremum, 0 otherwise).\n    \"\"\"\n    extrem_local = []\n    for i in self.nodes:\n        self.nodes[i]['extrem_local_Fiedler'] = 0\n        val = self.nodes[i]['eigenvector_2']\n        max = True\n        min = True\n        for vois in self[i]:\n            if self.nodes[vois]['eigenvector_2'] &gt; val:\n                max = False\n            elif self.nodes[vois]['eigenvector_2'] &lt; val:\n                min = False\n        if max or min:\n            extrem_local.append(i)\n            self.nodes[i]['extrem_local_Fiedler'] = 1\n    self.extrem_local_fiedler = extrem_local\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.PointCloudGraph.find_local_minimum_of_gradient_norm","title":"find_local_minimum_of_gradient_norm","text":"<pre><code>find_local_minimum_of_gradient_norm()\n</code></pre> <p>Find and store local minima of the gradient norm in the provided field.</p> <p>This method identifies the elements where the calculated gradient norm is smaller than the minimum gradient norm of their direct neighbors in the field. It then stores these local minima for further processing or usage within the object.</p> Notes <p>The method assumes the object contains a <code>gradient_on_fiedler</code> attribute associated with the relevant gradient values for analysis and an iterable structure to define neighborhood relationships. It updates the <code>min_local</code> attribute upon execution, which stores the identified local minima indices.</p> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def find_local_minimum_of_gradient_norm(self):\n    \"\"\"Find and store local minima of the gradient norm in the provided field.\n\n    This method identifies the elements where the calculated gradient norm\n    is smaller than the minimum gradient norm of their direct neighbors\n    in the field. It then stores these local minima for further\n    processing or usage within the object.\n\n    Notes\n    -----\n    The method assumes the object contains a `gradient_on_fiedler` attribute\n    associated with the relevant gradient values for analysis and an iterable\n    structure to define neighborhood relationships. It updates the `min_local`\n    attribute upon execution, which stores the identified local minima indices.\n    \"\"\"\n    min_local = []\n    for i in self:\n        A = [n for n in self[i]]\n        min_neighborhood = min(self.gradient_on_fiedler[A])\n        gradient_on_point = self.gradient_on_fiedler[i]\n        if gradient_on_point &lt; min_neighborhood:\n            min_local.append(i)\n\n    self.min_local = min_local\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.create_normalized_vector_field","title":"create_normalized_vector_field","text":"<pre><code>create_normalized_vector_field(list_of_max_nodes, list_of_min_nodes, pcd_coordinates)\n</code></pre> <p>Creates a normalized vector field based on input node indices and point cloud coordinates.</p> <p>This function computes vectors between corresponding nodes specified in the list of maximum and minimum nodes using their respective coordinates in the point cloud. The computed vectors are then normalized to unit length using L2 norm.</p> <p>Parameters:</p> <ul> <li> <code>list_of_max_nodes</code>               (<code>list of int</code>)           \u2013            <p>A list containing the indices of the maximum nodes in the point cloud.</p> </li> <li> <code>list_of_min_nodes</code>               (<code>list of int</code>)           \u2013            <p>A list containing the indices of the minimum nodes in the point cloud.</p> </li> <li> <code>pcd_coordinates</code>               (<code>ndarray</code>)           \u2013            <p>A two-dimensional array representing the coordinates of the point cloud. Each row corresponds to a point in the point cloud, and its dimensions are determined by the spatial representation of the data (e.g., 3 for 3D Cartesian coordinates).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A two-dimensional array containing the normalized vectors. Each row corresponds to the normalized vector computed for the respective node pairs from the input lists and the point cloud coordinates. The shape is the same as the number of node pairs, with the dimensionality matching the input point cloud coordinates.</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def create_normalized_vector_field(list_of_max_nodes, list_of_min_nodes, pcd_coordinates):\n    \"\"\"Creates a normalized vector field based on input node indices and point cloud coordinates.\n\n    This function computes vectors between corresponding nodes specified in the list of maximum\n    and minimum nodes using their respective coordinates in the point cloud. The computed\n    vectors are then normalized to unit length using L2 norm.\n\n    Parameters\n    ----------\n    list_of_max_nodes : list of int\n        A list containing the indices of the maximum nodes in the point cloud.\n    list_of_min_nodes : list of int\n        A list containing the indices of the minimum nodes in the point cloud.\n    pcd_coordinates : numpy.ndarray\n        A two-dimensional array representing the coordinates of the point cloud.\n        Each row corresponds to a point in the point cloud, and its dimensions\n        are determined by the spatial representation of the data (e.g., 3 for\n        3D Cartesian coordinates).\n\n    Returns\n    -------\n    numpy.ndarray\n        A two-dimensional array containing the normalized vectors. Each row corresponds\n        to the normalized vector computed for the respective node pairs from the input\n        lists and the point cloud coordinates. The shape is the same as the number of\n        node pairs, with the dimensionality matching the input point cloud coordinates.\n    \"\"\"\n    vectors = pcd_coordinates[list_of_max_nodes] - pcd_coordinates[list_of_min_nodes]\n    # Normalization of the directions\n    vectors_scaled = sk.preprocessing.normalize(vectors, norm='l2')\n\n    return vectors_scaled\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.graph_laplacian","title":"graph_laplacian","text":"<pre><code>graph_laplacian(G, laplacian_type='classical')\n</code></pre> <p>Compute the graph Laplacian matrix of a given graph.</p> <p>This function computes the graph Laplacian matrix of the input graph <code>G</code> based on the specified type. The graph Laplacian is widely used in various graph-based algorithms, such as spectral clustering and network analysis. Depending on the value of <code>laplacian_type</code>, the function returns either the classical graph Laplacian matrix or the simple normalized Laplacian matrix. The computed Laplacian is returned as a sparse matrix.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>The input graph for which the Laplacian matrix is computed. It can be any NetworkX-compatible graph object.</p> </li> <li> <code>laplacian_type</code>               (<code>str</code>, default:                   <code>'classical'</code> )           \u2013            <p>A string specifying the type of graph Laplacian to compute. Accepts either 'classical' or 'simple_normalized'. If 'classical' is passed, the classical unnormalized Laplacian matrix is computed. If 'simple_normalized' is passed, the simple normalized Laplacian matrix is returned.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>csr_matrix</code>           \u2013            <p>The computed Laplacian matrix in Compressed Sparse Row (CSR) format.</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def graph_laplacian(G, laplacian_type='classical'):\n    \"\"\"\n    Compute the graph Laplacian matrix of a given graph.\n\n    This function computes the graph Laplacian matrix of the input graph\n    `G` based on the specified type. The graph Laplacian is widely used in\n    various graph-based algorithms, such as spectral clustering and network\n    analysis. Depending on the value of `laplacian_type`, the function\n    returns either the classical graph Laplacian matrix or the simple\n    normalized Laplacian matrix. The computed Laplacian is returned as a\n    sparse matrix.\n\n    Parameters\n    ----------\n    G : networkx.Graph\n        The input graph for which the Laplacian matrix is computed. It can\n        be any NetworkX-compatible graph object.\n    laplacian_type : str, optional, default='classical'\n        A string specifying the type of graph Laplacian to compute.\n        Accepts either 'classical' or 'simple_normalized'.\n        If 'classical' is passed, the classical unnormalized Laplacian matrix is computed.\n        If 'simple_normalized' is passed, the simple normalized Laplacian matrix is returned.\n\n    Returns\n    -------\n    scipy.sparse.csr_matrix\n        The computed Laplacian matrix in Compressed Sparse Row (CSR) format.\n\n    \"\"\"\n    if laplacian_type == 'classical':\n        L = nx.laplacian_matrix(G, weight='weight')\n    elif laplacian_type == 'simple_normalized':\n        L_normalized_numpyformat = nx.normalized_laplacian_matrix(G, weight='weight')\n        L = spsp.csr_matrix(L_normalized_numpyformat)\n    else:\n        raise Exception(f\"Unknown specified Laplacian type '{laplacian_type}'!\")\n\n    return L\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.graph_spectrum","title":"graph_spectrum","text":"<pre><code>graph_spectrum(G, sparse=True, k=50, smallest_first=True, laplacian_type='classical', laplacian=None)\n</code></pre> <p>Compute the spectrum of a graph using its Laplacian matrix.</p> <p>The function computes eigenvalues and eigenvectors of the graph's Laplacian matrix. It supports both dense and sparse computation methods, and allows control over whether the smallest or largest eigenvalues are computed. The type of Laplacian used can also be specified.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>The input graph for which the spectrum is computed.</p> </li> <li> <code>sparse</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, uses sparse matrix computation for efficiency. Defaults to True.</p> </li> <li> <code>k</code>               (<code>int</code>, default:                   <code>50</code> )           \u2013            <p>The number of eigenvalues and eigenvectors to compute. Defaults to 50.</p> </li> <li> <code>smallest_first</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, computes the smallest eigenvalues first. Defaults to True.</p> </li> <li> <code>laplacian_type</code>               (<code>str</code>, default:                   <code>'classical'</code> )           \u2013            <p>The type of Laplacian matrix to use. Possible values include 'classical'. Defaults to 'classical'.</p> </li> <li> <code>laplacian</code>               (<code>ndarray</code>, default:                   <code>None</code> )           \u2013            <p>Precomputed Laplacian matrix to use instead of computing it internally from the graph <code>G</code>. If None, the Laplacian will be computed based on <code>G</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>Eigenvalues of the Laplacian matrix, as a 1D array.</p> </li> <li> <code>ndarray</code>           \u2013            <p>Eigenvectors of the Laplacian matrix, as a 2D array where each column is an eigenvector.</p> </li> </ul> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def graph_spectrum(G, sparse=True, k=50, smallest_first=True, laplacian_type='classical', laplacian=None):\n    \"\"\"Compute the spectrum of a graph using its Laplacian matrix.\n\n    The function computes eigenvalues and eigenvectors of the graph's Laplacian\n    matrix. It supports both dense and sparse computation methods, and allows\n    control over whether the smallest or largest eigenvalues are computed. The type\n    of Laplacian used can also be specified.\n\n    Parameters\n    ----------\n    G : networkx.Graph\n        The input graph for which the spectrum is computed.\n    sparse : bool, optional\n        If True, uses sparse matrix computation for efficiency. Defaults to True.\n    k : int, optional\n        The number of eigenvalues and eigenvectors to compute. Defaults to 50.\n    smallest_first : bool, optional\n        If True, computes the smallest eigenvalues first. Defaults to True.\n    laplacian_type : str, optional\n        The type of Laplacian matrix to use. Possible values include 'classical'.\n        Defaults to 'classical'.\n    laplacian : numpy.ndarray, optional\n        Precomputed Laplacian matrix to use instead of computing it internally from\n        the graph `G`. If None, the Laplacian will be computed based on `G`.\n\n    Returns\n    -------\n    numpy.ndarray\n        Eigenvalues of the Laplacian matrix, as a 1D array.\n    numpy.ndarray\n        Eigenvectors of the Laplacian matrix, as a 2D array where each column is an eigenvector.\n    \"\"\"\n\n    if laplacian is None:\n        # fonction condens\u00e9e plus efficace en quantit\u00e9 de points :\n        L = graph_laplacian(G, laplacian_type=laplacian_type)\n    else:\n        L = laplacian\n\n    if sparse:\n        Lcsr = spsp.csr_matrix.asfptype(L)\n\n        # k = 50\n        # On pr\u00e9cise que l'on souhaite les k premi\u00e8res valeurs propres directement dans la fonction\n        # Les valeurs propres sont bien class\u00e9es par ordre croissant\n\n        # Calcul des k premiers vecteurs et valeurs propres\n        if smallest_first:\n            keigenval, keigenvec = spsp.linalg.eigsh(Lcsr, k=k, sigma=0, which='LM')\n        else:\n            # TODO check if ordering is ok\n            keigenval, keigenvec = spsp.linalg.eigsh(Lcsr, k=k, which='LM')\n\n    else:\n        keigenval, keigenvec = np.linalg.eigh(L)\n        if not smallest_first:\n            keigenvec = keigenvec[np.argsort(-np.abs(keigenval))]\n            keigenval = keigenval[np.argsort(-np.abs(keigenval))]\n\n    return keigenval, keigenvec\n</code></pre>"},{"location":"reference/spectral_clustering/point_cloud_graph/#spectral_clustering.point_cloud_graph.simple_graph_to_test_methods","title":"simple_graph_to_test_methods","text":"<pre><code>simple_graph_to_test_methods()\n</code></pre> <p>Generate a test graph and perform spectral graph analysis</p> <p>This function creates a simple undirected weighted graph, computes its Laplacian matrix, eigenvalues, and eigenvectors. It also analyzes node-level relationships based on eigenvector components, identifying nodes associated with the maximum and minimum values of specific eigenvector components among their neighbors. Additionally, it retrieves the corresponding weights of these connections.</p> Source code in <code>spectral_clustering/point_cloud_graph.py</code> <pre><code>def simple_graph_to_test_methods():\n    \"\"\"Generate a test graph and perform spectral graph analysis\n\n    This function creates a simple undirected weighted graph, computes its Laplacian\n    matrix, eigenvalues, and eigenvectors. It also analyzes node-level relationships\n    based on eigenvector components, identifying nodes associated with the maximum\n    and minimum values of specific eigenvector components among their neighbors.\n    Additionally, it retrieves the corresponding weights of these connections.\n    \"\"\"\n    G = nx.Graph()\n    G.add_nodes_from([0, 1, 2, 3, 4])\n    G.add_weighted_edges_from([(0, 1, 10), (0, 2, 30), (0, 3, 40), (0, 4, 50), (1, 2, 20), (1, 3, 40), (1, 4, 60)])\n\n    L = nx.laplacian_matrix(G, weight='weight')\n    keigenval, keigenvec = sgk.graph_spectrum(G, k=2)\n\n    A = nx.adjacency_matrix(G).astype(float)\n    vp2 = np.asarray(keigenvec[:, 1])\n    vp2_matrix = A.copy()\n    vp2_matrix[A.nonzero()] = vp2[A.nonzero()[1]]\n\n    node_neighbor_max_vp2_node = np.array(\n        [vp2_matrix[node].indices[np.argmax(vp2_matrix[node].data)] for node in range(A.shape[0])])\n    node_neighbor_max_vp2 = np.array([vp2_matrix[node, neighbor_max_node] for node, neighbor_max_node in\n                                      zip(range(A.shape[0]), node_neighbor_max_vp2_node)])\n\n    node_neighbor_min_vp2_node = np.array(\n        [vp2_matrix[node].indices[np.argmin(vp2_matrix[node].data)] for node in range(A.shape[0])])\n    node_neighbor_min_vp2 = np.array([vp2_matrix[node, neighbor_min_node] for node, neighbor_min_node in\n                                      zip(range(A.shape[0]), node_neighbor_min_vp2_node)])\n\n    wmax = np.zeros(node_neighbor_min_vp2.shape)\n    wmin = np.zeros(node_neighbor_max_vp2.shape)\n\n    for i in range(node_neighbor_min_vp2_node.shape[0]):\n        print(i)\n        wmax[i] = G.edges[node_neighbor_max_vp2_node[i], i]['weight']\n        print(wmax[i])\n        wmin[i] = G.edges[i, node_neighbor_min_vp2_node[i]]['weight']\n        print(wmin[i])\n</code></pre>"},{"location":"reference/spectral_clustering/quotient_graph/","title":"quotient_graph","text":""},{"location":"reference/spectral_clustering/quotient_graph/#spectral_clustering.quotient_graph.QuotientGraph","title":"QuotientGraph","text":"<pre><code>QuotientGraph()\n</code></pre> <p>               Bases: <code>Graph</code></p> <p>Represents a quotient graph derived from a point cloud graph.</p> <p>The <code>QuotientGraph</code> class is designed to create a quotient graph based on the provided point cloud graph structure. The class allows for computation of graph nodes, which are regions derived from clustering in the point cloud graph, and establishes intra-class and inter-class connections with computed weights and labels. Additionally, coordinates of nodes can be derived, representing the geometric center of their respective regions.</p> <p>Attributes:</p> <ul> <li> <code>point_cloud_graph</code>               (<code>PointCloudGraph or None</code>)           \u2013            <p>The underlying point cloud graph associated to this quotient graph.</p> </li> <li> <code>nodes_coordinates</code>               (<code>ndarray or None</code>)           \u2013            <p>Computed coordinates of the nodes within the quotient graph.</p> </li> </ul> Source code in <code>spectral_clustering/quotient_graph.py</code> <pre><code>def __init__(self):\n    super().__init__()\n    # self.seed_colors = None\n    # self.graph_labels_dict = None\n    # self.label_count = None\n    self.point_cloud_graph = None\n    self.nodes_coordinates = None\n</code></pre>"},{"location":"reference/spectral_clustering/quotient_graph/#spectral_clustering.quotient_graph.QuotientGraph.build_from_pointcloudgraph","title":"build_from_pointcloudgraph","text":"<pre><code>build_from_pointcloudgraph(G, labels_from_cluster, region_growing=True)\n</code></pre> <p>Build a quotient graph from a given point cloud graph.</p> <p>Builds a quotient graph from a given point cloud graph based on clustering results and optionally applies a region-growing algorithm to extract connected components made of the same k-means cluster label. The resulting quotient graph nodes represent connected components, while edges represent interactions between these components.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The input point cloud graph where nodes represent points and edges may have associated weights describing relationships between points.</p> </li> <li> <code>labels_from_cluster</code>               (<code>ndarray</code>)           \u2013            <p>An array of labels from the initial clustering (e.g., k-means clustering) where each element corresponds to the cluster label of a graph node.</p> </li> <li> <code>region_growing</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>A flag indicating whether to use a region-growing algorithm to group nodes into connected components based on their k-means cluster labels. If False, connected components are not grown, and nodes are assigned to clusters based on initial cluster labels directly. Default is <code>True</code>.</p> </li> </ul> Source code in <code>spectral_clustering/quotient_graph.py</code> <pre><code>def build_from_pointcloudgraph(self, G, labels_from_cluster, region_growing=True):\n    \"\"\"Build a quotient graph from a given point cloud graph.\n\n    Builds a quotient graph from a given point cloud graph based on clustering results\n    and optionally applies a region-growing algorithm to extract connected components\n    made of the same k-means cluster label. The resulting quotient graph nodes represent\n    connected components, while edges represent interactions between these components.\n\n    Parameters\n    ----------\n    G : spectral_clustering.point_cloud_graph.PointCloudGraph\n        The input point cloud graph where nodes represent points and edges may have\n        associated weights describing relationships between points.\n    labels_from_cluster : numpy.ndarray\n        An array of labels from the initial clustering (e.g., k-means clustering) where\n        each element corresponds to the cluster label of a graph node.\n    region_growing : bool, optional\n        A flag indicating whether to use a region-growing algorithm to group nodes into\n        connected components based on their k-means cluster labels. If False, connected\n        components are not grown, and nodes are assigned to clusters based on initial\n        cluster labels directly.\n        Default is ``True``.\n    \"\"\"\n\n    kmeans_labels = labels_from_cluster\n    connected_component_labels = np.zeros(kmeans_labels.shape, dtype=int)\n    current_cc_size = 0\n    connected_component_size = []\n    seed_kmeans_labels = []\n    # This line has been added to obtain particular colors when the initial clustering is done with four clusters\n    # especially kmeans.\n    lablist = list(kmeans_labels[:])\n    my_count = pd.Series(lablist).value_counts()\n    # if len(my_count) == 4:\n    #     #cluster_colors = ['#0000FF', '#00FF00', '#FFFF00', '#FF0000']\n    #     cluster_colors = ['glasbey_'+str(i) for i in range(len(my_count))]\n    # else:\n    #     jet = cm.get_cmap('jet', len(my_count))\n    #     cluster_colors = jet(range(len(my_count)))\n    #     list_labels = np.unique(lablist).tolist()\n    seed_colors = []\n    label_count = 0\n    visited = np.zeros(kmeans_labels.shape, dtype=int)\n    queue = []\n\n    # Region growing algorithm to extract connected components made of the same k-means class.\n    if region_growing:\n        for i in range(kmeans_labels.shape[0]):\n\n            # Find a seed to initialize the seed fill process.\n\n            if visited[i] == 0:\n                seed = i\n                visited[i] = 1\n                queue.append(i)\n                seed_kmeans_labels.append(kmeans_labels[seed])\n                seed_colors.append('glasbey_' + str(kmeans_labels[seed][0] % 256))\n                # if len(my_count) == 4:\n                #     seed_colors.append(cluster_colors[kmeans_labels[seed][0]])\n                # else:\n                #     seed_colors.append(cluster_colors[list_labels.index(kmeans_labels[seed][0])][:])\n                current_cc_size = 0\n\n                # Region growing from the specified seed.\n\n                while len(queue) != 0:\n\n                    current = queue.pop(0)\n                    connected_component_labels[current] = label_count\n                    current_cc_size += 1\n\n                    for n in G[current]:\n                        if kmeans_labels[n] == kmeans_labels[seed] and visited[n] == 0:\n                            queue.append(n)\n                            visited[n] = 1\n\n                connected_component_size.append(current_cc_size)\n                label_count += 1\n    else:\n        # To correct/finish, it doesn't work for now\n        list_kmeans_labels = [kmeans_labels[i][0] for i in range(len(kmeans_labels))]\n        label_count = len(list(set(list_kmeans_labels)))\n        for i in range(kmeans_labels.shape[0]):\n            seed_colors.append('glasbey_' + str(kmeans_labels[i][0] % 256))\n            seed_kmeans_labels.append(kmeans_labels[i])\n\n    # Create quotient graph nodes.\n\n    self.add_nodes_from(range(label_count))\n\n    node_kmeans_labels_values = dict(\n        zip(np.asarray(self.nodes()), np.transpose(np.asarray(seed_kmeans_labels))[0]))\n    nx.set_node_attributes(self, node_kmeans_labels_values, 'kmeans_labels')\n\n    # Create quotient graph edges.\n\n    intra_edge_weight_sum = np.zeros(label_count, dtype=np.float64)\n    intra_edge_count = np.zeros(label_count, dtype=int)\n\n    for (u, v) in G.edges:\n        a = connected_component_labels[u, 0]\n        b = connected_component_labels[v, 0]\n\n        # Inter-class edge case:\n\n        if a != b:\n            if not self.has_edge(a, b):\n                w = G.edges[u, v]['weight']\n                self.add_edge(a, b, inter_class_edge_weight=w, inter_class_edge_number=1)\n                # nx.set_edge_attributes(self, G.edges[u, v]['weight'], 'inter_class_edge_weight')\n                # self.edges[a, b]['inter_class_edge_weight'] = G.edges[u, v]['weight']\n                # nx.set_edge_attributes(self, 1, 'inter_class_edge_number')\n                # self.edges[a, b]['inter_class_edge_number'] = 1\n            else:\n                self.edges[a, b]['inter_class_edge_weight'] += G.edges[u, v]['weight']\n                self.edges[a, b]['inter_class_edge_number'] += 1\n\n        # Intra-class edge case:\n\n        else:\n            intra_edge_weight_sum[a] += G.edges[u, v]['weight']\n            intra_edge_count[a] += 1\n\n    # Assign to each point cloud graph node the corresponding quotient graph node.\n\n    node_cc = dict(\n        zip(np.asarray(G.nodes()), np.transpose(np.asarray(connected_component_labels))[0]))\n    nx.set_node_attributes(G, node_cc, 'quotient_graph_node')\n\n    nx.set_node_attributes(self, dict(\n        zip(np.asarray(self.nodes()), np.transpose(np.asarray(connected_component_size)))),\n                           'intra_class_node_number')\n\n    nx.set_node_attributes(self, dict(\n        zip(np.asarray(self.nodes()), np.transpose(np.asarray(intra_edge_weight_sum)))), 'intra_class_edge_weight')\n\n    nx.set_node_attributes(self, dict(\n        zip(np.asarray(self.nodes()), np.transpose(np.asarray(intra_edge_count)))), 'intra_class_edge_number')\n\n    # if len(my_count) == 4:\n    #     nx.set_node_attributes(self, dict(\n    #         zip(np.asarray(self.nodes()), np.transpose(np.asarray(seed_colors)))), 'seed_colors')\n    # else:\n    nx.set_node_attributes(self, dict(\n        zip(np.asarray(self.nodes()), seed_colors)), 'seed_colors')\n\n    # self.seed_colors = seed_colors\n    # self.label_count = label_count\n    self.point_cloud_graph = G\n</code></pre>"},{"location":"reference/spectral_clustering/quotient_graph/#spectral_clustering.quotient_graph.QuotientGraph.compute_direction_info","title":"compute_direction_info","text":"<pre><code>compute_direction_info(list_leaves)\n</code></pre> <p>Computes directional gradient information for specific nodes and edges in the graph.</p> <p>This function computes a mean direction gradient for each node in the graph, based on the sum of the direction gradients of the individual nodes that belong to its quotient graph node. Additionally, it calculates the energy dot product for each edge based on the dot product of the mean direction gradients of the connected nodes. Leaves from the specified list are assigned a predefined energy dot product value.</p> <p>Parameters:</p> <ul> <li> <code>list_leaves</code>               (<code>list</code>)           \u2013            <p>A list of nodes that are considered as leaves in the graph. These nodes will have their associated edges assigned a constant energy dot product value.</p> </li> </ul> Source code in <code>spectral_clustering/quotient_graph.py</code> <pre><code>def compute_direction_info(self, list_leaves):\n    \"\"\"Computes directional gradient information for specific nodes and edges in the graph.\n\n    This function computes a mean direction gradient for each node in the graph, based on\n    the sum of the direction gradients of the individual nodes that belong to its quotient\n    graph node. Additionally, it calculates the energy dot product for each edge based\n    on the dot product of the mean direction gradients of the connected nodes. Leaves\n    from the specified list are assigned a predefined energy dot product value.\n\n    Parameters\n    ----------\n    list_leaves : list\n        A list of nodes that are considered as leaves in the graph. These nodes will\n        have their associated edges assigned a constant energy dot product value.\n    \"\"\"\n    G = self.point_cloud_graph\n    for l in self:\n        self.nodes[l]['dir_gradient_mean'] = 0\n        list_of_nodes_in_qnode = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == l]\n        for n in list_of_nodes_in_qnode:\n            self.nodes[l]['dir_gradient_mean'] += G.nodes[n]['direction_gradient']\n        self.nodes[l]['dir_gradient_mean'] /= len(list_of_nodes_in_qnode)\n\n    # take all the edges and compute the dot product between the two cluster\n    for e in self.edges():\n        v1 = self.nodes[e[0]]['dir_gradient_mean']\n        v2 = self.nodes[e[1]]['dir_gradient_mean']\n        if e[0] in list_leaves or e[1] in list_leaves:\n            self.edges[e]['energy_dot_product'] = 4\n        else:\n            dot = v1[0] * v2[0] + v1[1] * v2[1] + v1[2] * v2[2]\n            energy_dot_product = 1 - dot\n            self.edges[e]['energy_dot_product'] = energy_dot_product\n</code></pre>"},{"location":"reference/spectral_clustering/quotient_graph/#spectral_clustering.quotient_graph.QuotientGraph.compute_local_descriptors","title":"compute_local_descriptors","text":"<pre><code>compute_local_descriptors(method='all_qg_cluster', data='coords', neighborhood='radius', scale=10)\n</code></pre> <p>Compute local descriptors for the points in a graph or its quotient graph nodes based on various methods, data types, and neighborhood definitions.</p> <p>This method calculates geometric and structural descriptors such as planarity, linearity, scattering, curvature, and eigenvalues using covariance matrices derived from either the point coordinates or gradient vectors. Depending on the method and data type, the computation is either performed for individual points or for clusters of points belonging to quotient graph nodes.</p> <p>Parameters:</p> <ul> <li> <code>method</code>               (<code>str</code>, default:                   <code>'all_qg_cluster'</code> )           \u2013            <p>Specifies the type of computation to perform. Default is <code>'all_qg_cluster'</code>. Options include:</p> <ul> <li><code>'all_qg_cluster'</code>: Compute descriptors for quotient graph nodes by aggregating information from all points   in a node.</li> <li><code>'each_point'</code>: Compute descriptors for individual points based on their direct neighborhoods.</li> </ul> </li> <li> <code>data</code>               (<code>str</code>, default:                   <code>'coords'</code> )           \u2013            <p>Specifies the type of data on which descriptors are computed. Default is 'coords'. Options include:</p> <ul> <li><code>'coords'</code>: Use the coordinates of points.</li> <li><code>'gradient_vector_fiedler'</code>: Use the gradient vector of the Fiedler eigenvector.</li> </ul> </li> <li> <code>neighborhood</code>               (<code>str</code>, default:                   <code>'radius'</code> )           \u2013            <p>Specifies the neighborhood definition when computing descriptors for individual points. Default is 'radius'. Options include:</p> <ul> <li><code>'radius'</code>: Neighborhood defined by points within a given radius.</li> <li><code>'pointcloudgraph'</code>: Predefined graph-based neighborhood.</li> </ul> </li> <li> <code>scale</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>When 'neighborhood' is set to 'radius', this parameter determines the radius to define the neighborhood. Default is <code>10</code>.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>             \u2013            <p>If an invalid combination of <code>method</code>, <code>data</code>, or <code>neighborhood</code> is provided.</p> </li> <li> <code>KeyError</code>             \u2013            <p>If required attributes are missing in the point cloud graph.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>This method updates nodes in the graph with their computed descriptors as attributes.</p> </li> </ul> Source code in <code>spectral_clustering/quotient_graph.py</code> <pre><code>def compute_local_descriptors(self, method='all_qg_cluster', data='coords', neighborhood='radius', scale=10):\n    \"\"\"\n    Compute local descriptors for the points in a graph or its quotient graph nodes based on various methods, data types, and neighborhood definitions.\n\n    This method calculates geometric and structural descriptors such as planarity, linearity, scattering, curvature, and eigenvalues\n    using covariance matrices derived from either the point coordinates or gradient vectors. Depending on the method and data type, the\n    computation is either performed for individual points or for clusters of points belonging to quotient graph nodes.\n\n    Parameters\n    ----------\n    method : str, optional\n        Specifies the type of computation to perform.\n        Default is ``'all_qg_cluster'``.\n        Options include:\n\n        - ``'all_qg_cluster'``: Compute descriptors for quotient graph nodes by aggregating information from all points\n          in a node.\n        - ``'each_point'``: Compute descriptors for individual points based on their direct neighborhoods.\n    data : str, optional\n        Specifies the type of data on which descriptors are computed.\n        Default is 'coords'.\n        Options include:\n\n        - ``'coords'``: Use the coordinates of points.\n        - ``'gradient_vector_fiedler'``: Use the gradient vector of the Fiedler eigenvector.\n    neighborhood : str, optional\n        Specifies the neighborhood definition when computing descriptors for individual points.\n        Default is 'radius'.\n        Options include:\n\n          - ``'radius'``: Neighborhood defined by points within a given radius.\n          - ``'pointcloudgraph'``: Predefined graph-based neighborhood.\n    scale : int, optional\n        When 'neighborhood' is set to 'radius', this parameter determines the radius to define the neighborhood.\n        Default is ``10``.\n\n    Raises\n    ------\n    ValueError\n        If an invalid combination of `method`, `data`, or `neighborhood` is provided.\n    KeyError\n        If required attributes are missing in the point cloud graph.\n\n    Returns\n    -------\n    None\n        This method updates nodes in the graph with their computed descriptors as attributes.\n    \"\"\"\n    G = self.point_cloud_graph\n    # compute the descriptor for all the point in a quotient graph node\n    if method == 'all_qg_cluster' and data == 'coords':\n        for qnode in self:\n            list_of_nodes_in_qnode = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == qnode]\n            mat = np.zeros((len(list_of_nodes_in_qnode), 3))\n            i = 0\n            for n in list_of_nodes_in_qnode:\n                mat[i] = G.nodes_coords[n]\n                i += 1\n            covmat = np.cov(np.transpose(mat))\n\n            eigenval, eigenvec = np.linalg.eigh(covmat)\n\n            self.nodes[qnode]['planarity'] = (eigenval[1] - eigenval[0]) / eigenval[2]\n            self.nodes[qnode]['planarity2'] = (eigenval[1] - eigenval[0]) / eigenval[1]\n            self.nodes[qnode]['linearity'] = (eigenval[2] - eigenval[1]) / eigenval[2]\n            self.nodes[qnode]['scattering'] = eigenval[0] / eigenval[2]\n            self.nodes[qnode]['curvature_eig'] = eigenval[0] / (eigenval[0] + eigenval[2] + eigenval[1])\n            self.nodes[qnode]['lambda1'] = eigenval[2]\n            self.nodes[qnode]['lambda2'] = eigenval[1]\n            self.nodes[qnode]['lambda3'] = eigenval[0]\n\n    if method == 'each_point' and data == 'coords' and neighborhood == 'radius':\n        # compute a new pointcloudgraph with the neighborhood wanted\n        NewG = sgk.create_riemannian_graph(G.pcd, method=neighborhood, nearest_neighbors=neighborhood, radius=scale)\n\n    if method == 'each_point' and data == 'coords' and neighborhood == 'pointcloudgraph':\n        # compute each descriptor for each point of the point cloud and its neighborhood\n        for p in G:\n            mat = np.zeros((len(G[p]), 3))\n            i = 0\n            for n in G[p]:\n                mat[i] = G.nodes_coords[n]\n                i += 1\n            covmat = np.cov(np.transpose(mat))\n\n            eigenval, eigenvec = np.linalg.eigh(covmat)\n            G.nodes[p]['planarity'] = (eigenval[1] - eigenval[0]) / eigenval[2]\n            G.nodes[p]['linearity'] = (eigenval[2] - eigenval[1]) / eigenval[2]\n            G.nodes[p]['scattering'] = eigenval[0] / eigenval[2]\n            G.nodes[p]['curvature_eig'] = eigenval[0] / (eigenval[0] + eigenval[2] + eigenval[1])\n        # compute mean value for the qnode\n        for qnode in self:\n            list_of_nodes_in_qnode = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == qnode]\n            self.nodes[qnode]['planarity'] = 0\n            self.nodes[qnode]['linearity'] = 0\n            self.nodes[qnode]['scattering'] = 0\n            self.nodes[qnode]['curvature_eig'] = 0\n\n            for n in list_of_nodes_in_qnode:\n                self.nodes[qnode]['planarity'] += G.nodes[n]['planarity']\n                self.nodes[qnode]['linearity'] += G.nodes[n]['linearity']\n                self.nodes[qnode]['scattering'] += G.nodes[n]['scattering']\n                self.nodes[qnode]['curvature_eig'] += G.nodes[n]['curvature_eig']\n            self.nodes[qnode]['planarity'] /= len(list_of_nodes_in_qnode)\n            self.nodes[qnode]['linearity'] /= len(list_of_nodes_in_qnode)\n            self.nodes[qnode]['scattering'] /= len(list_of_nodes_in_qnode)\n            self.nodes[qnode]['curvature_eig'] /= len(list_of_nodes_in_qnode)\n\n    if method == 'all_qg_cluster' and data == 'gradient_vector_fiedler':\n        for qnode in self:\n            list_of_nodes_in_qnode = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == qnode]\n            mat = np.zeros((len(list_of_nodes_in_qnode), 3))\n            i = 0\n            for n in list_of_nodes_in_qnode:\n                mat[i] = G.nodes[n]['direction_gradient']\n                i += 1\n            covmat = np.cov(np.transpose(mat))\n\n            eigenval, eigenvec = np.linalg.eigh(covmat)\n\n            self.nodes[qnode]['max_eigenval'] = eigenval[2]\n            self.nodes[qnode]['planarity'] = (eigenval[1] - eigenval[0]) / eigenval[2]\n            self.nodes[qnode]['linearity'] = (eigenval[2] - eigenval[1]) / eigenval[2]\n            self.nodes[qnode]['scattering'] = eigenval[0] / eigenval[2]\n            self.nodes[qnode]['curvature_eig'] = eigenval[0] / (eigenval[0] + eigenval[2] + eigenval[1])\n</code></pre>"},{"location":"reference/spectral_clustering/quotient_graph/#spectral_clustering.quotient_graph.QuotientGraph.compute_nodes_coordinates","title":"compute_nodes_coordinates","text":"<pre><code>compute_nodes_coordinates()\n</code></pre> <p>Compute and assign average 3D coordinates to nodes in the quotient graph.</p> <p>This function calculates the centroid coordinates for each node in the quotient graph by computing the mean of the coordinates of the corresponding point cloud graph nodes. These coordinates are subsequently stored as an attribute for each node in the quotient graph. It provides a mechanism for visualizing the quotient graph in 3D space.</p> Source code in <code>spectral_clustering/quotient_graph.py</code> <pre><code>def compute_nodes_coordinates(self):\n    \"\"\"Compute and assign average 3D coordinates to nodes in the quotient graph.\n\n    This function calculates the centroid coordinates for each node in the quotient\n    graph by computing the mean of the coordinates of the corresponding point cloud\n    graph nodes. These coordinates are subsequently stored as an attribute for each\n    node in the quotient graph. It provides a mechanism for visualizing the quotient\n    graph in 3D space.\n    \"\"\"\n\n    G = self.point_cloud_graph\n\n    # Calcul de coordonn\u00e9es moyennes pour chaque noeud du graphe quotient, dans le but d'afficher en 3D le graphe.\n    new_classif = np.asarray(list((dict(G.nodes(data='quotient_graph_node')).values())))\n    nodes_coords_moy = np.array([np.mean(G.nodes_coords[new_classif == n], axis=0) for n in self.nodes])\n\n    # import scipy.ndimage as nd\n    # nodes_coords_moy = np.transpose([nd.mean(G.nodes_coords[:,k],\n    #                                          new_classif,\n    #                                          index=list(self.nodes)) for k in range(3)])\n    #\n    # nodes_coords_moy = np.zeros((len(self), 3))\n    # for j, n in enumerate(self.nodes):\n    #     nodes_coords_moy[j] = np.mean(G.nodes_coords[new_classif == n], axis=0)\n    #\n    #     X = []\n    #     Y = []\n    #     Z = []\n    #     for i in range(pcd_attribute.shape[0]):\n    #         if sorted_pcd_attribute_by_quotient_graph_attribute[i, 3] == n:\n    #             X.append(sorted_pcd_attribute_by_quotient_graph_attribute[i, 0])\n    #             Y.append(sorted_pcd_attribute_by_quotient_graph_attribute[i, 1])\n    #             Z.append(sorted_pcd_attribute_by_quotient_graph_attribute[i, 2])\n    #     nodes_coords_moy[j, 0] = np.mean(X)\n    #     nodes_coords_moy[j, 1] = np.mean(Y)\n    #     nodes_coords_moy[j, 2] = np.mean(Z)\n\n    # new_classif = new_classif[:, np.newaxis]\n    # pcd_attribute = np.concatenate([G.nodes_coords, new_classif], axis=1)\n    # sorted_pcd_attribute_by_quotient_graph_attribute = pcd_attribute[np.argsort(pcd_attribute[:, 3])]\n    # nodes_coords_moy = np.zeros((len(self), 3))\n    # j = 0\n    # for n in self.nodes:\n    #     X = []\n    #     Y = []\n    #     Z = []\n    #     for i in range(pcd_attribute.shape[0]):\n    #         if sorted_pcd_attribute_by_quotient_graph_attribute[i, 3] == n:\n    #             X.append(sorted_pcd_attribute_by_quotient_graph_attribute[i, 0])\n    #             Y.append(sorted_pcd_attribute_by_quotient_graph_attribute[i, 1])\n    #             Z.append(sorted_pcd_attribute_by_quotient_graph_attribute[i, 2])\n    #     nodes_coords_moy[j, 0] = np.mean(X)\n    #     nodes_coords_moy[j, 1] = np.mean(Y)\n    #     nodes_coords_moy[j, 2] = np.mean(Z)\n    #     j += 1\n    self.nodes_coordinates = nodes_coords_moy\n\n    for nodes in self.nodes:\n        self.nodes[nodes]['centroide_coordinates'] = np.nan\n    i = 0\n    for nodes in self.nodes:\n        self.nodes[nodes]['centroide_coordinates'] = nodes_coords_moy[i, :]\n        i += 1\n</code></pre>"},{"location":"reference/spectral_clustering/quotient_graph/#spectral_clustering.quotient_graph.QuotientGraph.compute_quotientgraph_metadata_on_a_node_interclass","title":"compute_quotientgraph_metadata_on_a_node_interclass","text":"<pre><code>compute_quotientgraph_metadata_on_a_node_interclass(node)\n</code></pre> <p>Computes metadata for a specific node in the quotient graph while focusing on interclass relationships.</p> <p>This function analyzes the relationships of the node's neighbors that belong to different classes within the quotient graph. It returns a dictionary that counts the occurrences of neighboring nodes belonging to other classes relative to the specified node.</p> <p>Parameters:</p> <ul> <li> <code>node</code>               (<code>any</code>)           \u2013            <p>The node in the quotient graph for which the interclass metadata should be computed.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>           \u2013            <p>A dictionary where the keys are the different classes (quotient graph nodes) and the values are the count of neighboring nodes belonging to those classes.</p> </li> </ul> Notes <p>The function uses the 'quotient_graph_node' attribute of the nodes in the graph to determine the class of each node. Nodes with the same 'quotient_graph_node' value are considered to belong to the same class.</p> Source code in <code>spectral_clustering/quotient_graph.py</code> <pre><code>def compute_quotientgraph_metadata_on_a_node_interclass(self, node):\n    \"\"\"Computes metadata for a specific node in the quotient graph while focusing on interclass relationships.\n\n    This function analyzes the relationships of the node's neighbors that belong to different classes within\n    the quotient graph. It returns a dictionary that counts the occurrences of neighboring nodes belonging\n    to other classes relative to the specified node.\n\n    Parameters\n    ----------\n    node : any\n        The node in the quotient graph for which the interclass metadata should be computed.\n\n    Returns\n    -------\n    dict\n        A dictionary where the keys are the different classes (quotient graph nodes)\n        and the values are the count of neighboring nodes belonging to those classes.\n\n    Notes\n    -----\n    The function uses the 'quotient_graph_node' attribute of the nodes in the graph to determine\n    the class of each node. Nodes with the same 'quotient_graph_node' value are considered to\n    belong to the same class.\n    \"\"\"\n    G = self.point_cloud_graph\n    count = {}\n    for c in self[node]:\n        count[c] = 0\n\n    list_of_nodes_G = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == node]\n    for ng in list_of_nodes_G:\n        for neing in G[ng]:\n            if G.nodes[ng]['quotient_graph_node'] != G.nodes[neing]['quotient_graph_node']:\n                count[G.nodes[neing]['quotient_graph_node']] += 1\n\n    return count\n</code></pre>"},{"location":"reference/spectral_clustering/quotient_graph/#spectral_clustering.quotient_graph.QuotientGraph.compute_silhouette","title":"compute_silhouette","text":"<pre><code>compute_silhouette(method='topological', data='direction_gradient_vector_fiedler')\n</code></pre> <p>Compute the silhouette score for nodes in a point cloud graph based on clustering.</p> <p>This function calculates silhouette scores for each node in a point cloud graph based either on the \"all_qg_cluster\" or \"topological\" approach. The silhouette score is a measure of how similar a node's association to its own cluster is versus its association to neighboring, adjacent clusters. The results are stored in the graph for individual nodes and quotient graph nodes.</p> <p>Parameters:</p> <ul> <li> <code>method</code>               (<code>str</code>, default:                   <code>'topological'</code> )           \u2013            <p>The method used to compute the silhouette score. Acceptable values are 'all_qg_cluster' for traditional silhouette computation or 'topological' for a more nuanced topology-based computation. Default is 'topological'.</p> </li> <li> <code>data</code>               (<code>str</code>, default:                   <code>'direction_gradient_vector_fiedler'</code> )           \u2013            <p>Indicates the data used for silhouette computation. Options are 'direction_gradient_vector_fiedler' or 'norm_gradient_vector_fiedler', determining the specific gradient vector field used in the calculation. Default is 'direction_gradient_vector_fiedler'.</p> </li> </ul> Notes <ul> <li>For the 'all_qg_cluster' method, silhouette scores are based on the classical   approach available in scikit-learn.</li> <li>For the 'topological' method, silhouette calculation considers the dissimilarities   with adjacent clusters only, leveraging adjacency matrices for the computations.</li> <li>The computed silhouette scores are stored directly as node attributes in the   underlying graph.</li> <li>Quotient graph nodes' silhouette scores are computed as the average of individual   nodes within the respective cluster.</li> </ul> Source code in <code>spectral_clustering/quotient_graph.py</code> <pre><code>def compute_silhouette(self, method='topological', data='direction_gradient_vector_fiedler'):\n    \"\"\"Compute the silhouette score for nodes in a point cloud graph based on clustering.\n\n    This function calculates silhouette scores for each node in a point cloud graph\n    based either on the \"all_qg_cluster\" or \"topological\" approach. The silhouette\n    score is a measure of how similar a node's association to its own cluster is\n    versus its association to neighboring, adjacent clusters. The results are stored\n    in the graph for individual nodes and quotient graph nodes.\n\n    Parameters\n    ----------\n    method : str, optional\n        The method used to compute the silhouette score. Acceptable values are\n        'all_qg_cluster' for traditional silhouette computation or 'topological'\n        for a more nuanced topology-based computation. Default is 'topological'.\n    data : str, optional\n        Indicates the data used for silhouette computation. Options are\n        'direction_gradient_vector_fiedler' or 'norm_gradient_vector_fiedler',\n        determining the specific gradient vector field used in the calculation.\n        Default is 'direction_gradient_vector_fiedler'.\n\n    Notes\n    -----\n    - For the 'all_qg_cluster' method, silhouette scores are based on the classical\n      approach available in scikit-learn.\n    - For the 'topological' method, silhouette calculation considers the dissimilarities\n      with adjacent clusters only, leveraging adjacency matrices for the computations.\n    - The computed silhouette scores are stored directly as node attributes in the\n      underlying graph.\n    - Quotient graph nodes' silhouette scores are computed as the average of individual\n      nodes within the respective cluster.\n    \"\"\"\n    G = self.point_cloud_graph\n    label = []\n    for node in G:\n        label.append(G.nodes[node]['quotient_graph_node'])\n\n    if method == 'all_qg_cluster':\n        # this method is based on the classical way to compute silhouette coefficients in the sci-kit learn module\n\n        if data == 'direction_gradient_vector_fiedler':\n            sil = sk.metrics.silhouette_samples(G.direction_gradient_on_fiedler_scaled, label, metric='euclidean')\n        elif data == 'norm_gradient_vector_fiedler':\n            sil = sk.metrics.silhouette_samples(G.gradient_on_fiedler, label, metric='euclidean')\n\n    if method == 'topological':\n        import scipy.ndimage as nd\n        from sklearn.metrics import pairwise_distances_chunked\n        # this method aims at comparing the cluster A of the point considered with the adjacent clusters of A.\n        X = []\n\n        if data == 'direction_gradient_vector_fiedler':\n            X = G.direction_gradient_on_fiedler_scaled\n        elif data == 'norm_gradient_vector_fiedler':\n            X = G.gradient_on_fiedler\n\n        labels = np.array(label)\n\n        label_list = np.array(self.nodes)\n\n        label_adjacency = nx.adjacency_matrix(self).todense().astype('float64')\n        label_adjacency -= 1 * np.eye(len(label_adjacency)).astype('float64')\n\n        label_index = np.array([np.where(label_list == l)[0][0] for l in labels])\n\n        def mean_by_label(D_chunk, start):\n            \"\"\"Computes the mean of data points by label, excluding contributions from the current label.\n\n            This function calculates the per-label mean of a given chunk of data points, while\n            excluding contributions from the label currently being processed. It operates on an\n            input chunk of data and associated labels, aggregating information based on the specified\n            index labels.\n\n            Parameters\n            ----------\n            D_chunk : np.ndarray\n                A chunk of multi-dimensional data points split from the full dataset, where each row\n                represents a data point.\n            start : int\n                The start index for the current chunk of data within the full dataset. Used to\n                correctly align the chunk with the corresponding labels.\n\n            Returns\n            -------\n            np.ndarray\n                An array representing the mean value of data points grouped by label, excluding\n                contributions from the current label. The size of the array matches the provided\n                `D_chunk`.\n            \"\"\"\n            label_mean = []\n            chunk_labels = labels[start:start + len(D_chunk)]\n            for line, label in zip(D_chunk, chunk_labels):\n                label_sum = nd.sum(line, labels, index=label_list)\n                label_count = nd.sum(np.ones_like(labels), labels, index=label_list)\n                label_count -= label_list == label\n                label_mean += [label_sum / label_count]\n            return np.array(label_mean)\n\n        gen = pairwise_distances_chunked(X, reduce_func=mean_by_label)\n\n        start = 0\n        silhouette = []\n        for label_mean_dissimilarity in gen:\n            chunk_label_index = label_index[start:start + len(label_mean_dissimilarity)]\n\n            adjacent_label_mean_dissimilarity = np.copy(label_mean_dissimilarity)\n            adjacent_label_mean_dissimilarity[label_adjacency[chunk_label_index] != 1] = np.nan\n\n            self_label_mean_dissimilarity = np.copy(label_mean_dissimilarity)\n            self_label_mean_dissimilarity[label_adjacency[chunk_label_index] != -1] = np.nan\n\n            intra = np.nanmin(self_label_mean_dissimilarity, axis=1)\n            inter = np.nanmin(adjacent_label_mean_dissimilarity, axis=1)\n\n            silhouette += list((inter - intra) / np.maximum(inter, intra))\n            start += len(label_mean_dissimilarity)\n\n        sil = np.array(silhouette)\n\n    i = 0\n    for node in G:\n        G.nodes[node]['silhouette'] = sil[i]\n        i += 1\n    for qnode in self:\n        list_of_nodes_in_qnode = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == qnode]\n        self.nodes[qnode]['silhouette'] = 0\n        for n in list_of_nodes_in_qnode:\n            self.nodes[qnode]['silhouette'] += G.nodes[n]['silhouette']\n        self.nodes[qnode]['silhouette'] /= len(list_of_nodes_in_qnode)\n</code></pre>"},{"location":"reference/spectral_clustering/quotient_graph/#spectral_clustering.quotient_graph.QuotientGraph.count_local_extremum_of_Fiedler","title":"count_local_extremum_of_Fiedler","text":"<pre><code>count_local_extremum_of_Fiedler()\n</code></pre> <p>Counts the local extrema of the Fiedler vector in the graph associated with each node.</p> <p>The method utilizes a point cloud graph and updates the associated nodes in the graph with the total number of local extrema of the Fiedler vector belonging to their corresponding quotient graph nodes.</p> Source code in <code>spectral_clustering/quotient_graph.py</code> <pre><code>def count_local_extremum_of_Fiedler(self):\n    \"\"\"Counts the local extrema of the Fiedler vector in the graph associated with each node.\n\n    The method utilizes a point cloud graph and updates the associated nodes\n    in the graph with the total number of local extrema of the Fiedler vector\n    belonging to their corresponding quotient graph nodes.\n    \"\"\"\n    G = self.point_cloud_graph\n    G.find_local_extremum_of_Fiedler()\n    for c in self.nodes():\n        self.nodes[c]['number_of_local_Fiedler_extremum'] = 0\n        list_of_nodes_r = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == c]\n        for pt in list_of_nodes_r:\n            self.nodes[c]['number_of_local_Fiedler_extremum'] += G.nodes[pt]['extrem_local_Fiedler']\n</code></pre>"},{"location":"reference/spectral_clustering/quotient_graph/#spectral_clustering.quotient_graph.QuotientGraph.delete_empty_edges_and_nodes","title":"delete_empty_edges_and_nodes","text":"<pre><code>delete_empty_edges_and_nodes()\n</code></pre> <p>Delete edges from the quotient graph that do not represent any edges in the distance-based graph anymore.</p> <p>Delete nodes from the quotient graph that do not represent any nodes of the distance-based graph. Update of the topological structure by removal only.</p> Source code in <code>spectral_clustering/quotient_graph.py</code> <pre><code>def delete_empty_edges_and_nodes(self):\n    \"\"\"Delete edges from the quotient graph that do not represent any edges in the distance-based graph anymore.\n\n    Delete nodes from the quotient graph that do not represent any nodes of the distance-based graph.\n    Update of the topological structure by removal only.\n    \"\"\"\n    to_remove = []\n    list = [e for e in self.edges]\n    for e in list:\n        if self.edges[e[0], e[1]]['inter_class_edge_number'] == 0:\n            to_remove.append(e)\n    print(to_remove)\n    self.remove_edges_from(to_remove)\n    to_remove = []\n    for n in self.nodes:\n        if self.nodes[n]['intra_class_node_number'] == 0:\n            to_remove.append(n)\n    self.remove_nodes_from(to_remove)\n    print(to_remove)\n</code></pre>"},{"location":"reference/spectral_clustering/quotient_graph/#spectral_clustering.quotient_graph.QuotientGraph.ponderate_with_coordinates_of_points","title":"ponderate_with_coordinates_of_points","text":"<pre><code>ponderate_with_coordinates_of_points()\n</code></pre> <p>Computes the weights of edges based on the centroid coordinates of their connected nodes.</p> <p>This method first calculates the coordinates of the centroids for all nodes and then uses these coordinates to calculate the distance between connected nodes in the graph. The calculated distance is stored as an additional weight attribute for each edge.</p> <p>Attributes:</p> <ul> <li> <code>self.nodes</code>               (<code>dict</code>)           \u2013            <p>A dictionary representing graph nodes where keys are node identifiers and values are associated attributes, including 'centroide_coordinates'.</p> </li> <li> <code>self.edges</code>               (<code>dict</code>)           \u2013            <p>A dictionary representing graph edges where keys are tuples of connected node identifiers and values are associated attributes, including the new 'distance_centroides'.</p> </li> </ul> Notes <p>The edge weight 'distance_centroides' is calculated as the Euclidean distance between the centroid coordinates of two nodes connected by the edge.</p> Source code in <code>spectral_clustering/quotient_graph.py</code> <pre><code>def ponderate_with_coordinates_of_points(self):\n    \"\"\"Computes the weights of edges based on the centroid coordinates of their connected nodes.\n\n    This method first calculates the coordinates of the centroids for all nodes and then uses these\n    coordinates to calculate the distance between connected nodes in the graph. The calculated\n    distance is stored as an additional weight attribute for each edge.\n\n    Attributes\n    ----------\n    self.nodes : dict\n        A dictionary representing graph nodes where keys are node identifiers and values are\n        associated attributes, including 'centroide_coordinates'.\n    self.edges : dict\n        A dictionary representing graph edges where keys are tuples of connected node identifiers\n        and values are associated attributes, including the new 'distance_centroides'.\n\n    Notes\n    -----\n    The edge weight 'distance_centroides' is calculated as the Euclidean distance between the\n    centroid coordinates of two nodes connected by the edge.\n    \"\"\"\n    self.compute_nodes_coordinates()\n    # Calcul des poids\n    for e in self.edges:\n        n1 = e[0]\n        n2 = e[1]\n        c1 = self.nodes[n1]['centroide_coordinates']\n        c2 = self.nodes[n2]['centroide_coordinates']\n        dist = np.linalg.norm(c1 - c2)\n        self.edges[e]['distance_centroides'] = dist\n</code></pre>"},{"location":"reference/spectral_clustering/quotient_graph/#spectral_clustering.quotient_graph.QuotientGraph.rebuild","title":"rebuild","text":"<pre><code>rebuild(G, clear=True)\n</code></pre> <p>Rebuilds the internal structure based on the provided graph and its associated data.</p> <p>This method processes the input graph and reinitializes the internal structure. If the <code>clear</code> flag is set to True, any existing data in the internal structure is cleared before rebuilding. The method extracts node attributes from the graph, transforms them into a numpy array, and utilizes this array to rebuild the internal representation from the given graph.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>PointCloudGraph</code>)           \u2013            <p>A graph structure that contains nodes with the attribute 'quotient_graph_node', which is used to rebuild the internal data structure.</p> </li> <li> <code>clear</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If <code>True</code>, clears the current internal structure before rebuilding. Default is <code>True</code>.</p> </li> </ul> Source code in <code>spectral_clustering/quotient_graph.py</code> <pre><code>def rebuild(self, G, clear=True):\n    \"\"\"Rebuilds the internal structure based on the provided graph and its associated data.\n\n    This method processes the input graph and reinitializes the internal structure. If the\n    `clear` flag is set to True, any existing data in the internal structure is cleared\n    before rebuilding. The method extracts node attributes from the graph, transforms them\n    into a numpy array, and utilizes this array to rebuild the internal representation\n    from the given graph.\n\n    Parameters\n    ----------\n    G : spectral_clustering.point_cloud_graph.PointCloudGraph\n        A graph structure that contains nodes with the attribute 'quotient_graph_node', which is\n        used to rebuild the internal data structure.\n    clear : bool, optional\n        If ``True``, clears the current internal structure before rebuilding.\n        Default is ``True``.\n    \"\"\"\n    if clear:\n        self.clear()\n    labels_qg = [k for k in dict(G.nodes(data='quotient_graph_node')).values()]\n    labels_qg_re = np.asarray(labels_qg)[:, np.newaxis]\n    self.build_from_pointcloudgraph(G, labels_qg_re)\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_operations/","title":"quotientgraph_operations","text":""},{"location":"reference/spectral_clustering/quotientgraph_operations/#spectral_clustering.quotientgraph_operations.calculate_leaf_quotients","title":"calculate_leaf_quotients","text":"<pre><code>calculate_leaf_quotients(QG, list_leaves, list_of_linear, root_point_riemanian)\n</code></pre> <p>Calculates leaf quotients for nodes and edges in a graph, updating specific attributes for each.</p> <p>The function processes a quotient graph <code>QG</code> and updates node and edge attributes based on the paths between leaf nodes in <code>list_leaves</code> and a designated <code>root_point_riemanian</code>. For each leaf, the function determines the shortest path (via Dijkstra's algorithm) from the leaf to the root, either through specific nodes in <code>list_of_linear</code> or the entire graph. It updates the 'leaf_quotient_n' and 'leaf_quotient_e' attributes of nodes and edges respectively along the path, storing how many times each is involved in such paths. The function also manages the 'useful_path' attribute for edges.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph represented as a NetworkX graph object. It contains nodes and edges with specific attributes that are updated during the computation.</p> </li> <li> <code>list_leaves</code>               (<code>list</code>)           \u2013            <p>A list of leaf nodes from which paths to the root node will be calculated.</p> </li> <li> <code>list_of_linear</code>               (<code>list</code>)           \u2013            <p>A list of intermediate nodes that may be included in the subgraph for calculating paths.</p> </li> <li> <code>root_point_riemanian</code>               (<code>Any</code>)           \u2013            <p>The root point in the Riemannian space, used to identify the destination node within the quotient graph.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_operations.py</code> <pre><code>def calculate_leaf_quotients(QG, list_leaves, list_of_linear, root_point_riemanian):\n    \"\"\"Calculates leaf quotients for nodes and edges in a graph, updating specific attributes for each.\n\n    The function processes a quotient graph `QG` and updates node and edge attributes based on the paths\n    between leaf nodes in `list_leaves` and a designated `root_point_riemanian`. For each leaf, the function\n    determines the shortest path (via Dijkstra's algorithm) from the leaf to the root, either through specific\n    nodes in `list_of_linear` or the entire graph.\n    It updates the 'leaf_quotient_n' and 'leaf_quotient_e' attributes of nodes and edges respectively along the path,\n    storing how many times each is involved in such paths.\n    The function also manages the 'useful_path' attribute for edges.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph represented as a NetworkX graph object. It contains nodes and edges with\n        specific attributes that are updated during the computation.\n    list_leaves : list\n        A list of leaf nodes from which paths to the root node will be calculated.\n    list_of_linear : list\n        A list of intermediate nodes that may be included in the subgraph for calculating paths.\n    root_point_riemanian : Any\n        The root point in the Riemannian space, used to identify the destination node within the quotient\n        graph.\n\n    \"\"\"\n    G = QG.point_cloud_graph\n    for e in QG.edges:\n        QG.edges[e]['leaf_quotient_e'] = 0\n        QG.edges[e]['useful_path'] = 50\n    for n in QG.nodes:\n        QG.nodes[n]['leaf_quotient_n'] = 0\n\n    for leaf in list_leaves:\n        print(leaf)\n        sub_qg = nx.subgraph(QG, list_of_linear + [leaf] + [G.nodes[root_point_riemanian][\"quotient_graph_node\"]])\n        if nx.has_path(sub_qg, leaf, G.nodes[root_point_riemanian][\"quotient_graph_node\"]):\n            path = nx.dijkstra_path(sub_qg, leaf, G.nodes[root_point_riemanian][\"quotient_graph_node\"],\n                                    weight='distance_centroides')\n        else:\n            print('else')\n            path = nx.dijkstra_path(QG, leaf, G.nodes[root_point_riemanian][\"quotient_graph_node\"],\n                                    weight='distance_centroides')\n            print(path)\n        for n in path:\n            QG.nodes[n]['leaf_quotient_n'] += 1\n        for i in range(len(path) - 1):\n            e = (path[i], path[i + 1])\n            QG.edges[e]['leaf_quotient_e'] += 1\n            QG.edges[e]['useful_path'] = 0\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_operations/#spectral_clustering.quotientgraph_operations.check_connectivity_of_modified_cluster","title":"check_connectivity_of_modified_cluster","text":"<pre><code>check_connectivity_of_modified_cluster(pointcloudgraph, old_cluster, new_cluster, node_to_change)\n</code></pre> <p>Checks the connectivity of the old cluster after a node has been reassigned to a new cluster.</p> <p>When a node is moved from one cluster to another in the distance-based graph, this function verifies whether the old cluster of the node remains connected or gets split into multiple disconnected parts.</p> <p>Parameters:</p> <ul> <li> <code>pointcloudgraph</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The graph representing the point cloud and its connections.</p> </li> <li> <code>old_cluster</code>               (<code>int</code>)           \u2013            <p>The original cluster identifier of the node.</p> </li> <li> <code>new_cluster</code>               (<code>int</code>)           \u2013            <p>The new cluster identifier of the node.</p> </li> <li> <code>node_to_change</code>               (<code>int</code>)           \u2013            <p>The node that has been reassigned to a different cluster.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p><code>True</code> if the old cluster remains connected after the node is reassigned, <code>False</code> otherwise.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_operations.py</code> <pre><code>def check_connectivity_of_modified_cluster(pointcloudgraph, old_cluster, new_cluster, node_to_change):\n    \"\"\"Checks the connectivity of the old cluster after a node has been reassigned to a new cluster.\n\n    When a node is moved from one cluster to another in the distance-based graph, this function verifies\n    whether the old cluster of the node remains connected or gets split into multiple disconnected\n    parts.\n\n    Parameters\n    ----------\n    pointcloudgraph : spectral_clustering.pointcloudgraph.PointCloudGraph\n        The graph representing the point cloud and its connections.\n    old_cluster : int\n        The original cluster identifier of the node.\n    new_cluster : int\n        The new cluster identifier of the node.\n    node_to_change : int\n        The node that has been reassigned to a different cluster.\n\n    Returns\n    -------\n    bool\n        ``True`` if the old cluster remains connected after the node is reassigned, ``False`` otherwise.\n    \"\"\"\n    G = pointcloudgraph\n    # Build a dictionary which associate each node of the PointCloudGraph with its cluster/node in the QuotientGraph\n    d = dict(G.nodes(data='quotient_graph_node', default=None))\n    # Extract points of the old_cluster\n    points_of_interest = [key for (key, value) in d.items() if value == old_cluster]\n    # Handling the case where this cluster has completely disappeared\n    if not points_of_interest:\n        result = True\n    else:\n        # Creation of the subgraph and test\n        subgraph = G.subgraph(points_of_interest)\n        result = nx.is_connected(subgraph)\n\n    return result\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_operations/#spectral_clustering.quotientgraph_operations.collect_quotient_graph_nodes_from_pointcloudpoints","title":"collect_quotient_graph_nodes_from_pointcloudpoints","text":"<pre><code>collect_quotient_graph_nodes_from_pointcloudpoints(quotient_graph, list_of_points=[])\n</code></pre> <p>Collect unique quotient graph nodes corresponding to the given list of point cloud points.</p> <p>This function retrieves the quotient graph nodes associated with the provided points in the point cloud graph. It extracts the nodes from the quotient graph associated with each given point in the graph and eliminates duplicates to return a unique list of quotient graph nodes.</p> <p>Parameters:</p> <ul> <li> <code>quotient_graph</code>               (<code>QuotientGraph</code>)           \u2013            <p>A graph-like data structure with a <code>point_cloud_graph</code> attribute. The <code>point_cloud_graph</code> is expected to have nodes with a <code>quotient_graph_node</code> attribute.</p> </li> <li> <code>list_of_points</code>               (<code>list</code>, default:                   <code>[]</code> )           \u2013            <p>A list of specific point cloud node identifiers whose associated quotient graph nodes need to be collected. Default is an empty list.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>A list of unique quotient graph nodes corresponding to the input point cloud points.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_operations.py</code> <pre><code>def collect_quotient_graph_nodes_from_pointcloudpoints(quotient_graph, list_of_points=[]):\n    \"\"\"Collect unique quotient graph nodes corresponding to the given list of point cloud points.\n\n    This function retrieves the quotient graph nodes associated with the provided points\n    in the point cloud graph. It extracts the nodes from the quotient graph associated\n    with each given point in the graph and eliminates duplicates to return a unique\n    list of quotient graph nodes.\n\n    Parameters\n    ----------\n    quotient_graph : spectral_clustering.quotientgraph.QuotientGraph\n        A graph-like data structure with a `point_cloud_graph` attribute. The\n        `point_cloud_graph` is expected to have nodes with a `quotient_graph_node`\n        attribute.\n    list_of_points : list, optional\n        A list of specific point cloud node identifiers whose associated quotient\n        graph nodes need to be collected. Default is an empty list.\n\n    Returns\n    -------\n    list\n        A list of unique quotient graph nodes corresponding to the input point\n        cloud points.\n    \"\"\"\n    G = quotient_graph.point_cloud_graph\n    listi = []\n    for node in list_of_points:\n        listi.append(G.nodes[node]['quotient_graph_node'])\n\n    list_of_clusters = list(set(listi))\n\n    return list_of_clusters\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_operations/#spectral_clustering.quotientgraph_operations.collect_quotient_graph_nodes_from_pointcloudpoints_majority","title":"collect_quotient_graph_nodes_from_pointcloudpoints_majority","text":"<pre><code>collect_quotient_graph_nodes_from_pointcloudpoints_majority(quotient_graph, list_of_points=[])\n</code></pre> <p>Collects quotient graph nodes from a point cloud.</p> <p>This function determines the quotient graph nodes that are most associated with the points within a given list of points using a majority rule. It iterates through the nodes in the quotient graph, evaluates point membership, and decides the inclusion of a quotient graph node into the result based on the majority vote.</p> <p>Parameters:</p> <ul> <li> <code>quotient_graph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph object containing a point cloud graph with defined nodes. Each node in the graph must include a 'quotient_graph_node' attribute.</p> </li> <li> <code>list_of_points</code>               (<code>list</code>, default:                   <code>[]</code> )           \u2013            <p>A list of points that are used to determine the majority association with the quotient graph's nodes. If not provided, it defaults to an empty list.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>A list of unique quotient graph nodes from the point cloud graph that have a majority of association with the provided list of points.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_operations.py</code> <pre><code>def collect_quotient_graph_nodes_from_pointcloudpoints_majority(quotient_graph, list_of_points=[]):\n    \"\"\"Collects quotient graph nodes from a point cloud.\n\n    This function determines the quotient graph nodes that are most associated\n    with the points within a given list of points using a majority rule. It\n    iterates through the nodes in the quotient graph, evaluates point\n    membership, and decides the inclusion of a quotient graph node into the\n    result based on the majority vote.\n\n    Parameters\n    ----------\n    quotient_graph : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph object containing a point cloud graph with defined\n        nodes. Each node in the graph must include a 'quotient_graph_node'\n        attribute.\n    list_of_points : list, optional\n        A list of points that are used to determine the majority association\n        with the quotient graph's nodes. If not provided, it defaults to an\n        empty list.\n\n    Returns\n    -------\n    list\n        A list of unique quotient graph nodes from the point cloud graph that\n        have a majority of association with the provided list of points.\n    \"\"\"\n    G = quotient_graph.point_cloud_graph\n    listi = []\n\n    for qgnode in quotient_graph.nodes:\n        countyes = 0\n        countno = 0\n        list_of_nodes_each = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == qgnode]\n        for n in list_of_nodes_each:\n            if n in list_of_points:\n                countyes += 1\n            else:\n                countno += 1\n        if countyes &gt; countno:\n            listi.append(qgnode)\n\n    list_of_clusters = list(set(listi))\n\n    return list_of_clusters\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_operations/#spectral_clustering.quotientgraph_operations.compute_quotient_graph_mean_attribute_from_points","title":"compute_quotient_graph_mean_attribute_from_points","text":"<pre><code>compute_quotient_graph_mean_attribute_from_points(G, QG, attribute='clustering_labels')\n</code></pre> <p>Computes the mean of a specified attribute from nodes in the input graph <code>G</code> and assigns it to the corresponding nodes in the quotient graph <code>QG</code>.</p> <p>This function calculates the average value of a given attribute for all nodes in the original graph <code>G</code> that are represented by a single node in the quotient graph <code>QG</code>. The resulting mean is stored as a new attribute in the corresponding node in <code>QG</code>.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The original graph containing the detailed node information including attributes relevant to the computation.</p> </li> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph derived from the original graph. Each node in <code>QG</code> represents a group of nodes from <code>G</code>.</p> </li> <li> <code>attribute</code>               (<code>str</code>, default:                   <code>'clustering_labels'</code> )           \u2013            <p>The node attribute in <code>G</code> from which the mean is to be computed. The default value is 'clustering_labels'.</p> </li> </ul> Notes <p>The function assumes that: 1. Each node in <code>G</code> has the specified <code>attribute</code>. 2. Each node in <code>G</code> has a secondary attribute 'quotient_graph_node' which specifies    the corresponding node in <code>QG</code>. 3. Groups of nodes in <code>G</code> are mapped to nodes in <code>QG</code> through the    'quotient_graph_node' attribute.</p> <p>The resulting mean for each node in <code>QG</code> will be stored under a new attribute with the name defined as <code>{attribute}_mean</code>.</p> Source code in <code>spectral_clustering/quotientgraph_operations.py</code> <pre><code>def compute_quotient_graph_mean_attribute_from_points(G, QG, attribute='clustering_labels'):\n    \"\"\"Computes the mean of a specified attribute from nodes in the input graph `G` and assigns\n    it to the corresponding nodes in the quotient graph `QG`.\n\n    This function calculates the average value of a given attribute for all nodes in the\n    original graph `G` that are represented by a single node in the quotient graph `QG`.\n    The resulting mean is stored as a new attribute in the corresponding node in `QG`.\n\n    Parameters\n    ----------\n    G : spectral_clustering.pointcloudgraph.PointCloudGraph\n        The original graph containing the detailed node information including attributes\n        relevant to the computation.\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph derived from the original graph. Each node in `QG` represents\n        a group of nodes from `G`.\n    attribute : str, optional\n        The node attribute in `G` from which the mean is to be computed. The default value\n        is 'clustering_labels'.\n\n    Notes\n    -----\n    The function assumes that:\n    1. Each node in `G` has the specified `attribute`.\n    2. Each node in `G` has a secondary attribute 'quotient_graph_node' which specifies\n       the corresponding node in `QG`.\n    3. Groups of nodes in `G` are mapped to nodes in `QG` through the\n       'quotient_graph_node' attribute.\n\n    The resulting mean for each node in `QG` will be stored under a new attribute with\n    the name defined as `{attribute}_mean`.\n    \"\"\"\n    for n in QG.nodes:\n        moy = 0\n        list_of_nodes = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == n]\n        for e in list_of_nodes:\n            moy += G.nodes[e][attribute]\n        QG.nodes[n][attribute + '_mean'] = moy / len(list_of_nodes)\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_operations/#spectral_clustering.quotientgraph_operations.delete_small_clusters","title":"delete_small_clusters","text":"<pre><code>delete_small_clusters(quotientgraph, min_number_of_element_in_a_quotient_node=50)\n</code></pre> <p>Merges small clusters in a quotient graph with their largest neighboring cluster. This function modifies the quotient graph in place by removing clusters with fewer intra-class nodes than a specified threshold. The nodes of these removed clusters are reassigned to their neighboring cluster with the highest number of intra-class nodes. The edges and attributes of the remaining clusters are updated accordingly.</p> <p>quotientgraph : spectral_clustering.quotientgraph.QuotientGraph     A graph representing the quotient graph structure that holds clusters as nodes,     defined by the aggregated properties such as number of intra-class nodes, intra-class edge weights,     or inter-class edge properties. min_number_of_element_in_a_quotient_node: int, optional     Minimum threshold specifying the number of intra-class elements required for a cluster to persist.     Clusters with a count below this threshold are merged with their most significant neighboring cluster.     Default is <code>50</code>.</p> Source code in <code>spectral_clustering/quotientgraph_operations.py</code> <pre><code>def delete_small_clusters(quotientgraph, min_number_of_element_in_a_quotient_node=50):\n    \"\"\"\n    Merges small clusters in a quotient graph with their largest neighboring cluster. This function modifies the\n    quotient graph in place by removing clusters with fewer intra-class nodes than a specified threshold. The\n    nodes of these removed clusters are reassigned to their neighboring cluster with the highest number of\n    intra-class nodes. The edges and attributes of the remaining clusters are updated accordingly.\n\n    quotientgraph : spectral_clustering.quotientgraph.QuotientGraph\n        A graph representing the quotient graph structure that holds clusters as nodes,\n        defined by the aggregated properties such as number of intra-class nodes, intra-class edge weights,\n        or inter-class edge properties.\n    min_number_of_element_in_a_quotient_node: int, optional\n        Minimum threshold specifying the number of intra-class elements required for a cluster to persist.\n        Clusters with a count below this threshold are merged with their most significant neighboring cluster.\n        Default is ``50``.\n    \"\"\"\n    G = quotientgraph.point_cloud_graph\n    nodes_to_remove = []\n    for u in quotientgraph.nodes:\n        if quotientgraph.nodes[u]['intra_class_node_number'] &lt; min_number_of_element_in_a_quotient_node:\n            adjacent_clusters = [n for n in quotientgraph[u]]\n            max_number_of_nodes_in_adjacent_clusters = 0\n            for i in range(len(adjacent_clusters)):\n                if quotientgraph.nodes[adjacent_clusters[i]][\n                    'intra_class_node_number'] &gt; max_number_of_nodes_in_adjacent_clusters:\n                    max_number_of_nodes_in_adjacent_clusters = quotientgraph.nodes[adjacent_clusters[i]][\n                        'intra_class_node_number']\n                    new_cluster = adjacent_clusters[i]\n            # Op\u00e9ration de fusion du petit cluster avec son voisin le plus cons\u00e9quent.\n            # Mise \u00e0 jour des attributs de la grande classe et suppression de la petite classe\n            quotientgraph.nodes[new_cluster]['intra_class_node_number'] += quotientgraph.nodes[u][\n                'intra_class_node_number']\n            quotientgraph.nodes[new_cluster]['intra_class_edge_weight'] += (\n                        quotientgraph.nodes[u]['intra_class_edge_weight']\n                        + quotientgraph.edges[new_cluster, u][\n                            'inter_class_edge_weight'])\n            quotientgraph.nodes[new_cluster]['intra_class_edge_number'] += (\n                        quotientgraph.nodes[u]['intra_class_edge_number']\n                        + quotientgraph.edges[new_cluster, u][\n                            'inter_class_edge_number'])\n\n            # Mise \u00e0 jour du lien avec le PointCloudGraph d'origine\n            for v in G.nodes:\n                if G.nodes[v]['quotient_graph_node'] == u:\n                    G.nodes[v]['quotient_graph_node'] = new_cluster\n\n            # Mise \u00e0 jour des edges\n            for i in range(len(adjacent_clusters)):\n                if quotientgraph.has_edge(new_cluster, adjacent_clusters[i]) is False:\n                    quotientgraph.add_edge(new_cluster, adjacent_clusters[i],\n                                           inter_class_edge_weight=quotientgraph.edges[u, adjacent_clusters[i]][\n                                               'inter_class_edge_weight'],\n                                           inter_class_edge_number=quotientgraph.edges[u, adjacent_clusters[i]][\n                                               'inter_class_edge_number'])\n                elif quotientgraph.has_edge(new_cluster, adjacent_clusters[i]) and new_cluster != adjacent_clusters[i]:\n                    quotientgraph.edges[new_cluster, adjacent_clusters[i]]['inter_class_edge_weight'] += \\\n                        quotientgraph.edges[u, adjacent_clusters[i]]['inter_class_edge_weight']\n                    quotientgraph.edges[new_cluster, adjacent_clusters[i]]['inter_class_edge_weight'] += \\\n                        quotientgraph.edges[u, adjacent_clusters[i]]['inter_class_edge_number']\n            nodes_to_remove.append(u)\n\n    quotientgraph.remove_nodes_from(nodes_to_remove)\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_operations/#spectral_clustering.quotientgraph_operations.merge_one_class_QG_nodes","title":"merge_one_class_QG_nodes","text":"<pre><code>merge_one_class_QG_nodes(QG, attribute='viterbi_class', viterbiclass=[1])\n</code></pre> <p>Merge nodes of a quotient graph (QG) based on a specified attribute and classes.</p> <p>This function processes a quotient graph and modifies it by merging nodes of the same specified class based on their attributes. It calculates similarities between nodes and iteratively merges those with a similarity class of 1, updating the properties of the resulting graph. The node merging process ensures that the point cloud graph associated with the quotient graph is also updated correctly.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph that contains nodes and edges to be processed. The graph must already include the attributes necessary for merging, such as intra-class node numbers and node classes.</p> </li> <li> <code>attribute</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The node attribute of the quotient graph used to determine which nodes can be merged. Defaults to 'viterbi_class'.</p> </li> <li> <code>viterbiclass</code>               (<code>list</code>, default:                   <code>[1]</code> )           \u2013            <p>A list of class values used for similarity calculations and determining whether nodes should be merged. Defaults to [1].</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>QuotientGraph</code>           \u2013            <p>The updated quotient graph after merging nodes of the specified class.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_operations.py</code> <pre><code>def merge_one_class_QG_nodes(QG, attribute='viterbi_class', viterbiclass=[1]):\n    \"\"\"Merge nodes of a quotient graph (QG) based on a specified attribute and classes.\n\n    This function processes a quotient graph and modifies it by merging nodes of the same\n    specified class based on their attributes. It calculates similarities between nodes\n    and iteratively merges those with a similarity class of 1, updating the properties\n    of the resulting graph. The node merging process ensures that the point cloud graph\n    associated with the quotient graph is also updated correctly.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph that contains nodes and edges to be processed. The graph must\n        already include the attributes necessary for merging, such as intra-class node\n        numbers and node classes.\n    attribute : str, optional\n        The node attribute of the quotient graph used to determine which nodes can\n        be merged. Defaults to 'viterbi_class'.\n    viterbiclass : list, optional\n        A list of class values used for similarity calculations and determining\n        whether nodes should be merged. Defaults to [1].\n\n    Returns\n    -------\n    spectral_clustering.quotientgraph.QuotientGraph\n        The updated quotient graph after merging nodes of the specified class.\n    \"\"\"\n    G = QG.point_cloud_graph\n    energy_similarity = 0\n    for e in QG.edges():\n        v1 = QG.nodes[e[0]][attribute]\n        v2 = QG.nodes[e[1]][attribute]\n        if v1 == v2 and v1 in viterbiclass:\n            QG.edges[e]['similarity_class'] = 1\n        else:\n            QG.edges[e]['similarity_class'] = 0\n        energy_similarity += QG.edges[e]['similarity_class']\n\n    energy_per_edges = nx.get_edge_attributes(QG, 'similarity_class')\n    edge_to_delete = max(energy_per_edges.items(), key=operator.itemgetter(1))[0]\n    energy_max = energy_per_edges[edge_to_delete]\n    while energy_max == 1:\n        n1 = QG.nodes[edge_to_delete[0]]['intra_class_node_number']\n        n2 = QG.nodes[edge_to_delete[1]]['intra_class_node_number']\n        viterbi = QG.nodes[edge_to_delete[0]][attribute]\n        list_of_nodes = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == edge_to_delete[1]]\n        for j in range(len(list_of_nodes)):\n            G.nodes[list_of_nodes[j]]['quotient_graph_node'] = edge_to_delete[0]\n\n        QG = nx.contracted_nodes(QG, edge_to_delete[0], edge_to_delete[1], self_loops=False)\n        QG.point_cloud_graph = G\n        QG.nodes[edge_to_delete[0]]['intra_class_node_number'] = n1 + n2\n        QG.nodes[edge_to_delete[0]][attribute] = viterbi\n        for e in QG.edges(edge_to_delete[0]):\n            v1 = QG.nodes[e[0]][attribute]\n            v2 = QG.nodes[e[1]][attribute]\n            if v1 == v2 and v1 in viterbiclass:\n                QG.edges[e]['similarity_class'] = 1\n            else:\n                QG.edges[e]['similarity_class'] = 0\n\n        energy_per_edges = nx.get_edge_attributes(QG, 'similarity_class')\n        edge_to_delete = max(energy_per_edges.items(), key=operator.itemgetter(1))[0]\n        energy_max = energy_per_edges[edge_to_delete]\n    # QG.rebuild(G=G)\n\n    return QG\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_operations/#spectral_clustering.quotientgraph_operations.merge_similar_class_QG_nodes","title":"merge_similar_class_QG_nodes","text":"<pre><code>merge_similar_class_QG_nodes(QG, attribute='viterbi_class', export=True)\n</code></pre> <p>Merges similar quotient graph (QG) nodes based on the specified attribute and updates the graph structure.</p> <p>This function iteratively merges nodes in the quotient graph (QG) that share the same value of the specified attribute. Each merge operation updates the QG and its associated point cloud graph, recalculating the 'similarity_class' for affected edges until no edges exhibit similarity. Optionally, the function can export specific attributes to a file and display/export the modified graph.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph to be processed, which contains node attributes and maintains a reference to the associated point cloud graph.</p> </li> <li> <code>attribute</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The node attribute used to evaluate similarity between nodes. By default, 'viterbi_class'.</p> </li> <li> <code>export</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If set to True, exports graph attributes and visualizations of the modified QG. Defaults to True.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>QuotientGraph</code>           \u2013            <p>The modified quotient graph (QG) with merged similar nodes and updated attributes.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_operations.py</code> <pre><code>def merge_similar_class_QG_nodes(QG, attribute='viterbi_class', export=True):\n    \"\"\"Merges similar quotient graph (QG) nodes based on the specified attribute and updates the graph structure.\n\n    This function iteratively merges nodes in the quotient graph (QG) that share the same value of the specified\n    attribute. Each merge operation updates the QG and its associated point cloud graph, recalculating the\n    'similarity_class' for affected edges until no edges exhibit similarity. Optionally, the function can export\n    specific attributes to a file and display/export the modified graph.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph to be processed, which contains node attributes and maintains\n        a reference to the associated point cloud graph.\n    attribute : str, optional\n        The node attribute used to evaluate similarity between nodes. By default, 'viterbi_class'.\n    export : bool, optional\n        If set to True, exports graph attributes and visualizations of the modified QG.\n        Defaults to True.\n\n    Returns\n    -------\n    spectral_clustering.quotientgraph.QuotientGraph\n        The modified quotient graph (QG) with merged similar nodes and updated attributes.\n    \"\"\"\n    G = QG.point_cloud_graph\n    energy_similarity = 0\n    for e in QG.edges():\n        v1 = QG.nodes[e[0]][attribute]\n        v2 = QG.nodes[e[1]][attribute]\n        if v1 == v2:\n            QG.edges[e]['similarity_class'] = 1\n        else:\n            QG.edges[e]['similarity_class'] = 0\n        energy_similarity += QG.edges[e]['similarity_class']\n\n    energy_per_edges = nx.get_edge_attributes(QG, 'similarity_class')\n    edge_to_delete = max(energy_per_edges.items(), key=operator.itemgetter(1))[0]\n    energy_max = energy_per_edges[edge_to_delete]\n    while energy_max != 0:\n        n1 = QG.nodes[edge_to_delete[0]]['intra_class_node_number']\n        n2 = QG.nodes[edge_to_delete[1]]['intra_class_node_number']\n        viterbi = QG.nodes[edge_to_delete[0]][attribute]\n        list_of_nodes = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == edge_to_delete[1]]\n        for j in range(len(list_of_nodes)):\n            G.nodes[list_of_nodes[j]]['quotient_graph_node'] = edge_to_delete[0]\n\n        QG = nx.contracted_nodes(QG, edge_to_delete[0], edge_to_delete[1], self_loops=False)\n        QG.point_cloud_graph = G\n        QG.nodes[edge_to_delete[0]]['intra_class_node_number'] = n1 + n2\n        QG.nodes[edge_to_delete[0]][attribute] = viterbi\n        for e in QG.edges(edge_to_delete[0]):\n            v1 = QG.nodes[e[0]][attribute]\n            v2 = QG.nodes[e[1]][attribute]\n            if v1 == v2:\n                QG.edges[e]['similarity_class'] = 1\n            else:\n                QG.edges[e]['similarity_class'] = 0\n\n        energy_per_edges = nx.get_edge_attributes(QG, 'similarity_class')\n        edge_to_delete = max(energy_per_edges.items(), key=operator.itemgetter(1))[0]\n        energy_max = energy_per_edges[edge_to_delete]\n    # QG.rebuild(G=G)\n    if export is True:\n        export_some_graph_attributes_on_point_cloud(pcd_g=QG.point_cloud_graph,\n                                                    graph_attribute='quotient_graph_node',\n                                                    filename='Merge_after_viterbi.txt')\n        display_and_export_quotient_graph_matplotlib(qg=QG, node_sizes=20,\n                                                     name=\"merge_quotient_graph_viterbi\", data_on_nodes='viterbi_class',\n                                                     data=True, attributekmeans4clusters=False)\n    return QG\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_operations/#spectral_clustering.quotientgraph_operations.quotient_graph_compute_direction_mean","title":"quotient_graph_compute_direction_mean","text":"<pre><code>quotient_graph_compute_direction_mean(quotient_graph)\n</code></pre> <p>Computes the mean direction gradient for each node in a quotient graph.</p> <p>This function iterates through nodes in the given <code>quotient_graph</code> and computes the mean of a specified property, <code>direction_gradient</code>, over corresponding subsets of nodes in the associated point cloud graph. The computed means are stored as a new property, <code>dir_gradient_mean</code>, in the nodes of the quotient graph.</p> <p>Parameters:</p> <ul> <li> <code>quotient_graph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The input quotient graph, which is expected to contain a property, <code>point_cloud_graph</code>. Each node in the <code>quotient_graph</code> corresponds to a set of nodes in the associated <code>point_cloud_graph</code>, and the function computes and assigns a mean value for its <code>direction_gradient</code> property.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_operations.py</code> <pre><code>def quotient_graph_compute_direction_mean(quotient_graph):\n    \"\"\"Computes the mean direction gradient for each node in a quotient graph.\n\n    This function iterates through nodes in the given `quotient_graph` and computes\n    the mean of a specified property, `direction_gradient`, over corresponding\n    subsets of nodes in the associated point cloud graph. The computed means are\n    stored as a new property, `dir_gradient_mean`, in the nodes of the quotient graph.\n\n    Parameters\n    ----------\n    quotient_graph : spectral_clustering.quotientgraph.QuotientGraph\n        The input quotient graph, which is expected to contain a property,\n        `point_cloud_graph`. Each node in the `quotient_graph` corresponds to\n        a set of nodes in the associated `point_cloud_graph`, and the function\n        computes and assigns a mean value for its `direction_gradient` property.\n    \"\"\"\n    G = quotient_graph.point_cloud_graph\n    for l in quotient_graph:\n        quotient_graph.nodes[l]['dir_gradient_mean'] = 0\n        list_of_nodes_in_qnode = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == l]\n        for n in list_of_nodes_in_qnode:\n            quotient_graph.nodes[l]['dir_gradient_mean'] += G.nodes[n]['direction_gradient']\n        quotient_graph.nodes[l]['dir_gradient_mean'] /= len(list_of_nodes_in_qnode)\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_operations/#spectral_clustering.quotientgraph_operations.quotient_graph_compute_direction_standard_deviation","title":"quotient_graph_compute_direction_standard_deviation","text":"<pre><code>quotient_graph_compute_direction_standard_deviation(quotient_graph, mean='dir_gradient_mean')\n</code></pre> <p>Computes the standard deviation of direction gradients for a quotient graph node.</p> <p>This function calculates the standard deviation of the direction gradients for each quotient graph node. It processes each node in the quotient graph by iterating through its associated nodes in the original graph. For each associated node, a directional gradient is computed, and the mean and standard deviation of the gradients are updated accordingly in the quotient graph node attributes.</p> <p>Parameters:</p> <ul> <li> <code>quotient_graph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph object, which contains nodes and associated attributes. It includes a point cloud graph (point_cloud_graph) and information about the directional gradients of each node.</p> </li> <li> <code>mean</code>               (<code>str</code>, default:                   <code>'dir_gradient_mean'</code> )           \u2013            <p>The attribute name in the quotient graph node describing the mean vector for the directional gradient. Defaults to 'dir_gradient_mean'.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_operations.py</code> <pre><code>def quotient_graph_compute_direction_standard_deviation(quotient_graph, mean='dir_gradient_mean'):\n    \"\"\"Computes the standard deviation of direction gradients for a quotient graph node.\n\n    This function calculates the standard deviation of the direction gradients for each\n    quotient graph node. It processes each node in the quotient graph by iterating through\n    its associated nodes in the original graph. For each associated node, a directional\n    gradient is computed, and the mean and standard deviation of the gradients are updated\n    accordingly in the quotient graph node attributes.\n\n    Parameters\n    ----------\n    quotient_graph : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph object, which contains nodes and associated attributes. It\n        includes a point cloud graph (point_cloud_graph) and information about the\n        directional gradients of each node.\n    mean : str, optional\n        The attribute name in the quotient graph node describing the mean vector for\n        the directional gradient. Defaults to 'dir_gradient_mean'.\n    \"\"\"\n    G = quotient_graph.point_cloud_graph\n    for l in quotient_graph:\n        quotient_graph.nodes[l]['dir_gradient_angle_mean'] = 0\n        quotient_graph.nodes[l]['dir_gradient_stdv'] = 0\n        list_of_nodes_in_qnode = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == l]\n        for n in list_of_nodes_in_qnode:\n            v1 = quotient_graph.nodes[l][mean]\n            v2 = G.nodes[n]['direction_gradient']\n            G.nodes[n]['dir_gradient_angle'] = abs(v1[0] * v2[0] + v1[1] * v2[1] + v1[2] * v2[2])\n            quotient_graph.nodes[l]['dir_gradient_angle_mean'] += G.nodes[n]['dir_gradient_angle']\n        quotient_graph.nodes[l]['dir_gradient_angle_mean'] /= len(list_of_nodes_in_qnode)\n        for n in list_of_nodes_in_qnode:\n            v1 = quotient_graph.nodes[l][mean]\n            v2 = G.nodes[n]['direction_gradient']\n            quotient_graph.nodes[l]['dir_gradient_stdv'] += np.power(\n                quotient_graph.nodes[l]['dir_gradient_angle_mean'] - G.nodes[n]['dir_gradient_angle'], 2)\n        quotient_graph.nodes[l]['dir_gradient_stdv'] /= len(list_of_nodes_in_qnode)\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_operations/#spectral_clustering.quotientgraph_operations.transfer_quotientgraph_infos_on_riemanian_graph","title":"transfer_quotientgraph_infos_on_riemanian_graph","text":"<pre><code>transfer_quotientgraph_infos_on_riemanian_graph(QG, info='viterbi_class')\n</code></pre> <p>Transfers information from a quotient graph to a Riemannian graph based on a specified attribute.</p> <p>The function replicates a specified attribute from the nodes of the quotient graph to the nodes of the Riemannian graph. Each node in the Riemannian graph receives the value of the attribute from its corresponding node in the quotient graph. The correspondence is determined by a mapping stored in each node of the Riemannian graph.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph containing the original information that will be transferred.</p> </li> <li> <code>info</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The attribute key in the quotient graph's nodes whose values are to be transferred to the nodes of the Riemannian graph. Default is 'viterbi_class'.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>KeyError</code>             \u2013            <p>If the <code>quotient_graph_node</code> key is missing in any node's attributes in the Riemannian graph or if the specified <code>info</code> key is missing in the corresponding nodes in the quotient graph.</p> </li> </ul> Notes <p>This function assumes correspondence between the nodes of the quotient graph and the nodes of the Riemannian graph is established via the 'quotient_graph_node' key in each Riemannian graph node.</p> Source code in <code>spectral_clustering/quotientgraph_operations.py</code> <pre><code>def transfer_quotientgraph_infos_on_riemanian_graph(QG, info='viterbi_class'):\n    \"\"\"Transfers information from a quotient graph to a Riemannian graph based on a specified attribute.\n\n    The function replicates a specified attribute from the nodes of the quotient graph to the nodes\n    of the Riemannian graph. Each node in the Riemannian graph receives the value of the attribute\n    from its corresponding node in the quotient graph. The correspondence is determined by a mapping\n    stored in each node of the Riemannian graph.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph containing the original information that will be transferred.\n    info : str, optional\n        The attribute key in the quotient graph's nodes whose values are to be transferred to\n        the nodes of the Riemannian graph. Default is 'viterbi_class'.\n\n    Raises\n    ------\n    KeyError\n        If the `quotient_graph_node` key is missing in any node's attributes in the\n        Riemannian graph or if the specified `info` key is missing in the corresponding\n        nodes in the quotient graph.\n\n    Notes\n    -----\n    This function assumes correspondence between the nodes of the quotient graph and\n    the nodes of the Riemannian graph is established via the 'quotient_graph_node'\n    key in each Riemannian graph node.\n    \"\"\"\n    G = QG.point_cloud_graph\n    for n in G.nodes:\n        G.nodes[n][info] = QG.nodes[G.nodes[n]['quotient_graph_node']][info]\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_operations/#spectral_clustering.quotientgraph_operations.update_quotient_graph_attributes_when_node_change_cluster","title":"update_quotient_graph_attributes_when_node_change_cluster","text":"<pre><code>update_quotient_graph_attributes_when_node_change_cluster(quotientgraph, old_cluster, new_cluster, node_to_change)\n</code></pre> <p>Updates the attributes of a quotient graph after a node changes its cluster.</p> <p>This function modifies all the relevant attributes of the quotient graph and ensures consistency after a node transitions from one cluster to another.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph object whose attributes need to be updated. It contains the graph structure as well as attribute data.</p> </li> <li> <code>old_cluster</code>               (<code>int</code>)           \u2013            <p>The original cluster to which the node belonged.</p> </li> <li> <code>new_cluster</code>               (<code>int</code>)           \u2013            <p>The new cluster to which the node is assigned.</p> </li> <li> <code>node_to_change</code>               (<code>int</code>)           \u2013            <p>The node that transitions from one cluster to another.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_operations.py</code> <pre><code>def update_quotient_graph_attributes_when_node_change_cluster(quotientgraph, old_cluster, new_cluster, node_to_change):\n    \"\"\"Updates the attributes of a quotient graph after a node changes its cluster.\n\n    This function modifies all the relevant attributes of the quotient graph\n    and ensures consistency after a node transitions from one cluster to another.\n\n    Parameters\n    ----------\n    quotientgraph : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph object whose attributes need to be updated. It contains\n        the graph structure as well as attribute data.\n    old_cluster : int\n        The original cluster to which the node belonged.\n    new_cluster : int\n        The new cluster to which the node is assigned.\n    node_to_change : int\n        The node that transitions from one cluster to another.\n    \"\"\"\n\n    G = quotientgraph.point_cloud_graph\n    # update Quotient Graph attributes\n    # Intra_class_node_number\n    # print(old_cluster)\n    # print(new_cluster)\n    quotientgraph.nodes[old_cluster]['intra_class_node_number'] += -1\n    quotientgraph.nodes[new_cluster]['intra_class_node_number'] += 1\n\n    # intra_class_edge_weight, inter_class_edge_number\n    for ng in G[node_to_change]:\n        if old_cluster != G.nodes[ng]['quotient_graph_node'] and new_cluster == G.nodes[ng]['quotient_graph_node']:\n            quotientgraph.nodes[new_cluster]['intra_class_edge_weight'] += G.edges[ng, node_to_change]['weight']\n            quotientgraph.nodes[new_cluster]['intra_class_edge_number'] += 1\n            quotientgraph.edges[old_cluster, new_cluster]['inter_class_edge_weight'] += - G.edges[ng, node_to_change][\n                'weight']\n            quotientgraph.edges[old_cluster, new_cluster]['inter_class_edge_number'] += - 1\n\n        if old_cluster == G.nodes[ng]['quotient_graph_node'] and new_cluster != G.nodes[ng]['quotient_graph_node']:\n            quotientgraph.nodes[old_cluster]['intra_class_edge_weight'] += -G.edges[ng, node_to_change]['weight']\n            quotientgraph.nodes[old_cluster]['intra_class_edge_number'] += -1\n            cluster_adj = G.nodes[ng]['quotient_graph_node']\n            if quotientgraph.has_edge(new_cluster, cluster_adj) is False:\n                quotientgraph.add_edge(new_cluster, cluster_adj, inter_class_edge_weight=None,\n                                       inter_class_edge_number=None)\n            quotientgraph.edges[new_cluster, cluster_adj]['inter_class_edge_weight'] += G.edges[ng, node_to_change][\n                'weight']\n            quotientgraph.edges[new_cluster, cluster_adj]['inter_class_edge_number'] += 1\n\n        if old_cluster != G.nodes[ng]['quotient_graph_node'] and new_cluster != G.nodes[ng]['quotient_graph_node']:\n            cluster_adj = G.nodes[ng]['quotient_graph_node']\n            if quotientgraph.has_edge(new_cluster, cluster_adj) is False:\n                quotientgraph.add_edge(new_cluster, cluster_adj,\n                                       inter_class_edge_weight=G.edges[ng, node_to_change]['weight'],\n                                       inter_class_edge_number=1)\n            else:\n                quotientgraph.edges[new_cluster, cluster_adj]['inter_class_edge_weight'] += G.edges[ng, node_to_change][\n                    'weight']\n                quotientgraph.edges[new_cluster, cluster_adj]['inter_class_edge_number'] += 1\n            if new_cluster != old_cluster:\n                quotientgraph.edges[old_cluster, cluster_adj]['inter_class_edge_weight'] += - \\\n                    G.edges[ng, node_to_change]['weight']\n                quotientgraph.edges[old_cluster, cluster_adj]['inter_class_edge_number'] += - 1\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/","title":"quotientgraph_semantics","text":""},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.define_leaves_by_topo","title":"define_leaves_by_topo","text":"<pre><code>define_leaves_by_topo(quotientgraph)\n</code></pre> <p>Defines the leaves of a quotient graph based on topological structure and selects a root node based on specific node attributes.</p> <p>This function identifies \"end\" nodes (leaves) of the graph and computes a mean gradient value for each leaf node based on the associated nodes' gradient attributes from the base graph. The root node is randomly selected from the leaves, although it could optionally be chosen as the node with the highest mean gradient.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph structure representing a simplified version of the point cloud graph. Nodes in this graph contain attributes, and the graph is connected to the underlying detailed structure of the point cloud graph.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def define_leaves_by_topo(quotientgraph):\n    \"\"\"\n    Defines the leaves of a quotient graph based on topological structure and selects\n    a root node based on specific node attributes.\n\n    This function identifies \"end\" nodes (leaves) of the graph and computes a\n    mean gradient value for each leaf node based on the associated nodes' gradient\n    attributes from the base graph. The root node is randomly selected from the\n    leaves, although it could optionally be chosen as the node with the highest\n    mean gradient.\n\n    Parameters\n    ----------\n    quotientgraph : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph structure representing a simplified version of the\n        point cloud graph. Nodes in this graph contain attributes, and the graph\n        is connected to the underlying detailed structure of the point cloud\n        graph.\n    \"\"\"\n    G = quotientgraph.point_cloud_graph\n    # Put the \"end\" nodes in a list\n    list_leaves = [x for x in quotientgraph.nodes() if quotientgraph.degree(x) == 1]\n\n    # Pick the node with the most average norm gradient (most likely to be part of the stem)\n    max_norm = 0\n    max_norm_node = -1\n    for l in list_leaves:\n        quotientgraph.nodes[l]['norm_gradient_mean'] = 0\n        list_of_nodes_in_qnode = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == l]\n        for n in list_of_nodes_in_qnode:\n            quotientgraph.nodes[l]['norm_gradient_mean'] += G.nodes[n]['norm_gradient']\n        quotientgraph.nodes[l]['norm_gradient_mean'] /= len(list_of_nodes_in_qnode)\n        if quotientgraph.nodes[l]['norm_gradient_mean'] &gt; max_norm:\n            max_norm = quotientgraph.nodes[l]['norm_gradient_mean']\n            max_norm_node = l\n\n    # Finally I chose randomly the root among the leaves but I could choose the max_norm_node\n    root = np.random.choice(list_leaves)\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.define_semantic_classes","title":"define_semantic_classes","text":"<pre><code>define_semantic_classes(quotientgraph)\n</code></pre> <p>Assigns semantic labels to nodes in a quotient graph.</p> <p>Given a quotient graph, this function classifies its nodes into three semantic classes: 'leaf', 'stem', and 'petiole'. Nodes with a single adjacency are labeled as 'leaf'. The node with the highest number of neighbors is labeled as 'stem'. All other nodes are classified as 'petiole'. The function directly modifies the quotient graph by adding a 'semantic_label' attribute with the appropriate class to each node.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>QuotientGraph</code>)           \u2013            <p>A quotient graph where each node represents an abstract entity, and its edges define connections between these entities.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def define_semantic_classes(quotientgraph):\n    \"\"\"Assigns semantic labels to nodes in a quotient graph.\n\n    Given a quotient graph, this function classifies its nodes into three semantic classes:\n    'leaf', 'stem', and 'petiole'.\n    Nodes with a single adjacency are labeled as 'leaf'.\n    The node with the highest number of neighbors is labeled as 'stem'.\n    All other nodes are classified as 'petiole'.\n    The function directly modifies the quotient graph by adding a 'semantic_label' attribute with the\n    appropriate class to each node.\n\n    Parameters\n    ----------\n    quotientgraph : spectral_clustering.quotientgraph.QuotientGraph\n        A quotient graph where each node represents an abstract entity, and its\n        edges define connections between these entities.\n    \"\"\"\n    # leaves : one adjacency\n    list_leaves = [x for x in quotientgraph.nodes() if quotientgraph.degree(x) == 1]\n\n    # the node with the most number of neighborhood is the stem\n    degree_sorted = sorted(quotientgraph.degree, key=lambda x: x[1], reverse=True)\n    stem = [degree_sorted[0][0]]\n\n    # the rest is defined as branches\n    for n in quotientgraph.nodes:\n        if n in list_leaves:\n            quotientgraph.nodes[n]['semantic_label'] = 'leaf'\n        if n in stem:\n            quotientgraph.nodes[n]['semantic_label'] = 'stem'\n        elif n not in list_leaves and n not in stem:\n            quotientgraph.nodes[n]['semantic_label'] = 'petiole'\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.define_semantic_scores","title":"define_semantic_scores","text":"<pre><code>define_semantic_scores(quotientgraph, method='similarity_dist')\n</code></pre> <p>Defines semantic scores for nodes in the quotient graph based on specific methods.</p> <p>This function computes the semantic scores for each node in the quotient graph based on either a condition-based logic or a similarity distance approach. The method determines how the scores are calculated and applied to the nodes. Scores are computed for three categories: <code>leaf</code>, <code>petiole</code>, and <code>stem</code>. The method 'includes intermediate computation and smoothstep/identity transformations for distances or direct logical conditions.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>QuotientGraph</code>)           \u2013            <p>A quotient graph object which contains nodes and related descriptors such as planarity, linearity, silhouette, and degree. The graph structure and attributes are utilized to compute semantic scores for each node.</p> </li> <li> <code>method</code>               (<code>str</code>, default:                   <code>'similarity_dist'</code> )           \u2013            <p>The scoring method to be used. Defaults to 'similarity_dist'. Options include:</p> <ul> <li>'condition_list': Evaluates descriptive conditions on graph node properties.</li> <li>'similarity_dist': Computes similarity based on a reference score vector     using Euclidean distances and applies smoothstep or identity transformations.</li> </ul> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def define_semantic_scores(quotientgraph, method='similarity_dist'):\n    \"\"\"Defines semantic scores for nodes in the quotient graph based on specific methods.\n\n    This function computes the semantic scores for each node in the quotient graph\n    based on either a condition-based logic or a similarity distance approach. The\n    method determines how the scores are calculated and applied to the nodes. Scores\n    are computed for three categories: `leaf`, `petiole`, and `stem`. The method\n    'includes intermediate computation and smoothstep/identity transformations for\n    distances or direct logical conditions.\n\n    Parameters\n    ----------\n    quotientgraph : spectral_clustering.quotientgraph.QuotientGraph\n        A quotient graph object which contains nodes and related descriptors\n        such as planarity, linearity, silhouette, and degree. The graph structure\n        and attributes are utilized to compute semantic scores for each node.\n    method : str, optional\n        The scoring method to be used. Defaults to 'similarity_dist'.\n        Options include:\n\n          - 'condition_list': Evaluates descriptive conditions on graph node properties.\n          - 'similarity_dist': Computes similarity based on a reference score vector\n            using Euclidean distances and applies smoothstep or identity transformations.\n    \"\"\"\n    quotientgraph.compute_local_descriptors(quotientgraph.point_cloud_graph, method='all_qg_cluster', data='coords')\n    quotientgraph.compute_silhouette()\n    degree_sorted = sorted(quotientgraph.degree, key=lambda x: x[1], reverse=True)\n    stem = [degree_sorted[0][0]]\n\n    if method == 'condition_list':\n        for n in quotientgraph.nodes:\n            score_vector_leaf = [quotientgraph.nodes[n]['planarity'] &gt; 0.5, quotientgraph.nodes[n]['linearity'] &lt; 0.5,\n                                 quotientgraph.degree(n) == 1]\n            score_vector_petiole = [quotientgraph.nodes[n]['planarity'] &lt; 0.5,\n                                    quotientgraph.nodes[n]['linearity'] &gt; 0.5, quotientgraph.degree(n) == 2,\n                                    quotientgraph.nodes[n]['silhouette'] &gt; 0.2]\n            score_vector_stem = [quotientgraph.nodes[n]['planarity'] &lt; 0.5, quotientgraph.nodes[n]['linearity'] &gt; 0.5,\n                                 quotientgraph.degree(n) == degree_sorted[0][1]]\n            quotientgraph.nodes[n]['score_leaf'] = score_vector_leaf.count(True) / len(score_vector_leaf)\n            quotientgraph.nodes[n]['score_petiole'] = score_vector_petiole.count(True) / len(score_vector_petiole)\n            quotientgraph.nodes[n]['score_stem'] = score_vector_stem.count(True) / len(score_vector_stem)\n\n    if method == 'similarity_dist':\n        def smoothstep(x):\n            if x &lt;= 0:\n                res = 0\n            elif x &gt;= 1:\n                res = 1\n            else:\n                res = 3 * pow(x, 2) - 2 * pow(x, 3)\n\n            return res\n\n        def identity(x):\n            if x &lt;= 0:\n                res = 0\n            elif x &gt;= 1:\n                res = 1\n            else:\n                res = x\n\n            return res\n\n        score_vector_leaf_ref = [0.81, 0, -0.1]\n        score_vector_linea_ref = [0, 1, 0.3]\n        for n in quotientgraph.nodes:\n            # score_vector_n = sk.preprocessing.normalize(np.asarray([QG.nodes[n]['planarity'], QG.nodes[n]['linearity']]).reshape(1,len(score_vector_leaf_ref)), norm='l2')\n            score_vector_n = [quotientgraph.nodes[n]['planarity'], quotientgraph.nodes[n]['linearity'],\n                              quotientgraph.nodes[n]['silhouette']]\n            print(score_vector_n)\n            d1_leaf = sp.spatial.distance.euclidean(score_vector_leaf_ref, score_vector_n)\n            # print(d1_leaf)\n            d2_linea = sp.spatial.distance.euclidean(score_vector_linea_ref, score_vector_n)\n            # print(d2_leaf)\n            f1 = 1 - d1_leaf\n            f2 = 1 - d2_linea\n            quotientgraph.nodes[n]['score_leaf'] = identity(f1)\n            quotientgraph.nodes[n]['score_petiole'] = identity(f2)\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.determination_main_stem","title":"determination_main_stem","text":"<pre><code>determination_main_stem(QG, list_of_linear_QG_nodes, stemroot, list_leaves, angle_to_stop=45, new_viterbi_class_number=3)\n</code></pre> <p>Determines the main stem of a Quotient Graph (QG) starting from a stem root, facilitated by directional and angular constraints. Updates the viterbi classification for the identified stem nodes in both the QG and the associated point cloud graph.</p> <p>The function iteratively identifies the stem path by minimizing energy values (dot products of edge vectors). The traversal stops either when the energy threshold (<code>angle_to_stop</code>) is exceeded or if the next node is not part of the predefined QG linear nodes. Additionally, the function assigns the provided viterbi class number to all nodes in the identified stem.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>The input Quotient Graph where directional and viterbi classifications are computed.</p> </li> <li> <code>list_of_linear_QG_nodes</code>               (<code>list</code>)           \u2013            <p>A list of node identifiers in the Quotient Graph representing the linear structural nodes of interest.</p> </li> <li> <code>stemroot</code>               (<code>int or str</code>)           \u2013            <p>Identifier of the starting node for the stem determination process in the Quotient Graph.</p> </li> <li> <code>list_leaves</code>               (<code>list</code>)           \u2013            <p>List of leaf node identifiers in the Quotient Graph used for directional computation.</p> </li> <li> <code>angle_to_stop</code>               (<code>float</code>, default:                   <code>45</code> )           \u2013            <p>Angular threshold (in degrees) to determine when to stop the stem traversal. Defaults to <code>45</code> degrees.</p> </li> <li> <code>new_viterbi_class_number</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The viterbi classification number assigned to identified stem nodes in both the Quotient Graph and the point cloud graph. Defaults to <code>3</code>.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def determination_main_stem(QG, list_of_linear_QG_nodes, stemroot, list_leaves, angle_to_stop=45,\n                            new_viterbi_class_number=3):\n    \"\"\"\n    Determines the main stem of a Quotient Graph (QG) starting from a stem root, facilitated\n    by directional and angular constraints. Updates the viterbi classification for the identified\n    stem nodes in both the QG and the associated point cloud graph.\n\n    The function iteratively identifies the stem path by minimizing energy values (dot products\n    of edge vectors). The traversal stops either when the energy threshold (`angle_to_stop`) is\n    exceeded or if the next node is not part of the predefined QG linear nodes. Additionally,\n    the function assigns the provided viterbi class number to all nodes in the identified stem.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        The input Quotient Graph where directional and viterbi classifications are computed.\n    list_of_linear_QG_nodes : list\n        A list of node identifiers in the Quotient Graph representing the linear structural\n        nodes of interest.\n    stemroot : int or str\n        Identifier of the starting node for the stem determination process in the Quotient Graph.\n    list_leaves : list\n        List of leaf node identifiers in the Quotient Graph used for directional computation.\n    angle_to_stop : float, optional\n        Angular threshold (in degrees) to determine when to stop the stem traversal.\n        Defaults to ``45`` degrees.\n    new_viterbi_class_number : int, optional\n        The viterbi classification number assigned to identified stem nodes in both the Quotient\n        Graph and the point cloud graph. Defaults to ``3``.\n    \"\"\"\n    QG.compute_direction_info(list_leaves=list_leaves)\n    G = QG.point_cloud_graph\n    energy_to_stop = 1 - np.cos(np.radians(angle_to_stop))\n    keepgoing = True\n    node_stem = stemroot\n    list_stem = []\n    list_stem.append(node_stem)\n    while keepgoing:\n        list_energies = []\n        list_nodes = []\n        print(node_stem)\n        for n in QG[node_stem]:\n            if n not in list_stem:\n                list_energies.append(QG.edges[(n, node_stem)]['energy_dot_product'])\n                list_nodes.append(n)\n        node = list_energies.index(min(list_energies))\n        node_stem = list_nodes[node]\n        if list_nodes:\n            if min(list_energies) &gt; energy_to_stop or node_stem not in list_of_linear_QG_nodes:\n                keepgoing = False\n            else:\n                list_stem.append(node_stem)\n        else:\n            keepgoing is False\n\n    for n in list_stem:\n        QG.nodes[n]['viterbi_class'] = new_viterbi_class_number\n        list_gnode = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == n]\n        for i in list_gnode:\n            G.nodes[i]['viterbi_class'] = new_viterbi_class_number\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.determination_main_stem_shortest_paths","title":"determination_main_stem_shortest_paths","text":"<pre><code>determination_main_stem_shortest_paths(QG, list_of_linear_QG_nodes)\n</code></pre> <p>Determines the shortest paths for the main stem using the quotient graph (QG).</p> <p>This function identifies and processes key nodes in the quotient graph (QG) and marks their corresponding nodes in the point cloud graph with a specific class. It uses the Sub-Riemannian graph derived from the QG to compute the traversed clusters and identifies the main stem's shortest paths within the graph structure.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph representing the higher-level graph structure, which includes nodes and edges used for the analysis.</p> </li> <li> <code>list_of_linear_QG_nodes</code>               (<code>list</code>)           \u2013            <p>A list of nodes from the quotient graph that defines the linear paths to focus on.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>A deduplicated list of quotient graph nodes traversed by the shortest paths of the main stem.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def determination_main_stem_shortest_paths(QG, list_of_linear_QG_nodes):\n    \"\"\"Determines the shortest paths for the main stem using the quotient graph (QG).\n\n    This function identifies and processes key nodes in the quotient graph (QG) and\n    marks their corresponding nodes in the point cloud graph with a specific class.\n    It uses the Sub-Riemannian graph derived from the QG to compute the traversed\n    clusters and identifies the main stem's shortest paths within the graph structure.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph representing the higher-level graph structure, which includes\n        nodes and edges used for the analysis.\n    list_of_linear_QG_nodes : list\n        A list of nodes from the quotient graph that defines the linear paths to focus on.\n\n    Returns\n    -------\n    list\n        A deduplicated list of quotient graph nodes traversed by the shortest paths of the main stem.\n    \"\"\"\n    sub_riemanian = create_subgraphs_to_work(quotientgraph=QG, list_quotient_node_to_work=list_of_linear_QG_nodes)\n    G = QG.point_cloud_graph\n    segmsource, ptsource, ptarrivee = initdijkstra(sub_riemanian)\n    list_clusters_qg_traversed = []\n    for i in segmsource:\n        n = G.nodes[i]['quotient_graph_node']\n        list_clusters_qg_traversed.append(n)\n    final_list_stem = list(set(list_clusters_qg_traversed))\n    for n in final_list_stem:\n        QG.nodes[n]['viterbi_class'] = 3\n        list_gnode = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == n]\n        for i in list_gnode:\n            G.nodes[i]['viterbi_class'] = 3\n    return final_list_stem\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.determination_main_stem_shortest_paths_improved","title":"determination_main_stem_shortest_paths_improved","text":"<pre><code>determination_main_stem_shortest_paths_improved(QG, ptsource, list_of_linear_QG_nodes, angle_to_stop=45, minimumpoint=5, classnumberstem=3, classnumberanomaly=3)\n</code></pre> <p>Determines the main 'stem' paths on a quotient graph using an improved algorithm, identifying clusters and marking anomalies based on vector directions and energy thresholds.</p> <p>The function processes a quotient graph and a list of linear quotient graph nodes to identify the main linear stems. It applies directional filtering based on the mean and variance of directional information stored in the graph vertices. The stems are further refined using angle-based thresholds, and anomalies are noted and classified accordingly. Additionally, this function transfers classifications from the quotient graph to the Riemannian graph.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph (QG) that contains the structure and properties used to compute the main stems and anomaly points.</p> </li> <li> <code>ptsource</code>               (<code>int</code>)           \u2013            <p>A starting point or source node for the shortest path calculation on the sub-Riemannian graph.</p> </li> <li> <code>list_of_linear_QG_nodes</code>               (<code>list[int]</code>)           \u2013            <p>A list of nodes in the quotient graph that are considered linear for the purposes of this computation.</p> </li> <li> <code>angle_to_stop</code>               (<code>float</code>, default:                   <code>45</code> )           \u2013            <p>The angle threshold to stop splitting paths, in degrees. Default is <code>45</code>.</p> </li> <li> <code>minimumpoint</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Minimum number of traversals through a cluster node for it to be considered part of the main stem. Default is <code>5</code>.</p> </li> <li> <code>classnumberstem</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The classification number assigned to the nodes belonging to the main stem. Default is <code>3</code>.</p> </li> <li> <code>classnumberanomaly</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The classification number assigned to nodes considered anomalies. Default is <code>3</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[int]</code>           \u2013            <p>A list of quotient graph nodes identified as the refined main stem, including the source point and the final cleaned list.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def determination_main_stem_shortest_paths_improved(QG, ptsource, list_of_linear_QG_nodes, angle_to_stop=45,\n                                                    minimumpoint=5, classnumberstem=3, classnumberanomaly=3):\n    \"\"\"\n    Determines the main 'stem' paths on a quotient graph using an improved algorithm,\n    identifying clusters and marking anomalies based on vector directions and energy\n    thresholds.\n\n    The function processes a quotient graph and a list of linear quotient graph nodes\n    to identify the main linear stems. It applies directional filtering based on the\n    mean and variance of directional information stored in the graph vertices. The\n    stems are further refined using angle-based thresholds, and anomalies are noted\n    and classified accordingly. Additionally, this function transfers classifications\n    from the quotient graph to the Riemannian graph.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph (QG) that contains the structure and properties used to\n        compute the main stems and anomaly points.\n    ptsource : int\n        A starting point or source node for the shortest path calculation on the sub-Riemannian graph.\n    list_of_linear_QG_nodes : list[int]\n        A list of nodes in the quotient graph that are considered linear for the purposes of this computation.\n    angle_to_stop : float, optional\n        The angle threshold to stop splitting paths, in degrees. Default is ``45``.\n    minimumpoint : int, optional\n        Minimum number of traversals through a cluster node for it to be considered part of the main stem.\n        Default is ``5``.\n    classnumberstem : int, optional\n        The classification number assigned to the nodes belonging to the main stem.\n        Default is ``3``.\n    classnumberanomaly : int, optional\n        The classification number assigned to nodes considered anomalies.\n        Default is ``3``.\n\n    Returns\n    -------\n    list[int]\n        A list of quotient graph nodes identified as the refined main stem,\n        including the source point and the final cleaned list.\n    \"\"\"\n    import copy\n    sub_riemanian = create_subgraphs_to_work(quotientgraph=QG, list_quotient_node_to_work=list_of_linear_QG_nodes)\n    G = QG.point_cloud_graph\n    energy_to_stop = 1 - np.cos(np.radians(angle_to_stop))\n\n    dict = nx.single_source_dijkstra_path_length(sub_riemanian, ptsource, weight='weight')\n    ptarrivee = max(dict.items(), key=operator.itemgetter(1))[0]\n    segmsource = nx.dijkstra_path(sub_riemanian, ptsource, ptarrivee, weight='weight')\n    list_clusters_qg_traversed = []\n    for i in segmsource:\n        n = G.nodes[i]['quotient_graph_node']\n        list_clusters_qg_traversed.append(n)\n\n    def count_to_dict(lst):\n        return {k: lst.count(k) for k in lst}\n\n    dict = count_to_dict(list_clusters_qg_traversed)\n    list_stem2 = []\n    for key, value in dict.items():\n        if value &gt; minimumpoint:\n            list_stem2.append(key)\n    list_stem1 = list(dict.fromkeys(list_clusters_qg_traversed))\n\n    quotient_graph_compute_direction_mean(QG)\n    quotient_graph_compute_direction_standard_deviation(QG)\n    final_list_stem = copy.deepcopy(list_stem2)\n    for node in list_stem2:\n        if QG.nodes[node]['dir_gradient_angle_mean'] &lt; np.cos(np.radians(angle_to_stop)):\n            final_list_stem.remove(node)\n            QG.nodes[node]['viterbi_class'] = classnumberanomaly\n\n    nodi = 0\n    final_list_stem_clean = []\n    while nodi &lt;= (len(final_list_stem) - 2):\n        e = (final_list_stem[nodi], final_list_stem[nodi + 1])\n        v1 = QG.nodes[e[0]]['dir_gradient_mean']\n        v2 = QG.nodes[e[1]]['dir_gradient_mean']\n        dot = v1[0] * v2[0] + v1[1] * v2[1] + v1[2] * v2[2]\n        energy = 1 - dot\n        print(e)\n        print(energy)\n        if energy &gt; energy_to_stop:\n            final_list_stem_clean = final_list_stem[:nodi + 1]\n            nodi = len(final_list_stem) + 2\n        else:\n            final_list_stem_clean = final_list_stem\n            nodi += 1\n\n    final_list_stem_clean.insert(0, G.nodes[ptsource]['quotient_graph_node'])\n    for n in final_list_stem_clean:\n        QG.nodes[n]['viterbi_class'] = classnumberstem\n\n    transfer_quotientgraph_infos_on_riemanian_graph(QG=QG, info='viterbi_class')\n\n    return final_list_stem_clean\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.differenciate_apex_limb","title":"differenciate_apex_limb","text":"<pre><code>differenciate_apex_limb(QG, attribute_class='viterbi_class', number_leaves_limb=1, new_apex_class=4)\n</code></pre> <p>Differentiate the apex limb based on the given attribute class and number of leaves.</p> <p>This function updates the provided graph by reassigning the specified attribute class for nodes that meet specific conditions. It identifies nodes (limbs) in the graph based on the attribute value and further modifies their attribute class if certain criteria regarding local extremum of the Fiedler vector are satisfied.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>A graph-like object with nodes carrying specific attributes. Typically, this should be a custom graph object that includes attributes such as <code>number_of_local_Fiedler_extremum</code> in its nodes.</p> </li> <li> <code>attribute_class</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The attribute class in the graph's node dictionary to check and update. Default is <code>'viterbi_class'</code>.</p> </li> <li> <code>number_leaves_limb</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The value of <code>attribute_class</code> used to identify the nodes of interest (limbs). Only nodes where the specific attribute class has this value will be processed. Default is <code>1</code>.</p> </li> <li> <code>new_apex_class</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>The new value for the attribute class to assign to the nodes that satisfy the conditions. Default is <code>4</code>.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def differenciate_apex_limb(QG, attribute_class='viterbi_class', number_leaves_limb=1, new_apex_class=4):\n    \"\"\"Differentiate the apex limb based on the given attribute class and number of leaves.\n\n    This function updates the provided graph by reassigning the specified attribute\n    class for nodes that meet specific conditions. It identifies nodes (limbs) in the\n    graph based on the attribute value and further modifies their attribute class if\n    certain criteria regarding local extremum of the Fiedler vector are satisfied.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        A graph-like object with nodes carrying specific attributes. Typically,\n        this should be a custom graph object that includes attributes such as\n        `number_of_local_Fiedler_extremum` in its nodes.\n    attribute_class : str, optional\n        The attribute class in the graph's node dictionary to check and update.\n        Default is ``'viterbi_class'``.\n    number_leaves_limb : int, optional\n        The value of `attribute_class` used to identify the nodes of interest\n        (limbs). Only nodes where the specific attribute class has this value\n        will be processed. Default is ``1``.\n    new_apex_class : int, optional\n        The new value for the attribute class to assign to the nodes that satisfy\n        the conditions. Default is ``4``.\n    \"\"\"\n    QG.count_local_extremum_of_Fiedler()\n    list_limbs = [x for x, y in QG.nodes(data=True) if y[attribute_class] == number_leaves_limb]\n    for l in list_limbs:\n        if QG.nodes[l]['number_of_local_Fiedler_extremum'] &gt; 1:\n            QG.nodes[l][attribute_class] = new_apex_class\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.maj_weight_semantics","title":"maj_weight_semantics","text":"<pre><code>maj_weight_semantics(QG, class_attribute='viterbi_class', class_limb=1, class_mainstem=3, class_petiol=5, class_apex=4, class_branch=6, weight_petiol_petiol=0, weight_petiol_apex=10000, weight_branch_limb=10000)\n</code></pre> <p>Adjusts edge weights in a graph based on semantic class relationships.</p> <p>This function considers semantic relationships between different graph node classes and modifies the edge weight accordingly. It specifically targets edges connecting nodes with defined class combinations, and assigns a new weight to them based on the given parameters.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>The input graph where the semantic weights of edges will be modified. Nodes of the graph should include the attribute specified in <code>class_attribute</code> to determine their semantic class.</p> </li> <li> <code>class_attribute</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The name of the node attribute that represents the semantic class of the node. Default is <code>'viterbi_class'</code>.</p> </li> <li> <code>class_limb</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Represents the integer code for the 'limb' semantic class. Default: <code>1</code></p> </li> <li> <code>class_mainstem</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>Represents the integer code for the 'mainstem' semantic class. Default: <code>3</code></p> </li> <li> <code>class_petiol</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Represents the integer code for the 'petiol' semantic class. Default: <code>5</code></p> </li> <li> <code>class_apex</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>Represents the integer code for the 'apex' semantic class. Default: <code>4</code></p> </li> <li> <code>class_branch</code>               (<code>int</code>, default:                   <code>6</code> )           \u2013            <p>Represents the integer code for the 'branch' semantic class. Default: <code>6</code></p> </li> <li> <code>weight_petiol_petiol</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The weight representing edges between two 'petiol' class nodes. Default: <code>0</code>.</p> </li> <li> <code>weight_petiol_apex</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>The weight representing edges connecting a 'petiol' class node to an 'apex' class node. Default: <code>10000</code>.</p> </li> <li> <code>weight_branch_limb</code>               (<code>int</code>, default:                   <code>10000</code> )           \u2013            <p>The weight representing edges connecting a 'branch' class node to a 'limb' class node. Default: <code>10000</code>.</p> </li> </ul> Notes <p>This function modifies the input graph in-place by adding or updating the 'weight_sem_paths' attribute on edges based on their connected nodes' semantic classes.</p> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def maj_weight_semantics(QG, class_attribute='viterbi_class', class_limb=1, class_mainstem=3, class_petiol=5,\n                         class_apex=4, class_branch=6,\n                         weight_petiol_petiol=0, weight_petiol_apex=10000, weight_branch_limb=10000):\n    \"\"\"Adjusts edge weights in a graph based on semantic class relationships.\n\n    This function considers semantic relationships between different graph node\n    classes and modifies the edge weight accordingly. It specifically targets\n    edges connecting nodes with defined class combinations, and assigns a new\n    weight to them based on the given parameters.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        The input graph where the semantic weights of edges will be modified.\n        Nodes of the graph should include the attribute specified in\n        `class_attribute` to determine their semantic class.\n    class_attribute : str\n        The name of the node attribute that represents the semantic class of the node.\n        Default is ``'viterbi_class'``.\n    class_limb : int, optional\n        Represents the integer code for the 'limb' semantic class.\n        Default: `1`\n    class_mainstem : int, optional\n        Represents the integer code for the 'mainstem' semantic class.\n        Default: `3`\n    class_petiol : int, optional\n        Represents the integer code for the 'petiol' semantic class.\n        Default: `5`\n    class_apex : int, optional\n        Represents the integer code for the 'apex' semantic class.\n        Default: `4`\n    class_branch : int, optional\n        Represents the integer code for the 'branch' semantic class.\n        Default: `6`\n    weight_petiol_petiol : int, optional\n        The weight representing edges between two 'petiol' class nodes.\n        Default: `0`.\n    weight_petiol_apex : int, optional\n        The weight representing edges connecting a 'petiol' class node to an 'apex' class node.\n        Default: `10000`.\n    weight_branch_limb : int, optional\n        The weight representing edges connecting a 'branch' class node to a 'limb' class node.\n        Default: `10000`.\n\n    Notes\n    -------\n    This function modifies the input graph in-place by adding or updating the 'weight_sem_paths' attribute\n    on edges based on their connected nodes' semantic classes.\n    \"\"\"\n    for e in QG.edges():\n        c1 = QG.nodes[e[0]][class_attribute]\n        c2 = QG.nodes[e[1]][class_attribute]\n        l = [c1, c2]\n        if set(l) == {class_branch, class_limb}:\n            QG.edges[e]['weight_sem_paths'] = weight_branch_limb\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.merge_remaining_clusters","title":"merge_remaining_clusters","text":"<pre><code>merge_remaining_clusters(quotientgraph, remaining_clusters_class=0, class_attribute='viterbi_class')\n</code></pre> <p>Merges clusters in a given quotient graph based on inter-class metadata and updates the point cloud graph accordingly. The function operates on nodes belonging to the specified 'remaining_clusters_class' and involves reassigning nodes in the point cloud graph to new clusters after merging.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph in which clusters are to be merged. This is a networkx graph object containing nodes and edges, along with associated metadata.</p> </li> <li> <code>remaining_clusters_class</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The class value used to identify nodes in the quotient graph that belong to the target cluster to be merged. Default is <code>0</code>.</p> </li> <li> <code>class_attribute</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The attribute name in the quotient graph's node metadata used to distinguish clusters. Nodes with the specified 'remaining_clusters_class' value for this attribute will be targeted for merging. Default is <code>'viterbi_class'</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>QuotientGraph</code>           \u2013            <p>Updated quotient graph after merging clusters. The graph includes revised node and edge metadata based on the merging process.</p> </li> </ul> Notes <ul> <li>Clusters are merged based on the most frequent inter-class links (metadata). If the most frequent linked   cluster also belongs to the target class to be merged, the second-most frequent linked cluster is chosen.   This ensures proper merging behavior.</li> <li>Updates are propagated to the point cloud graph (<code>point_cloud_graph</code>) within the quotient graph. Nodes in   the point cloud graph corresponding to the merged clusters are reassigned to the new cluster.</li> <li>Edge attributes 'useful_path_shortest' are preserved during the merging process. In cases of conflicting data   between nodes being merged, priority is given to attributes of the original edges in the quotient graph.</li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def merge_remaining_clusters(quotientgraph, remaining_clusters_class=0, class_attribute='viterbi_class'):\n    \"\"\"\n    Merges clusters in a given quotient graph based on inter-class metadata and updates the point cloud graph\n    accordingly. The function operates on nodes belonging to the specified 'remaining_clusters_class' and involves\n    reassigning nodes in the point cloud graph to new clusters after merging.\n\n    Parameters\n    ----------\n    quotientgraph : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph in which clusters are to be merged. This is a networkx graph object containing nodes\n        and edges, along with associated metadata.\n    remaining_clusters_class : int, optional\n        The class value used to identify nodes in the quotient graph that belong to the target cluster to\n        be merged. Default is ``0``.\n    class_attribute : str, optional\n        The attribute name in the quotient graph's node metadata used to distinguish clusters. Nodes with the\n        specified 'remaining_clusters_class' value for this attribute will be targeted for merging. Default\n        is ``'viterbi_class'``.\n\n    Returns\n    -------\n    spectral_clustering.quotientgraph.QuotientGraph\n        Updated quotient graph after merging clusters. The graph includes revised node and edge metadata based on\n        the merging process.\n\n    Notes\n    -----\n    - Clusters are merged based on the most frequent inter-class links (metadata). If the most frequent linked\n      cluster also belongs to the target class to be merged, the second-most frequent linked cluster is chosen.\n      This ensures proper merging behavior.\n    - Updates are propagated to the point cloud graph (`point_cloud_graph`) within the quotient graph. Nodes in\n      the point cloud graph corresponding to the merged clusters are reassigned to the new cluster.\n    - Edge attributes 'useful_path_shortest' are preserved during the merging process. In cases of conflicting data\n      between nodes being merged, priority is given to attributes of the original edges in the quotient graph.\n\n    \"\"\"\n    list_clusters = [x for x, y in quotientgraph.nodes(data=True) if y[class_attribute] == remaining_clusters_class]\n    print(list_clusters)\n    G = quotientgraph.point_cloud_graph\n\n    for u in list_clusters:\n        count = quotientgraph.compute_quotientgraph_metadata_on_a_node_interclass(u)\n        print(count)\n        max_class_o = max(count, key=count.get)\n        max_class = max_class_o\n        # deal with possibility of max_class_ another class to merge. In that case, second best linked is chosent\n        # if only linked to another class to merge, merge with this one.\n        while max_class in list_clusters and bool(count) and len(count) &gt; 1:\n            count.pop(max_class)\n            max_class = max(count, key=count.get)\n        if bool(count) is False or len(count) == 1:\n            max_class = max_class_o\n\n        new_cluster = max_class\n        print(new_cluster)\n        list_G_nodes_to_change = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == u]\n        for g in list_G_nodes_to_change:\n            G.nodes[g]['quotient_graph_node'] = new_cluster\n\n        dict1 = {}\n        for e in quotientgraph.edges(new_cluster):\n            dict1[e] = quotientgraph.edges[e]['useful_path_shortest']\n        quotientgraph = nx.contracted_nodes(quotientgraph, new_cluster, u, self_loops=False)\n        quotientgraph.point_cloud_graph = G\n        dict2 = {}\n        for e in quotientgraph.edges(new_cluster):\n            dict2[e] = quotientgraph.edges[e]['useful_path_shortest']\n            if e in dict1.keys():\n                quotientgraph.edges[e]['useful_path_shortest'] = dict1[e]\n        print(dict1)\n        print(dict2)\n\n    return quotientgraph\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.minimum_spanning_tree_quotientgraph_semantics","title":"minimum_spanning_tree_quotientgraph_semantics","text":"<pre><code>minimum_spanning_tree_quotientgraph_semantics(quotientgraph)\n</code></pre> <p>Compute the minimum spanning tree (MST) of a quotient graph with semantic-based weight adjustments.</p> <p>This function processes a quotient graph by assigning semantic weights to its edges based on the semantic labels of the connected nodes. Edges connecting nodes with the same semantic label are given a higher weight than those connecting nodes with different semantic labels. Subsequently, the function computes the MST of the adjusted quotient graph using Kruskal's algorithm.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph on which the MST and weight adjustments should be computed. The graph must have nodes with a 'semantic_label' property and edges that need a 'semantic_weight' property. Additionally, it must incorporate attributes for the point cloud graph used in computation.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>QG_t2</code> (              <code>Graph</code> )          \u2013            <p>The resultant minimum spanning tree of the quotient graph, where weights are determined by semantic-based criteria.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def minimum_spanning_tree_quotientgraph_semantics(quotientgraph):\n    \"\"\"\n    Compute the minimum spanning tree (MST) of a quotient graph with semantic-based\n    weight adjustments.\n\n    This function processes a quotient graph by assigning semantic weights to its\n    edges based on the semantic labels of the connected nodes. Edges connecting\n    nodes with the same semantic label are given a higher weight than those\n    connecting nodes with different semantic labels. Subsequently, the function\n    computes the MST of the adjusted quotient graph using Kruskal's algorithm.\n\n    Parameters\n    ----------\n    quotientgraph : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph on which the MST and weight adjustments should be\n        computed. The graph must have nodes with a 'semantic_label' property and\n        edges that need a 'semantic_weight' property. Additionally, it must\n        incorporate attributes for the point cloud graph used in computation.\n\n    Returns\n    -------\n    QG_t2 : networkx.Graph\n        The resultant minimum spanning tree of the quotient graph, where weights\n        are determined by semantic-based criteria.\n    \"\"\"\n    define_semantic_classes(quotientgraph)\n    for (u, v) in quotientgraph.edges:\n        if quotientgraph.nodes[u]['semantic_label'] == quotientgraph.nodes[v]['semantic_label']:\n            quotientgraph.edges[u, v]['semantic_weight'] = 50\n        else:\n            quotientgraph.edges[u, v]['semantic_weight'] = 1\n    compute_quotient_graph_mean_attribute_from_points(quotientgraph.point_cloud_graph, quotientgraph,\n                                                      attribute='quotient_graph_node')\n    QG_t2 = nx.minimum_spanning_tree(quotientgraph, algorithm='kruskal', weight='semantic_weight')\n\n    return QG_t2\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.remove_edges_useful_paths","title":"remove_edges_useful_paths","text":"<pre><code>remove_edges_useful_paths(QG)\n</code></pre> <p>Removes edges that are not marked as useful from the input graph.</p> <p>This function takes a graph as input and creates a deep copy of it. It iterates through all edges in the copied graph, and if an edge is marked as not part of a useful path (as indicated by the 'useful_path_shortest' attribute), it removes that edge from the original graph.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>Input graph from which edges not marked as useful will be removed. The graph must contain an attribute 'useful_path_shortest' on edges indicating whether the edge belongs to a useful shortest path or not.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def remove_edges_useful_paths(QG):\n    \"\"\"Removes edges that are not marked as useful from the input graph.\n\n    This function takes a graph as input and creates a deep copy of it. It iterates\n    through all edges in the copied graph, and if an edge is marked as not part of a\n    useful path (as indicated by the 'useful_path_shortest' attribute), it removes\n    that edge from the original graph.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        Input graph from which edges not marked as useful will be removed. The graph\n        must contain an attribute 'useful_path_shortest' on edges indicating whether\n        the edge belongs to a useful shortest path or not.\n    \"\"\"\n    FG = copy.deepcopy(QG)\n    d = FG.edges()\n    for e in d:\n        if FG.edges[e]['useful_path_shortest'] is False:\n            QG.remove_edge(*e)\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.shortest_paths_from_apex_det_branch","title":"shortest_paths_from_apex_det_branch","text":"<pre><code>shortest_paths_from_apex_det_branch(QG, root_point_riemanian, class_attribute='viterbi_class', weight='weight_sem_paths', class_apex=4, class_branch=0, class_mainstem=3, new_class_branch=6)\n</code></pre> <p>Shortest paths calculation and attribute mutation for apex-derived branches.</p> <p>This function calculates shortest paths in a point-cloud graph (QG) from nodes classified as \"apex\" to the specified root point, utilizing a Riemannian metric. It then updates node attributes by reclassifying nodes belonging to a specified class and sets edge attributes for edges on these paths as useful.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph representing the point-cloud structure. It should contain node attributes, including those specified in <code>class_attribute</code>, and edge attributes for weights used in shortest path computation.</p> </li> <li> <code>root_point_riemanian</code>               (<code>int or string</code>)           \u2013            <p>The identifier of the root node within the quotient graph. This is the target node for computing shortest paths using Dijkstra's algorithm.</p> </li> <li> <code>class_attribute</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The name of the node attribute used to determine and reclassify nodes for processing. Default is <code>'viterbi_class'</code>.</p> </li> <li> <code>weight</code>               (<code>str</code>, default:                   <code>'weight_sem_paths'</code> )           \u2013            <p>The edge attribute name representing edge weights for the shortest path computation. Default is <code>'weight_sem_paths'</code>.</p> </li> <li> <code>class_apex</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>The integer value of the node attribute used to identify \"apex\" nodes. Default is <code>4</code>.</p> </li> <li> <code>class_branch</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The integer value of the node attribute for nodes belonging to the original branch class which will be reclassified. Default is <code>0</code>.</p> </li> <li> <code>class_mainstem</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>This parameter exists but is not actively used in the function logic. Typically might relate to other classifications within the graph structure. Default is <code>3</code>.</p> </li> <li> <code>new_class_branch</code>               (<code>int</code>, default:                   <code>6</code> )           \u2013            <p>The new classification value assigned to nodes that belonged to the <code>class_branch</code> group encountered along the shortest paths. Default is <code>6</code>.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def shortest_paths_from_apex_det_branch(QG, root_point_riemanian, class_attribute='viterbi_class',\n                                        weight='weight_sem_paths', class_apex=4, class_branch=0, class_mainstem=3,\n                                        new_class_branch=6):\n    \"\"\"Shortest paths calculation and attribute mutation for apex-derived branches.\n\n    This function calculates shortest paths in a point-cloud graph (QG) from nodes classified\n    as \"apex\" to the specified root point, utilizing a Riemannian metric. It then updates\n    node attributes by reclassifying nodes belonging to a specified class and sets edge attributes\n    for edges on these paths as useful.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        The quotient graph representing the point-cloud structure. It should contain node\n        attributes, including those specified in `class_attribute`, and edge attributes for\n        weights used in shortest path computation.\n    root_point_riemanian : int or string\n        The identifier of the root node within the quotient graph. This is the target node for\n        computing shortest paths using Dijkstra's algorithm.\n    class_attribute : str, optional\n        The name of the node attribute used to determine and reclassify nodes for processing.\n        Default is ``'viterbi_class'``.\n    weight : str, optional\n        The edge attribute name representing edge weights for the shortest path computation.\n        Default is ``'weight_sem_paths'``.\n    class_apex : int, optional\n        The integer value of the node attribute used to identify \"apex\" nodes.\n        Default is ``4``.\n    class_branch : int, optional\n        The integer value of the node attribute for nodes belonging to the original branch class\n        which will be reclassified.\n        Default is ``0``.\n    class_mainstem : int, optional\n        This parameter exists but is not actively used in the function logic. Typically might\n        relate to other classifications within the graph structure.\n        Default is ``3``.\n    new_class_branch : int, optional\n        The new classification value assigned to nodes that belonged to the `class_branch` group\n        encountered along the shortest paths.\n        Default is ``6``.\n    \"\"\"\n    G = QG.point_cloud_graph\n    list_apex = [x for x, y in QG.nodes(data=True) if y[class_attribute] == class_apex]\n    for e in QG.edges():\n        QG.edges[e]['useful_path_shortest'] = False\n    for leaf in list_apex:\n        path = nx.dijkstra_path(QG, leaf, G.nodes[root_point_riemanian][\"quotient_graph_node\"], weight=weight)\n        print(path)\n        for n in path:\n            if QG.nodes[n][class_attribute] == class_branch:\n                QG.nodes[n][class_attribute] = new_class_branch\n        for i in range(len(path) - 1):\n            if QG.has_edge(path[i], path[i + 1]):\n                e = (path[i], path[i + 1])\n            else:\n                e = (path[i + 1], path[i])\n            QG.edges[e]['useful_path_shortest'] = True\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.shortest_paths_from_limbs_det_petiol","title":"shortest_paths_from_limbs_det_petiol","text":"<pre><code>shortest_paths_from_limbs_det_petiol(QG, root_point_riemanian, class_attribute='viterbi_class', weight='weight_sem_paths', class_limb=1, class_linear=0, class_mainstem=3, new_class_petiol=5)\n</code></pre> <p>Computes shortest paths from limb nodes to the root point in the Riemannian tree graph and updates node and edge attributes accordingly.</p> <p>This function identifies limb nodes in the graph based on their classification attribute and calculates the shortest path from these limb nodes to a specified root point in the Riemannian tree graph. During the path computation, nodes classified as linear are reclassified to a new specified petiol class. Additionally, edges along these paths are marked as part of a useful shortest path.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>The input graph representing the point cloud or Riemannian tree structure.</p> </li> <li> <code>root_point_riemanian</code>               (<code>Any</code>)           \u2013            <p>The key of the root node in the graph from which shortest paths are computed.</p> </li> <li> <code>class_attribute</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The node attribute in the graph used for classification. Default is <code>'viterbi_class'</code>.</p> </li> <li> <code>weight</code>               (<code>str</code>, default:                   <code>'weight_sem_paths'</code> )           \u2013            <p>The edge attribute used to calculate shortest paths' weights Default is <code>'weight_sem_paths'</code>.</p> </li> <li> <code>class_limb</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The classification value of nodes considered as limb nodes Default is <code>1</code>.</p> </li> <li> <code>class_linear</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>The classification value of nodes considered linear in the graph Default is <code>0</code>.</p> </li> <li> <code>class_mainstem</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>The classification value of nodes considered as the main stem in the graph Default is <code>3</code>.</p> </li> <li> <code>new_class_petiol</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>The classification value to which linear nodes are reclassified during path traversal Default is <code>5</code>.</p> </li> </ul> Notes <p>The function updates the graph <code>QG</code> in place by modifying node and edge attributes.</p> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def shortest_paths_from_limbs_det_petiol(QG, root_point_riemanian, class_attribute='viterbi_class',\n                                         weight='weight_sem_paths', class_limb=1, class_linear=0, class_mainstem=3,\n                                         new_class_petiol=5):\n    \"\"\"\n    Computes shortest paths from limb nodes to the root point in the Riemannian tree graph and updates\n    node and edge attributes accordingly.\n\n    This function identifies limb nodes in the graph based on their classification attribute and calculates\n    the shortest path from these limb nodes to a specified root point in the Riemannian tree graph.\n    During the path computation, nodes classified as linear are reclassified to a new specified petiol class.\n    Additionally, edges along these paths are marked as part of a useful shortest path.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        The input graph representing the point cloud or Riemannian tree structure.\n    root_point_riemanian : Any\n        The key of the root node in the graph from which shortest paths are computed.\n    class_attribute : str, optional\n        The node attribute in the graph used for classification.\n        Default is ``'viterbi_class'``.\n    weight : str, optional\n        The edge attribute used to calculate shortest paths' weights\n        Default is ``'weight_sem_paths'``.\n    class_limb : int, optional\n        The classification value of nodes considered as limb nodes\n        Default is ``1``.\n    class_linear : int, optional\n        The classification value of nodes considered linear in the graph\n        Default is ``0``.\n    class_mainstem : int, optional\n        The classification value of nodes considered as the main stem in the graph\n        Default is ``3``.\n    new_class_petiol : int, optional\n        The classification value to which linear nodes are reclassified during path traversal\n        Default is ``5``.\n\n    Notes\n    -----\n    The function updates the graph `QG` in place by modifying node and edge attributes.\n    \"\"\"\n    G = QG.point_cloud_graph\n\n    list_limb = [x for x, y in QG.nodes(data=True) if y[class_attribute] == class_limb]\n    for leaf in list_limb:\n        path = nx.dijkstra_path(QG, leaf, G.nodes[root_point_riemanian][\"quotient_graph_node\"], weight=weight)\n        for n in path:\n            if QG.nodes[n][class_attribute] == class_linear:\n                QG.nodes[n][class_attribute] = new_class_petiol\n        for i in range(len(path) - 1):\n            if QG.has_edge(path[i], path[i + 1]):\n                e = (path[i], path[i + 1])\n            else:\n                e = (path[i + 1], path[i])\n            QG.edges[e]['useful_path_shortest'] = True\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.stem_detection_with_quotite_leaves","title":"stem_detection_with_quotite_leaves","text":"<pre><code>stem_detection_with_quotite_leaves(QG, list_leaves3, list_apex, list_of_linear, root_point_riemanian, new_class_stem=3)\n</code></pre> <p>Detects and classifies the main stem of a graph based on leaf quotients and other metrics.</p> <p>This function identifies the main stem of an input graph using attributes like leaf quotients, apex nodes, and linear node structures. The identified stem is classified and its attributes are exported for further use. The function works by analyzing subgraphs, calculating paths, and determining connections between nodes to identify the main stem.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>A quotient graph representation of the point cloud graph.</p> </li> <li> <code>list_leaves3</code>               (<code>list</code>)           \u2013            <p>A list of end-leaf nodes in the quotient graph.</p> </li> <li> <code>list_apex</code>               (<code>list</code>)           \u2013            <p>A list of apex nodes to consider. If empty, list_leaves3 is used by default.</p> </li> <li> <code>list_of_linear</code>               (<code>list</code>)           \u2013            <p>A list of nodes representing a linear path or structure in the graph.</p> </li> <li> <code>root_point_riemanian</code>               (<code>int</code>)           \u2013            <p>Node id corresponding to the root point in the Riemannian graph representation.</p> </li> <li> <code>new_class_stem</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>An integer value used to classify the main stem nodes after detection. Default is <code>3</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>A list of nodes forming the identified and classified main stem of the graph.</p> </li> </ul> Notes <ul> <li>The function depends heavily on networkx for graph operations such as   subgraph creation, path calculations, and attribute manipulations.</li> <li>Subgraphs are dynamically created to analyze and validate paths.</li> <li>Detected stem nodes are marked with the provided classification value in   the quotient graph <code>viterbi_class</code> attribute.</li> <li>The exported attributes can be used for further semantic analysis or visualization.</li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def stem_detection_with_quotite_leaves(QG, list_leaves3, list_apex, list_of_linear, root_point_riemanian,\n                                       new_class_stem=3):\n    \"\"\"\n    Detects and classifies the main stem of a graph based on leaf quotients and other metrics.\n\n    This function identifies the main stem of an input graph using attributes like\n    leaf quotients, apex nodes, and linear node structures. The identified stem\n    is classified and its attributes are exported for further use. The function\n    works by analyzing subgraphs, calculating paths, and determining connections\n    between nodes to identify the main stem.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        A quotient graph representation of the point cloud graph.\n    list_leaves3 : list\n        A list of end-leaf nodes in the quotient graph.\n    list_apex : list\n        A list of apex nodes to consider. If empty, list_leaves3 is used by default.\n    list_of_linear : list\n        A list of nodes representing a linear path or structure in the graph.\n    root_point_riemanian : int\n        Node id corresponding to the root point in the Riemannian graph representation.\n    new_class_stem : int, optional\n        An integer value used to classify the main stem nodes after detection.\n        Default is ``3``.\n\n    Returns\n    -------\n    list\n        A list of nodes forming the identified and classified main stem of the graph.\n\n    Notes\n    -----\n    - The function depends heavily on networkx for graph operations such as\n      subgraph creation, path calculations, and attribute manipulations.\n    - Subgraphs are dynamically created to analyze and validate paths.\n    - Detected stem nodes are marked with the provided classification value in\n      the quotient graph `viterbi_class` attribute.\n    - The exported attributes can be used for further semantic analysis or visualization.\n    \"\"\"\n    calculate_leaf_quotients(QG, list_leaves3, list_of_linear, root_point_riemanian)\n    G = QG.point_cloud_graph\n    list_length = []\n    if list_apex:\n        list_end = list_apex\n    else:\n        list_end = list_leaves3\n\n    for leaf in list_end:\n        sub_qg = nx.subgraph(QG, list_of_linear + [leaf] + [G.nodes[root_point_riemanian][\"quotient_graph_node\"]])\n        display_and_export_quotient_graph_matplotlib(qg=sub_qg, node_sizes=20,\n                                                     name=\"sub_graphsclass_feuilles_sur_noeuds\" + str(leaf),\n                                                     data_on_nodes='viterbi_class', data=True,\n                                                     attributekmeans4clusters=False)\n\n        if nx.has_path(sub_qg, leaf, G.nodes[root_point_riemanian][\"quotient_graph_node\"]):\n            path = nx.dijkstra_path(sub_qg, leaf, G.nodes[root_point_riemanian][\"quotient_graph_node\"],\n                                    weight='distance_centroides')\n        else:\n            path = nx.dijkstra_path(QG, leaf, G.nodes[root_point_riemanian][\"quotient_graph_node\"],\n                                    weight='distance_centroides')\n        pathleafquantity = []\n        paths = []\n        for p in path:\n            pathleafquantity.append(QG.nodes[p]['leaf_quotient_n'])\n            paths.append(path)\n        print(pathleafquantity)\n        print(set(pathleafquantity))\n        lengthpath = sum(list(set(pathleafquantity)))\n        list_length.append(lengthpath)\n        print(path)\n        print(lengthpath)\n\n    leafend = list_end[list_length.index(max(list_length))]\n    # path_final = paths[]\n\n    list_stem_full = nx.dijkstra_path(QG, G.nodes[root_point_riemanian][\"quotient_graph_node\"], leafend,\n                                      weight='distance_centroides')\n    list_stem = list_stem_full\n    print('list_stem')\n    print(list_stem)\n    previous = 0\n    \"\"\"\n    maxim = QG.nodes[G.nodes[root_point_riemanian][\"quotient_graph_node\"]]['leaf_quotient_n']\n    for n in list_stem_full:\n        if maxim &gt;= QG.nodes[n]['leaf_quotient_n']:\n            maxim = QG.nodes[n]['leaf_quotient_n']\n            prev = n\n        else:\n            list_stem.pop(prev)\n    \"\"\"\n    del list_stem[-1]\n    for n in list_stem:\n        # if n not in list_leaves3:\n        QG.nodes[n][\"viterbi_class\"] = new_class_stem\n\n    export_quotient_graph_attribute_on_point_cloud(QG, attribute='viterbi_class', name='semantic_')\n    return list_stem\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.topology_control","title":"topology_control","text":"<pre><code>topology_control(quotient_graph, attribute_class_control='viterbi_class', class_stem=3, class_petiols=5, class_limb=1, class_apex=4, error_norm=10, error_dir=11)\n</code></pre> <p>Adjusts node attributes in a quotient graph based on the class control rules.</p> <p>This function modifies the node attributes in the provided quotient graph (QG) according to specific rules associated with node classifications such as stems, petioles, limbs, and apex. Adjustments are made to enforce corrections for nodes incorrectly classified with high degrees or inappropriate connections. The corrections are applied by reassigning specific error classification values.</p> <p>Parameters:</p> <ul> <li> <code>quotient_graph</code>               (<code>QuotientGraph</code>)           \u2013            <p>A NetworkX graph where each node has attributes, including the classification attribute used for controlling topology.</p> </li> <li> <code>attribute_class_control</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>Name of the node attribute that represents the class to control. The default is <code>'viterbi_class'</code>.</p> </li> <li> <code>class_stem</code>               (<code>int</code>, default:                   <code>3</code> )           \u2013            <p>Numerical identifier representing the class of stem nodes. The default is <code>3</code>.</p> </li> <li> <code>class_petiols</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>Numerical identifier representing the class of petiole nodes. The default is <code>5</code>.</p> </li> <li> <code>class_limb</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Numerical identifier representing the class of limb nodes. The default is <code>1</code>.</p> </li> <li> <code>class_apex</code>               (<code>int</code>, default:                   <code>4</code> )           \u2013            <p>Numerical identifier representing the class of apex nodes. The default is <code>4</code>.</p> </li> <li> <code>error_norm</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>Numerical identifier used to reclassify nodes that violate the connection rules for limb or apex nodes. The default is <code>10</code>.</p> </li> <li> <code>error_dir</code>               (<code>int</code>, default:                   <code>11</code> )           \u2013            <p>Numerical identifier used to reclassify nodes with high degree that violate the class petioles rules. The default is <code>11</code>.</p> </li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def topology_control(quotient_graph, attribute_class_control='viterbi_class', class_stem=3, class_petiols=5,\n                     class_limb=1, class_apex=4, error_norm=10, error_dir=11):\n    \"\"\"Adjusts node attributes in a quotient graph based on the class control rules.\n\n    This function modifies the node attributes in the provided quotient graph\n    (QG) according to specific rules associated with node classifications such as\n    stems, petioles, limbs, and apex. Adjustments are made to enforce corrections\n    for nodes incorrectly classified with high degrees or inappropriate connections.\n    The corrections are applied by reassigning specific error classification values.\n\n    Parameters\n    ----------\n    quotient_graph : spectral_clustering.quotientgraph.QuotientGraph\n        A NetworkX graph where each node has attributes, including the\n        classification attribute used for controlling topology.\n    attribute_class_control : str, optional\n        Name of the node attribute that represents the class to control.\n        The default is ``'viterbi_class'``.\n    class_stem : int, optional\n        Numerical identifier representing the class of stem nodes.\n        The default is ``3``.\n    class_petiols : int, optional\n        Numerical identifier representing the class of petiole nodes.\n        The default is ``5``.\n    class_limb : int, optional\n        Numerical identifier representing the class of limb nodes.\n        The default is ``1``.\n    class_apex : int, optional\n        Numerical identifier representing the class of apex nodes.\n        The default is ``4``.\n    error_norm : int, optional\n        Numerical identifier used to reclassify nodes that violate the\n        connection rules for limb or apex nodes. The default is ``10``.\n    error_dir : int, optional\n        Numerical identifier used to reclassify nodes with high degree\n        that violate the class petioles rules. The default is ``11``.\n    \"\"\"\n    QG = quotient_graph\n    # check leaves connected to stem\n    stem = [x for x, y in QG.nodes(data=True) if y[attribute_class_control] == class_stem]\n    for n in QG[stem[0]]:\n        if QG.nodes[n][attribute_class_control] == class_limb or QG.nodes[n][attribute_class_control] == class_apex:\n            QG.nodes[n][attribute_class_control] = error_norm\n\n    petiols = [x for x, y in QG.nodes(data=True) if y[attribute_class_control] == class_petiols]\n    for n in petiols:\n        if QG.degree(n) &gt;= 3:\n            QG.nodes[n][attribute_class_control] = error_dir\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.treat_topology_error","title":"treat_topology_error","text":"<pre><code>treat_topology_error(quotient_graph, attribute_class_control='viterbi_class', error=5, way_to_treat='direction', number_of_cluster_tested=20)\n</code></pre> <p>Handles errors in the topological attributes of a quotient graph by identifying problematic nodes and resegmenting them using a clustering approach. This method applies an elbow method for clustering to ensure appropriate grouping of nodes based on specified attributes.</p> <p>Parameters:</p> <ul> <li> <code>quotient_graph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The input quotient graph containing nodes with labeled attributes to analyze and correct.</p> </li> <li> <code>attribute_class_control</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The attribute in quotient_graph's nodes that is examined to identify nodes with errors. Default is <code>'viterbi_class'</code>.</p> </li> <li> <code>error</code>               (<code>int</code>, default:                   <code>5</code> )           \u2013            <p>The specific error value in the attribute_class_control being targeted for treatment. Default is <code>5</code>.</p> </li> <li> <code>way_to_treat</code>               (<code>(direction, norm)</code>, default:                   <code>'direction'</code> )           \u2013            <p>Specifies the method to use for segmenting and treating erroneous nodes. If <code>'direction'</code>, the 'direction_gradient' attribute is used for resegmentation. If <code>'norm'</code>, the 'norm_gradient' attribute is used.</p> </li> <li> <code>number_of_cluster_tested</code>               (<code>int</code>, default:                   <code>20</code> )           \u2013            <p>The maximum number of clusters to test when applying the elbow method for clustering the nodes. Default is <code>20</code>.</p> </li> </ul> Notes <p>The method makes use of the resegment_nodes_with_elbow_method, which performs clustering on nodes based on their attributes. The attributes \u2018direction_gradient\u2019 or \u2018norm_gradient\u2019 are utilized depending on the <code>way_to_treat</code> parameter to guide the resegmentation process.</p> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def treat_topology_error(quotient_graph, attribute_class_control='viterbi_class', error=5, way_to_treat='direction',\n                         number_of_cluster_tested=20):\n    \"\"\"\n    Handles errors in the topological attributes of a quotient graph by identifying problematic nodes\n    and resegmenting them using a clustering approach. This method applies an elbow method for clustering\n    to ensure appropriate grouping of nodes based on specified attributes.\n\n    Parameters\n    ----------\n    quotient_graph : spectral_clustering.quotientgraph.QuotientGraph\n        The input quotient graph containing nodes with labeled attributes to analyze and correct.\n    attribute_class_control : str, optional\n        The attribute in quotient_graph's nodes that is examined to identify nodes with errors.\n        Default is ``'viterbi_class'``.\n    error : int, optional\n        The specific error value in the attribute_class_control being targeted for treatment.\n        Default is ``5``.\n    way_to_treat : {'direction', 'norm'}, optional, default='direction'\n        Specifies the method to use for segmenting and treating erroneous nodes.\n        If ``'direction'``, the 'direction_gradient' attribute is used for resegmentation.\n        If ``'norm'``, the 'norm_gradient' attribute is used.\n    number_of_cluster_tested : int, optional\n        The maximum number of clusters to test when applying the elbow method for clustering the nodes.\n        Default is ``20``.\n\n    Notes\n    -----\n    The method makes use of the resegment_nodes_with_elbow_method, which performs clustering on nodes\n    based on their attributes. The attributes \u2018direction_gradient\u2019 or \u2018norm_gradient\u2019 are utilized\n    depending on the `way_to_treat` parameter to guide the resegmentation process.\n    \"\"\"\n    QG = quotient_graph\n    nodes_to_treat = [x for x, y in QG.nodes(data=True) if y[attribute_class_control] == error]\n\n    if way_to_treat == 'direction':\n        resegment_nodes_with_elbow_method(QG, QG_nodes_to_rework=nodes_to_treat,\n                                          number_of_cluster_tested=number_of_cluster_tested,\n                                          attribute='direction_gradient', number_attribute=3, standardization=False)\n    elif way_to_treat == 'norm':\n        resegment_nodes_with_elbow_method(QG, QG_nodes_to_rework=nodes_to_treat,\n                                          number_of_cluster_tested=number_of_cluster_tested,\n                                          attribute='norm_gradient', number_attribute=1, standardization=False,\n                                          numer=1000)\n</code></pre>"},{"location":"reference/spectral_clustering/quotientgraph_semantics/#spectral_clustering.quotientgraph_semantics.weight_with_semantic","title":"weight_with_semantic","text":"<pre><code>weight_with_semantic(QG, class_attribute='viterbi_class', class_limb=1, class_mainstem=3, class_linear=0, class_apex=4, weight_limb_limb=10000, weight_apex_apex=10000, weight_apex_mainstem=10000, weight_limb_apex=10000, weight_limb_mainstem=10000, weight_linear_mainstem=0, weight_linear_linear=0, weight_linear_limb=0, weight_linear_apex=0)\n</code></pre> <p>Assigns semantic weights to the edges of a graph based on node classifications.</p> <p>This function iterates over all edges in the provided graph <code>QG</code> and assigns a weight to each edge depending on the classification of its connected nodes. The classification of the nodes is determined using the <code>class_attribute</code> parameter. Different combinations or sets of node categories (e.g., <code>class_limb</code>, <code>class_apex</code>) have corresponding weights that are specified as input arguments to the function.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>QuotientGraph</code>)           \u2013            <p>The graph whose edges will be assigned weights based on the semantic relationships between connected nodes.</p> </li> <li> <code>class_attribute</code>               (<code>str</code>, default:                   <code>'viterbi_class'</code> )           \u2013            <p>The node attribute in <code>QG</code> used to determine the category of the nodes. Default is <code>'viterbi_class'</code>.</p> </li> <li> <code>class_limb</code>               (<code>Any</code>, default:                   <code>1</code> )           \u2013            <p>A value representing the \"limb\" classification of a node. Default is <code>1</code>.</p> </li> <li> <code>class_mainstem</code>               (<code>Any</code>, default:                   <code>3</code> )           \u2013            <p>A value representing the \"mainstem\" classification of a node. Default is <code>3</code>.</p> </li> <li> <code>class_linear</code>               (<code>Any</code>, default:                   <code>0</code> )           \u2013            <p>A value representing the \"linear\" classification of a node. Default is <code>0</code>.</p> </li> <li> <code>class_apex</code>               (<code>Any</code>, default:                   <code>4</code> )           \u2013            <p>A value representing the \"apex\" classification of a node. Default is <code>4</code>.</p> </li> <li> <code>weight_limb_limb</code>               (<code>float</code>, default:                   <code>10000</code> )           \u2013            <p>The weight assigned to edges where both connected nodes are classified as \"limb\". Default is <code>10000</code>.</p> </li> <li> <code>weight_apex_apex</code>               (<code>float</code>, default:                   <code>10000</code> )           \u2013            <p>The weight assigned to edges where both connected nodes are classified as \"apex\". Default is <code>10000</code>.</p> </li> <li> <code>weight_apex_mainstem</code>               (<code>float</code>, default:                   <code>10000</code> )           \u2013            <p>The weight assigned to edges where one node is classified as \"apex\" and the other as \"mainstem\". Default is <code>10000</code>.</p> </li> <li> <code>weight_limb_apex</code>               (<code>float</code>, default:                   <code>10000</code> )           \u2013            <p>The weight assigned to edges where one node is classified as \"limb\" and the other as \"apex\". Default is <code>10000</code>.</p> </li> <li> <code>weight_limb_mainstem</code>               (<code>float</code>, default:                   <code>10000</code> )           \u2013            <p>The weight assigned to edges where one node is classified as \"limb\" and the other as \"mainstem\". Default is <code>10000</code>.</p> </li> <li> <code>weight_linear_mainstem</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>The weight assigned to edges where one node is classified as \"linear\" and the other as \"mainstem\". Default is <code>0</code>.</p> </li> <li> <code>weight_linear_linear</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>The weight assigned to edges where both connected nodes are classified as \"linear\". Default is <code>0</code>.</p> </li> <li> <code>weight_linear_limb</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>The weight assigned to edges where one node is classified as \"linear\" and the other as \"limb\". Default is <code>0</code>.</p> </li> <li> <code>weight_linear_apex</code>               (<code>float</code>, default:                   <code>0</code> )           \u2013            <p>The weight assigned to edges where one node is classified as \"linear\" and the other as \"apex\". Default is <code>0</code>.</p> </li> </ul> Notes <ul> <li>The function modifies the provided graph <code>QG</code> in place. It adds a new edge attribute   named <code>weight_sem_paths</code> to store the computed weights.</li> <li>If node classifications for a given edge do not match any of the specified categories</li> </ul> Source code in <code>spectral_clustering/quotientgraph_semantics.py</code> <pre><code>def weight_with_semantic(QG, class_attribute='viterbi_class', class_limb=1, class_mainstem=3, class_linear=0,\n                         class_apex=4,\n                         weight_limb_limb=10000, weight_apex_apex=10000, weight_apex_mainstem=10000,\n                         weight_limb_apex=10000, weight_limb_mainstem=10000, weight_linear_mainstem=0,\n                         weight_linear_linear=0,\n                         weight_linear_limb=0, weight_linear_apex=0):\n    \"\"\"Assigns semantic weights to the edges of a graph based on node classifications.\n\n    This function iterates over all edges in the provided graph `QG` and assigns a weight\n    to each edge depending on the classification of its connected nodes. The classification\n    of the nodes is determined using the `class_attribute` parameter. Different combinations\n    or sets of node categories (e.g., `class_limb`, `class_apex`) have corresponding weights\n    that are specified as input arguments to the function.\n\n    Parameters\n    ----------\n    QG : spectral_clustering.quotientgraph.QuotientGraph\n        The graph whose edges will be assigned weights based on the semantic relationships\n        between connected nodes.\n    class_attribute : str, optional\n        The node attribute in `QG` used to determine the category of the nodes.\n        Default is ``'viterbi_class'``.\n    class_limb : Any, optional\n        A value representing the \"limb\" classification of a node.\n        Default is ``1``.\n    class_mainstem : Any, optional\n        A value representing the \"mainstem\" classification of a node.\n        Default is ``3``.\n    class_linear : Any, optional\n        A value representing the \"linear\" classification of a node.\n        Default is ``0``.\n    class_apex : Any, optional\n        A value representing the \"apex\" classification of a node.\n        Default is ``4``.\n    weight_limb_limb : float, optional\n        The weight assigned to edges where both connected nodes are classified as \"limb\".\n        Default is ``10000``.\n    weight_apex_apex : float, optional\n        The weight assigned to edges where both connected nodes are classified as \"apex\".\n        Default is ``10000``.\n    weight_apex_mainstem : float, optional\n        The weight assigned to edges where one node is classified as \"apex\" and the other as \"mainstem\".\n        Default is ``10000``.\n    weight_limb_apex : float, optional\n        The weight assigned to edges where one node is classified as \"limb\" and the other as \"apex\".\n        Default is ``10000``.\n    weight_limb_mainstem : float, optional\n        The weight assigned to edges where one node is classified as \"limb\" and the other as \"mainstem\".\n        Default is ``10000``.\n    weight_linear_mainstem : float, optional\n        The weight assigned to edges where one node is classified as \"linear\" and the other as \"mainstem\".\n        Default is ``0``.\n    weight_linear_linear : float, optional\n        The weight assigned to edges where both connected nodes are classified as \"linear\".\n        Default is ``0``.\n    weight_linear_limb : float, optional\n        The weight assigned to edges where one node is classified as \"linear\" and the other as \"limb\".\n        Default is ``0``.\n    weight_linear_apex : float, optional\n        The weight assigned to edges where one node is classified as \"linear\" and the other as \"apex\".\n        Default is ``0``.\n\n    Notes\n    -----\n    - The function modifies the provided graph `QG` in place. It adds a new edge attribute\n      named `weight_sem_paths` to store the computed weights.\n    - If node classifications for a given edge do not match any of the specified categories\n    \"\"\"\n    for e in QG.edges():\n        QG.edges[e]['weight_sem_paths'] = np.nan\n        c1 = QG.nodes[e[0]][class_attribute]\n        c2 = QG.nodes[e[1]][class_attribute]\n        l = [c1, c2]\n        if set(l) == {class_limb, class_limb}:\n            QG.edges[e]['weight_sem_paths'] = weight_limb_limb\n        if set(l) == {class_limb, class_mainstem}:\n            QG.edges[e]['weight_sem_paths'] = weight_limb_mainstem\n        if set(l) == {class_limb, class_apex}:\n            QG.edges[e]['weight_sem_paths'] = weight_limb_apex\n        if set(l) == {class_limb, class_linear}:\n            QG.edges[e]['weight_sem_paths'] = weight_linear_limb\n\n        if set(l) == {class_apex, class_apex}:\n            QG.edges[e]['weight_sem_paths'] = weight_apex_apex\n        if set(l) == {class_apex, class_mainstem}:\n            QG.edges[e]['weight_sem_paths'] = weight_apex_mainstem\n        if set(l) == {class_apex, class_linear}:\n            QG.edges[e]['weight_sem_paths'] = weight_linear_apex\n\n        if set(l) == {class_linear, class_linear}:\n            QG.edges[e]['weight_sem_paths'] = weight_linear_linear\n        if set(l) == {class_linear, class_mainstem}:\n            QG.edges[e]['weight_sem_paths'] = weight_linear_mainstem\n</code></pre>"},{"location":"reference/spectral_clustering/segmentation_algorithms/","title":"segmentation_algorithms","text":""},{"location":"reference/spectral_clustering/segmentation_algorithms/#spectral_clustering.segmentation_algorithms.segment_a_node_using_attribute","title":"segment_a_node_using_attribute","text":"<pre><code>segment_a_node_using_attribute(quotientgraph, quotient_node_to_work, attribute_to_work_with='direction_gradient', method='OPTICS')\n</code></pre> <p>Perform clustering on a specified node of the QuotientGraph, updating the associated nodes of the PointCloudGraph accordingly.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The QuotientGraph object containing the graph data.</p> </li> <li> <code>quotient_node_to_work</code>               (<code>int</code>)           \u2013            <p>The node in the QuotientGraph to cluster.</p> </li> <li> <code>attribute_to_work_with</code>               (<code>str</code>, default:                   <code>'direction_gradient'</code> )           \u2013            <p>The attribute of the PointCloudGraph nodes to use for clustering. Default is 'direction_gradient'.</p> </li> <li> <code>method</code>               (<code>str</code>, default:                   <code>'OPTICS'</code> )           \u2013            <p>The clustering method to use. Supported methods are 'KMEANS' and 'OPTICS'. Default is 'OPTICS'.</p> </li> </ul> Notes <ul> <li>The function clusters the nodes of the PointCloudGraph that are part of the given 'quotient_node_to_work'.</li> <li>Updates the <code>quotient_graph_node</code> attribute of each PointCloudGraph node to reflect the new clustering.</li> </ul> See Also <p>sklearn.cluster.KMeans : K-means clustering algorithm. sklearn.cluster.OPTICS : OPTICS clustering algorithm for density-based clustering.</p> Source code in <code>spectral_clustering/segmentation_algorithms.py</code> <pre><code>def segment_a_node_using_attribute(quotientgraph, quotient_node_to_work, attribute_to_work_with='direction_gradient',\n                                   method='OPTICS'):\n    \"\"\"Perform clustering on a specified node of the QuotientGraph, updating the associated nodes\n    of the PointCloudGraph accordingly.\n\n    Parameters\n    ----------\n    quotientgraph : spectral_clustering.quotientgraph.QuotientGraph\n        The QuotientGraph object containing the graph data.\n    quotient_node_to_work : int\n        The node in the QuotientGraph to cluster.\n    attribute_to_work_with : str, optional\n        The attribute of the PointCloudGraph nodes to use for clustering. Default is 'direction_gradient'.\n    method : str, optional\n        The clustering method to use. Supported methods are 'KMEANS' and 'OPTICS'. Default is 'OPTICS'.\n\n    Notes\n    -----\n    - The function clusters the nodes of the PointCloudGraph that are part of the given 'quotient_node_to_work'.\n    - Updates the `quotient_graph_node` attribute of each PointCloudGraph node to reflect the new clustering.\n\n    See Also\n    --------\n    sklearn.cluster.KMeans : K-means clustering algorithm.\n    sklearn.cluster.OPTICS : OPTICS clustering algorithm for density-based clustering.\n    \"\"\"\n    G = quotientgraph.point_cloud_graph\n    nw = quotient_node_to_work\n\n    # make list of nodes inside the quotient graph node to work with\n    list_of_nodes = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == nw]\n\n    # Use of a function to segment\n    X = np.zeros((len(list_of_nodes), 3))\n\n    for i in range(len(list_of_nodes)):\n        X[i] = G.nodes[list_of_nodes[i]][attribute_to_work_with]\n\n    if method == 'KMEANS':\n        clustering = skc.KMeans(n_clusters=2, init='k-means++', n_init=20, max_iter=300, tol=0.0001).fit(X)\n    if method == 'OPTICS':\n        clustering = skc.OPTICS(min_samples=100).fit(X)\n\n    # Instead of having 0 or 1, this gives a number not already used in the quotient graph to name the nodes\n    clustering_labels = clustering.labels_[:, np.newaxis] + max(quotientgraph.nodes) + 1\n\n    # Integration of the new labels in the quotient graph and updates\n\n    for i in range(len(list_of_nodes)):\n        G.nodes[list_of_nodes[i]]['quotient_graph_node'] = clustering_labels[i]\n</code></pre>"},{"location":"reference/spectral_clustering/segmentation_algorithms/#spectral_clustering.segmentation_algorithms.segment_each_cluster_by_optics","title":"segment_each_cluster_by_optics","text":"<pre><code>segment_each_cluster_by_optics(quotientgraph, list_leaves=[], leaves_out=True, attribute_to_work='direction_gradient')\n</code></pre> <p>Perform clustering on the nodes of the QuotientGraph, updating the corresponding nodes in the associated PointCloudGraph based on the specified attribute.</p> <p>Each node of the QuotientGraph is processed and re-clustered based on the values of a specified attribute in the associated PointCloudGraph. The clustering is performed using an external function, which updates the <code>quotient_graph_node</code> attribute for those nodes. The QuotientGraph is updated accordingly after the clustering.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The QuotientGraph object containing the graph structure and associated PointCloudGraph data.</p> </li> <li> <code>list_leaves</code>               (<code>list of int</code>, default:                   <code>[]</code> )           \u2013            <p>A list of node indices in the QuotientGraph to be excluded from clustering when <code>leaves_out</code> is True.</p> </li> <li> <code>leaves_out</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, end nodes (or leaves) of the QuotientGraph in <code>list_leaves</code> are excluded from the clustering process. If False, all nodes are included regardless of <code>list_leaves</code>.</p> </li> <li> <code>attribute_to_work</code>               (<code>str</code>, default:                   <code>'direction_gradient'</code> )           \u2013            <p>The attribute in the PointCloudGraph associated with the QuotientGraph to be used for re-clustering the nodes.</p> </li> </ul> Notes <ul> <li>The function updates the <code>quotient_graph_node</code> attribute for each node in the PointCloudGraph   to reflect the new clustering results.</li> <li>The QuotientGraph structure to align with the updated clustering.</li> <li>Only nodes in the QuotientGraph with an <code>intra_class_node_number</code> greater than 100   are processed for clustering.</li> <li>The function delegates the clustering task to <code>segment_several_nodes_using_attribute</code>,   which performs clustering using the specified attribute and method.</li> </ul> See Also <p>segment_several_nodes_using_attribute : Perform clustering on multiple specified nodes of the QuotientGraph.</p> Source code in <code>spectral_clustering/segmentation_algorithms.py</code> <pre><code>def segment_each_cluster_by_optics(quotientgraph, list_leaves=[], leaves_out=True,\n                                   attribute_to_work='direction_gradient'):\n    \"\"\"Perform clustering on the nodes of the QuotientGraph, updating the corresponding nodes\n    in the associated PointCloudGraph based on the specified attribute.\n\n    Each node of the QuotientGraph is processed and re-clustered based on the values of a specified\n    attribute in the associated PointCloudGraph. The clustering is performed using an external\n    function, which updates the `quotient_graph_node` attribute for those nodes. The QuotientGraph\n    is updated accordingly after the clustering.\n\n    Parameters\n    ----------\n    quotientgraph : spectral_clustering.quotientgraph.QuotientGraph\n        The QuotientGraph object containing the graph structure and associated PointCloudGraph data.\n    list_leaves : list of int, optional, default=[]\n        A list of node indices in the QuotientGraph to be excluded from clustering\n        when `leaves_out` is True.\n    leaves_out : bool, optional, default=True\n        If True, end nodes (or leaves) of the QuotientGraph in `list_leaves` are excluded\n        from the clustering process. If False, all nodes are included regardless of `list_leaves`.\n    attribute_to_work : str, optional, default='direction_gradient'\n        The attribute in the PointCloudGraph associated with the QuotientGraph to be\n        used for re-clustering the nodes.\n\n    Notes\n    -----\n    - The function updates the `quotient_graph_node` attribute for each node in the PointCloudGraph\n      to reflect the new clustering results.\n    - The QuotientGraph structure to align with the updated clustering.\n    - Only nodes in the QuotientGraph with an `intra_class_node_number` greater than 100\n      are processed for clustering.\n    - The function delegates the clustering task to `segment_several_nodes_using_attribute`,\n      which performs clustering using the specified attribute and method.\n\n    See Also\n    --------\n    segment_several_nodes_using_attribute : Perform clustering on multiple specified nodes of the QuotientGraph.\n\n\n    \"\"\"\n    # Put the \"end\" nodes in a list\n    for n in quotientgraph:\n        if leaves_out:\n            if n not in list_leaves and quotientgraph.nodes[n]['intra_class_node_number'] &gt; 100:\n                segment_several_nodes_using_attribute(quotientgraph=quotientgraph, list_quotient_node_to_work=[n],\n                                                      attribute=attribute_to_work)\n        elif leaves_out is False and quotientgraph.nodes[n]['intra_class_node_number'] &gt; 100:\n            segment_several_nodes_using_attribute(quotientgraph=quotientgraph, list_quotient_node_to_work=[n],\n                                                  attribute=attribute_to_work)\n\n    quotientgraph.rebuild(quotientgraph.point_cloud_graph)\n</code></pre>"},{"location":"reference/spectral_clustering/segmentation_algorithms/#spectral_clustering.segmentation_algorithms.segment_several_nodes_using_attribute","title":"segment_several_nodes_using_attribute","text":"<pre><code>segment_several_nodes_using_attribute(quotientgraph, list_quotient_node_to_work=[], algo='OPTICS', para_clustering_meth=100, attribute='direction_gradient')\n</code></pre> <p>Perform clustering on multiple specified nodes of the QuotientGraph, updating the class of the underlying nodes in the associated PointCloudGraph.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The QuotientGraph object containing the graph data.</p> </li> <li> <code>list_quotient_node_to_work</code>               (<code>list of int</code>, default:                   <code>[]</code> )           \u2013            <p>A list of node indices in the QuotientGraph to be clustered. Default is an empty list, which means no nodes are clustered.</p> </li> <li> <code>algo</code>               (<code>(kmeans, OPTICS)</code>, default:                   <code>'kmeans'</code> )           \u2013            <p>The clustering algorithm to use. Supported values are: - 'kmeans': K-means clustering, - 'OPTICS': Density-based clustering. Default is 'OPTICS'.</p> </li> <li> <code>para_clustering_meth</code>               (<code>int</code>, default:                   <code>100</code> )           \u2013            <p>The parameter needed for the chosen clustering algorithm: - For 'OPTICS', it specifies the minimum sample size (<code>min_samples</code>) to form a cluster. - For 'kmeans', it specifies the number of clusters (<code>n_clusters</code>) to generate. Default is 100.</p> </li> <li> <code>attribute</code>               (<code>str</code>, default:                   <code>'direction_gradient'</code> )           \u2013            <p>The node attribute from the PointCloudGraph to be used for clustering. Default is 'direction_gradient'.</p> </li> </ul> Notes <ul> <li>The function selects the nodes from the PointCloudGraph corresponding to the specified nodes in   <code>list_quotient_node_to_work</code> from the QuotientGraph.</li> <li>The clustering results are assigned as new values for the <code>quotient_graph_node</code> attribute of the   PointCloudGraph nodes.</li> <li>The updated clustering is applied to the PointCloudGraph associated with the QuotientGraph.   Only the PointCloudGraph is directly modified.</li> </ul> Source code in <code>spectral_clustering/segmentation_algorithms.py</code> <pre><code>def segment_several_nodes_using_attribute(quotientgraph, list_quotient_node_to_work=[], algo='OPTICS',\n                                          para_clustering_meth=100, attribute='direction_gradient'):\n    \"\"\"Perform clustering on multiple specified nodes of the QuotientGraph, updating the class of the underlying\n    nodes in the associated PointCloudGraph.\n\n    Parameters\n    ----------\n    quotientgraph : spectral_clustering.quotientgraph.QuotientGraph\n        The QuotientGraph object containing the graph data.\n    list_quotient_node_to_work : list of int, optional\n        A list of node indices in the QuotientGraph to be clustered. Default is an empty list, which means no nodes are clustered.\n    algo : {'kmeans', 'OPTICS'}, optional\n        The clustering algorithm to use. Supported values are:\n        - 'kmeans': K-means clustering,\n        - 'OPTICS': Density-based clustering.\n        Default is 'OPTICS'.\n    para_clustering_meth : int, optional\n        The parameter needed for the chosen clustering algorithm:\n        - For 'OPTICS', it specifies the minimum sample size (`min_samples`) to form a cluster.\n        - For 'kmeans', it specifies the number of clusters (`n_clusters`) to generate.\n        Default is 100.\n    attribute : str, optional\n        The node attribute from the PointCloudGraph to be used for clustering. Default is 'direction_gradient'.\n\n    Notes\n    -----\n    - The function selects the nodes from the PointCloudGraph corresponding to the specified nodes in\n      `list_quotient_node_to_work` from the QuotientGraph.\n    - The clustering results are assigned as new values for the `quotient_graph_node` attribute of the\n      PointCloudGraph nodes.\n    - The updated clustering is applied to the PointCloudGraph associated with the QuotientGraph.\n      Only the PointCloudGraph is directly modified.\n    \"\"\"\n\n    lw = list_quotient_node_to_work\n    G = quotientgraph.point_cloud_graph\n    # make list of nodes inside the different quotient graph nodes to work with\n    list_of_nodes = []\n    for qnode in lw:\n        list_of_nodes_each = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == qnode]\n        list_of_nodes += list_of_nodes_each\n\n    # Use of a function to segment\n    X = np.zeros((len(list_of_nodes), 3))\n\n    for i in range(len(list_of_nodes)):\n        X[i] = G.nodes[list_of_nodes[i]][attribute]\n\n    if algo == 'OPTICS':\n        clustering = skc.OPTICS(min_samples=para_clustering_meth).fit(X)\n    elif algo == 'kmeans':\n        clustering = skc.KMeans(n_clusters=para_clustering_meth, init='k-means++', n_init=20, max_iter=300,\n                                tol=0.0001).fit(X)\n\n    # Selection of max value for 'quotient_graph_node' in G\n    q_g = nx.get_node_attributes(G, 'quotient_graph_node')\n    q_g_values = list(q_g.values())\n\n    # Instead of having 0 or 1, this gives a number not already used in the quotient graph to name the nodes\n    clustering_labels = clustering.labels_[:, np.newaxis] + max(q_g_values) + 2\n\n    # Integration of the new labels in the quotient graph and updates\n    for i in range(len(list_of_nodes)):\n        G.nodes[list_of_nodes[i]]['quotient_graph_node'] = clustering_labels[i]\n\n    quotientgraph.point_cloud_graph = G\n</code></pre>"},{"location":"reference/spectral_clustering/similarity_graph/","title":"similarity_graph","text":""},{"location":"reference/spectral_clustering/similarity_graph/#spectral_clustering.similarity_graph.add_label_from_pcd_file","title":"add_label_from_pcd_file","text":"<pre><code>add_label_from_pcd_file(G, file='Data/peuplier_seg.txt')\n</code></pre> <p>Assigns clustering labels to a graph <code>G</code> from a specified Point Cloud Data (PCD) file.</p> <p>The function reads a given file containing point cloud data where clustering labels are extracted from the fourth column (index 3) of the file data. These labels are set as a new attribute <code>clustering_labels</code> of the graph <code>G</code> and are also assigned to individual nodes within the graph. This assignment links clustering information from the point cloud data to the graph structure.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>A graph representation of the dataset where each node will be assigned a clustering label based on the point cloud data loaded from the input file.</p> </li> <li> <code>file</code>               (<code>str</code>, default:                   <code>'Data/peuplier_seg.txt'</code> )           \u2013            <p>File path to the PCD (Point Cloud Data) file in text format. By default, the path points to a specific <code>.txt</code> dataset: \"/Users/katiamirande/PycharmProjects/ Spectral_clustering_0/Data/peuplier_seg.txt\".</p> </li> </ul> Notes <p>The function expects that the input data in the provided file contains at least four columns, where the fourth column (index 3) corresponds to the clustering labels. The labels are expected to be integers. The function specifically reshapes these labels before assigning them to the graph.</p> Source code in <code>spectral_clustering/similarity_graph.py</code> <pre><code>def add_label_from_pcd_file(G, file=\"Data/peuplier_seg.txt\"):\n    \"\"\"Assigns clustering labels to a graph `G` from a specified Point Cloud Data (PCD) file.\n\n    The function reads a given file containing point cloud data where clustering labels are\n    extracted from the fourth column (index 3) of the file data. These labels are set as a new\n    attribute `clustering_labels` of the graph `G` and are also assigned to individual nodes\n    within the graph. This assignment links clustering information from the point cloud data\n    to the graph structure.\n\n    Parameters\n    ----------\n    G : networkx.Graph\n        A graph representation of the dataset where each node will be assigned a clustering label\n        based on the point cloud data loaded from the input file.\n    file : str, optional\n        File path to the PCD (Point Cloud Data) file in text format. By default, the path\n        points to a specific `.txt` dataset: \"/Users/katiamirande/PycharmProjects/\n        Spectral_clustering_0/Data/peuplier_seg.txt\".\n\n    Notes\n    -----\n    The function expects that the input data in the provided file contains at least four columns,\n    where the fourth column (index 3) corresponds to the clustering labels. The labels are expected\n    to be integers. The function specifically reshapes these labels before assigning them to the\n    graph.\n\n    \"\"\"\n    label = np.loadtxt(file, delimiter=',')\n    l = label[:, 3].astype('int32')\n    G.clustering_labels = l.reshape((len(l), 1))\n    j = 0\n    for n in G.nodes:\n        G.nodes[n]['clustering_labels'] = l[j]\n        j += 1\n</code></pre>"},{"location":"reference/spectral_clustering/similarity_graph/#spectral_clustering.similarity_graph.add_label_from_separate_file","title":"add_label_from_separate_file","text":"<pre><code>add_label_from_separate_file(G, file='Data/rawLabels_Arabido_0029.txt')\n</code></pre> <p>Adds clustering labels from a separate file to the graph <code>G</code>.</p> <p>This function reads a file containing clustering labels, processes it into an integer array, and assigns these labels both as a graph-level attribute and node-level attributes. The labels for nodes are assigned sequentially based on the order of nodes in the graph.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>The graph to which clustering labels will be assigned.</p> </li> <li> <code>file</code>               (<code>str</code>, default:                   <code>'Data/rawLabels_Arabido_0029.txt'</code> )           \u2013            <p>Path to the file containing clustering labels. The file is expected to contain comma-separated values. Defaults to \" Data/rawLabels_Arabido_0029.txt\".</p> </li> </ul> Notes <ul> <li>The labels in the file are expected to align with the order of nodes in the   graph <code>G</code>.</li> <li>The clustering labels are stored as an attribute for the graph (<code>clustering_labels</code>)   and as an attribute for each node (<code>G.nodes[n]['clustering_labels']</code>).</li> </ul> Source code in <code>spectral_clustering/similarity_graph.py</code> <pre><code>def add_label_from_separate_file(G,\n                                 file=\"Data/rawLabels_Arabido_0029.txt\"):\n    \"\"\"Adds clustering labels from a separate file to the graph `G`.\n\n    This function reads a file containing clustering labels, processes it into an\n    integer array, and assigns these labels both as a graph-level attribute and\n    node-level attributes. The labels for nodes are assigned sequentially based\n    on the order of nodes in the graph.\n\n    Parameters\n    ----------\n    G : networkx.Graph\n        The graph to which clustering labels will be assigned.\n    file : str, optional\n        Path to the file containing clustering labels. The file is expected to\n        contain comma-separated values. Defaults to\n        \"\n        Data/rawLabels_Arabido_0029.txt\".\n\n    Notes\n    -----\n    - The labels in the file are expected to align with the order of nodes in the\n      graph `G`.\n    - The clustering labels are stored as an attribute for the graph (`clustering_labels`)\n      and as an attribute for each node (`G.nodes[n]['clustering_labels']`).\n    \"\"\"\n    label = np.loadtxt(file, delimiter=',')\n    l = label.astype('int32')\n    G.clustering_labels = l.reshape((len(l), 1))\n    j = 0\n    for n in G.nodes:\n        G.nodes[n]['clustering_labels'] = l[j]\n        j += 1\n</code></pre>"},{"location":"reference/spectral_clustering/similarity_graph/#spectral_clustering.similarity_graph.create_connected_riemannian_graph","title":"create_connected_riemannian_graph","text":"<pre><code>create_connected_riemannian_graph(point_cloud, method='knn', nearest_neighbors=1, radius=1.0)\n</code></pre> <p>Create a connected Riemannian graph from a point cloud using a specified method.</p> <p>This function takes a point cloud and generates a Riemannian graph based on the provided method and parameters. If the generated graph is not connected, it extracts the largest connected component from the graph, saves the corresponding points, and regenerates the graph. The final graph and updated point cloud are returned.</p> <p>Parameters:</p> <ul> <li> <code>point_cloud</code>               (<code>PointCloud</code>)           \u2013            <p>Input point cloud data.</p> </li> <li> <code>method</code>               (<code>str</code>, default:                   <code>'knn'</code> )           \u2013            <p>Method to generate the Riemannian graph. Options are 'knn' (k-nearest neighbors) or other methods, by default 'knn'.</p> </li> <li> <code>nearest_neighbors</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of nearest neighbors to use when creating the graph (if method is 'knn'), by default 1.</p> </li> <li> <code>radius</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Radius parameter to define connectivity (if applicable to the method), by default 1.0.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Graph</code>           \u2013            <p>The connected Riemannian graph.</p> </li> <li> <code>PointCloud</code>           \u2013            <p>The updated point cloud corresponding to the connected graph.</p> </li> </ul> Source code in <code>spectral_clustering/similarity_graph.py</code> <pre><code>def create_connected_riemannian_graph(point_cloud, method='knn', nearest_neighbors=1, radius=1.):\n    \"\"\"Create a connected Riemannian graph from a point cloud using a specified method.\n\n    This function takes a point cloud and generates a Riemannian graph based on the\n    provided method and parameters. If the generated graph is not connected, it\n    extracts the largest connected component from the graph, saves the corresponding\n    points, and regenerates the graph. The final graph and updated point cloud are\n    returned.\n\n    Parameters\n    ----------\n    point_cloud : o3d.geometry.PointCloud\n        Input point cloud data.\n    method : str, optional\n        Method to generate the Riemannian graph. Options are 'knn' (k-nearest neighbors)\n        or other methods, by default 'knn'.\n    nearest_neighbors : int, optional\n        Number of nearest neighbors to use when creating the graph (if method is 'knn'),\n        by default 1.\n    radius : float, optional\n        Radius parameter to define connectivity (if applicable to the method),\n        by default 1.0.\n\n    Returns\n    -------\n    networkx.Graph\n        The connected Riemannian graph.\n    o3d.geometry.PointCloud\n        The updated point cloud corresponding to the connected graph.\n    \"\"\"\n    G = create_riemannian_graph(pcd=point_cloud, method=method, nearest_neighbors=nearest_neighbors, radius=radius)\n    pcd2 = point_cloud\n    if nx.is_connected(G) is False:\n        print('not connected')\n        largest_cc = max(nx.connected_components(G), key=len)\n        # creating the new pcd point clouds\n        coords = np.zeros((len(largest_cc), 3))\n        i = 0\n        for node in largest_cc:\n            coords[i, :] = G.nodes[node]['pos']\n            i += 1\n        path = os.getcwd()\n        print(path)\n        np.savetxt(path + '/New_pcd_connected.txt', coords, delimiter=' ', fmt='%f')\n\n        pcd2 = o3d.io.read_point_cloud(path + \"/New_pcd_connected.txt\", format='xyz')\n\n        G = create_riemannian_graph(pcd2, method=method, nearest_neighbors=nearest_neighbors, radius=radius)\n        pcd = pcd2\n\n    return G, pcd2\n</code></pre>"},{"location":"reference/spectral_clustering/similarity_graph/#spectral_clustering.similarity_graph.create_riemannian_graph","title":"create_riemannian_graph","text":"<pre><code>create_riemannian_graph(pcd, method='knn', nearest_neighbors=1, radius=1.0)\n</code></pre> <p>Generate a similarity graph from a point cloud.</p> <p>Parameters:</p> <ul> <li> <code>p</code>               (<code>PointCloud</code>)           \u2013            <p>Point cloud on which to compute the similarity graph</p> </li> <li> <code>method</code>               (<code>str</code>, default:                   <code>'knn'</code> )           \u2013            <p>Search method : 'knn' or 'radius'</p> </li> <li> <code>nearest_neighbors</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Number of nearest neighbors for the 'knn' method</p> </li> <li> <code>radius</code>               (<code>float</code>, default:                   <code>1.0</code> )           \u2013            <p>Radius for the 'radius' method</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Graph</code>           \u2013            <p>Similarity graph computed on the point cloud</p> </li> </ul> Source code in <code>spectral_clustering/similarity_graph.py</code> <pre><code>def create_riemannian_graph(pcd, method='knn', nearest_neighbors=1, radius=1.):\n    \"\"\"Generate a similarity graph from a point cloud.\n\n    Parameters\n    ----------\n    p : o3d.o3d.geometry.PointCloud\n        Point cloud on which to compute the similarity graph\n    method : str\n        Search method : 'knn' or 'radius'\n    nearest_neighbors : int\n        Number of nearest neighbors for the 'knn' method\n    radius : float\n        Radius for the 'radius' method\n\n    Returns\n    -------\n    networkx.Graph\n        Similarity graph computed on the point cloud\n    \"\"\"\n    N = len(pcd.points)\n    # d\u00e9finition d'un arbre KD contenant tous les points\n    tree = o3d.geometry.KDTreeFlann(pcd)\n\n    pcd.estimate_normals()\n\n    # Prise des points sous forme de tableau ndarray\n    pts = np.array(pcd.points)\n    normals = np.array(pcd.normals)\n\n    # D\u00e9claration d'un graph networkx\n    G = nx.Graph()\n\n    # On ins\u00e8re chaque point du nuage de points dans le graphe avec un num\u00e9ro et le trio de coordonn\u00e9es (pos) en attributs\n    for i in range(N):\n        G.add_node(i, pos=pts[i], normal=normals[i])\n\n    # Construction des edges du graphe \u00e0 partir d'un seuil\n    # On part de la structure de nuage de points en KDTree\n    # Cette structure dans open3d dispose de fonctions pour seuil, KNN, RKNN\n    for i in range(N):\n        if method == 'radius':\n            [k, idxs, _] = tree.search_radius_vector_3d(pts[i], radius)\n        elif method == 'knn':\n            [k, idxs, _] = tree.search_knn_vector_3d(pts[i], nearest_neighbors)\n        for idx in idxs:\n            d = np.sqrt(np.square(pts[i][0] - pts[idx][0]) + np.square(pts[i][1] - pts[idx][1]) + np.square(\n                pts[i][2] - pts[idx][2]))\n            if d != 0:\n                w = 1 / d\n                G.add_edge(i, idx, weight=w)\n                G.edges[(i, idx)][\"distance\"] = d\n\n    return G\n</code></pre>"},{"location":"reference/spectral_clustering/similarity_graph/#spectral_clustering.similarity_graph.draw_graph_cellcomplex","title":"draw_graph_cellcomplex","text":"<pre><code>draw_graph_cellcomplex(pcd, G, pcd_to_superimpose)\n</code></pre> <p>Draws a graph cell complex visualization using the provided point cloud, graph and an additional point cloud for superimposition.</p> <p>The function generates a 3D representation of the graph with edges and vertices colored and styled using predefined colormaps and glyph configurations, and displays it using VTK.</p> <p>Parameters:</p> <ul> <li> <code>pcd</code>               (<code>PointCloud or ndarray</code>)           \u2013            <p>The primary point cloud used to define the coordinates of the graph vertices. It can either be an <code>o3d.geometry.PointCloud</code> object or a numpy array of point coordinates.</p> </li> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>The input graph whose nodes and edges will be visualized. Nodes must correspond to elements in the <code>pcd</code> parameter, and edges define the connections to be drawn.</p> </li> <li> <code>pcd_to_superimpose</code>               (<code>PointCloud or ndarray</code>)           \u2013            <p>An additional point cloud that will be visualized as a superimposed set of points on the graph. This provides a way to compare or highlight a separate dataset in relation to the graph cell complex.</p> </li> </ul> Source code in <code>spectral_clustering/similarity_graph.py</code> <pre><code>def draw_graph_cellcomplex(pcd, G, pcd_to_superimpose):\n    \"\"\"Draws a graph cell complex visualization using the provided point cloud, graph and an additional point cloud for superimposition.\n\n    The function generates a 3D representation of the graph with edges and vertices colored and styled\n    using predefined colormaps and glyph configurations, and displays it using VTK.\n\n    Parameters\n    ----------\n    pcd : o3d.geometry.PointCloud or numpy.ndarray\n        The primary point cloud used to define the coordinates of the graph vertices.\n        It can either be an `o3d.geometry.PointCloud` object or a numpy array of\n        point coordinates.\n    G : networkx.Graph\n        The input graph whose nodes and edges will be visualized. Nodes must\n        correspond to elements in the `pcd` parameter, and edges define the\n        connections to be drawn.\n    pcd_to_superimpose : o3d.geometry.PointCloud or numpy.ndarray\n        An additional point cloud that will be visualized as a superimposed set of\n        points on the graph. This provides a way to compare or highlight a separate\n        dataset in relation to the graph cell complex.\n    \"\"\"\n    if type(pcd) is o3d.geometry.PointCloud:\n        pcdtab = np.asarray(pcd.points)\n    else:\n        pcdtab = pcd\n    # s, t = np.meshgrid(np.arange(len(pcdtab)), np.arange(len(pcdtab)))\n    # sources = s[simatrix &gt; 0]\n    # targets = t[simatrix &gt; 0]\n    # sources, targets = sources[sources &lt; targets], targets[sources &lt; targets]\n\n    from cellcomplex.property_topomesh.creation import edge_topomesh\n    from cellcomplex.property_topomesh.visualization.vtk_actor_topomesh import VtkActorTopomesh\n    from cellcomplex.property_topomesh.visualization.vtk_tools import vtk_display_actors\n    from cellcomplex.property_topomesh.analysis import compute_topomesh_property\n    from cellcomplex.property_topomesh.creation import vertex_topomesh\n\n    topomesh = edge_topomesh(np.array([e for e in G.edges if e[0] != e[1]]),\n                             dict(zip(np.asarray([n for n in G.nodes]), pcdtab)))\n\n    compute_topomesh_property(topomesh, 'length', 1)\n\n    edge_actor = VtkActorTopomesh()\n    edge_actor.set_topomesh(topomesh, 1, property_name='length')\n    edge_actor.line_glyph = 'tube'\n    edge_actor.update(colormap=\"cool\")\n\n    vertex_actor = VtkActorTopomesh()\n    vertex_actor.set_topomesh(topomesh, 0)\n    # vertex_actor.point_glyph = 'point'\n    vertex_actor.point_glyph = 'sphere'\n    vertex_actor.glyph_scale = 2\n    vertex_actor.update(colormap=\"Reds\")\n\n    point_cloud_actor = VtkActorTopomesh(vertex_topomesh(pcd_to_superimpose), 0)\n    point_cloud_actor.point_glyph = 'point'\n    point_cloud_actor.update(colormap=\"Blues\")\n\n    vtk_display_actors([vertex_actor.actor, edge_actor.actor, point_cloud_actor.actor], background=(0.9, 0.9, 0.9))\n</code></pre>"},{"location":"reference/spectral_clustering/similarity_graph/#spectral_clustering.similarity_graph.draw_graph_open3d","title":"draw_graph_open3d","text":"<pre><code>draw_graph_open3d(pcd, G)\n</code></pre> <p>Visualize a graph overlaid on a 3D point cloud using o3d.</p> <p>This function creates a line set object from the provided graph edges and associates it with the nodes represented by the points in the point cloud. The resulting visualization is displayed in an Open3D viewer to provide an interactive 3D representation of the graph.</p> <p>Parameters:</p> <ul> <li> <code>pcd</code>               (<code>PointCloud</code>)           \u2013            <p>A 3D point cloud object where each point is treated as a node of the graph.</p> </li> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>A graph object, containing edges as tuples of integers representing connections between the indices of points in the provided point cloud.</p> </li> </ul> Source code in <code>spectral_clustering/similarity_graph.py</code> <pre><code>def draw_graph_open3d(pcd, G):\n    \"\"\"Visualize a graph overlaid on a 3D point cloud using o3d.\n\n    This function creates a line set object from the provided graph edges\n    and associates it with the nodes represented by the points in the\n    point cloud. The resulting visualization is displayed in an Open3D\n    viewer to provide an interactive 3D representation of the graph.\n\n    Parameters\n    ----------\n    pcd : o3d.geometry.PointCloud\n        A 3D point cloud object where each point is treated as a node of\n        the graph.\n    G : networkx.Graph\n        A graph object, containing edges as tuples of integers\n        representing connections between the indices of points in the\n        provided point cloud.\n\n    \"\"\"\n    graph = o3d.geometry.LineSet()\n    graph.points = pcd.points\n    graph.lines = o3d.utility.Vector2iVector(G.edges)\n    o3d.visualization.draw_geometries([graph])\n</code></pre>"},{"location":"reference/spectral_clustering/similarity_graph/#spectral_clustering.similarity_graph.export_eigenvectors_on_pointcloud","title":"export_eigenvectors_on_pointcloud","text":"<pre><code>export_eigenvectors_on_pointcloud(pcd, keigenvec, k, filename='vecteurproprecol.txt')\n</code></pre> <p>Export eigenvectors associated with a specific eigenvalue to a file for visualization alongside the point cloud data.</p> <p>This function computes a new array combining the coordinates of the points in the point cloud and the eigenvectors corresponding to a specific eigenvalue. The combined data is then saved to a CSV file for potential visualization purposes, e.g., in a tool like CloudCompare.</p> <p>Parameters:</p> <ul> <li> <code>pcd</code>               (<code>PointCloud</code>)           \u2013            <p>The input point cloud from which coordinates are extracted.</p> </li> <li> <code>keigenvec</code>               (<code>ndarray</code>)           \u2013            <p>The matrix of eigenvectors where each column corresponds to an eigenvalue.</p> </li> <li> <code>k</code>               (<code>int</code>)           \u2013            <p>The index of the eigenvalue whose eigenvectors will be used.</p> </li> <li> <code>filename</code>               (<code>str</code>, default:                   <code>'vecteurproprecol.txt'</code> )           \u2013            <p>The name of the output file where the combined data will be saved. Default is 'vecteurproprecol.txt'.</p> </li> </ul> Source code in <code>spectral_clustering/similarity_graph.py</code> <pre><code>def export_eigenvectors_on_pointcloud(pcd, keigenvec, k, filename='vecteurproprecol.txt'):\n    \"\"\"Export eigenvectors associated with a specific eigenvalue to a file for visualization alongside the point cloud data.\n\n    This function computes a new array combining the coordinates of the points in the point cloud\n    and the eigenvectors corresponding to a specific eigenvalue. The combined data is then saved\n    to a CSV file for potential visualization purposes, e.g., in a tool like CloudCompare.\n\n    Parameters\n    ----------\n    pcd : o3d.geometry.PointCloud\n        The input point cloud from which coordinates are extracted.\n    keigenvec : numpy.ndarray\n        The matrix of eigenvectors where each column corresponds to an eigenvalue.\n    k : int\n        The index of the eigenvalue whose eigenvectors will be used.\n    filename : str, optional\n        The name of the output file where the combined data will be saved. Default is\n        'vecteurproprecol.txt'.\n    \"\"\"\n    # Le facteur multiplicatif est pr\u00e9sent uniquement pour pouvoir \u00e9ventuellement mieux afficher les couleurs/poids dans CloudCompare\n    #\n    label = keigenvec[:, k]\n    size = label.shape[0]\n    label = np.asarray(label.reshape(size, 1), dtype=np.float64)\n    pcd = np.array(pcd.points)\n    pcdtabvecteurpropre = np.concatenate([pcd, label], axis=1)\n    np.savetxt(filename, pcdtabvecteurpropre, delimiter=',')\n</code></pre>"},{"location":"reference/spectral_clustering/similarity_graph/#spectral_clustering.similarity_graph.export_pointcloud_on_eigenvectors_3d","title":"export_pointcloud_on_eigenvectors_3d","text":"<pre><code>export_pointcloud_on_eigenvectors_3d(keigenvec, vec1, vec2, vec3, filename='espacespec.txt')\n</code></pre> <p>Export a 3D point cloud using specific eigenvector indices.</p> <p>This function extracts points from the given eigenvector matrix based on specified indices and exports the resulting 3D coordinates into a text file in a tabular format. The saved file consists of points where each row contains three values representing a single point in 3D space. The points are separated by commas for easier parsing.</p> <p>Parameters:</p> <ul> <li> <code>keigenvec</code>               (<code>ndarray</code>)           \u2013            <p>A 2D array where each column represents an eigenvector and rows represent points in the dataset. It is expected to have at least three columns to extract 3D coordinates.</p> </li> <li> <code>vec1</code>               (<code>int</code>)           \u2013            <p>Index of the eigenvector to use as the x-coordinate.</p> </li> <li> <code>vec2</code>               (<code>int</code>)           \u2013            <p>Index of the eigenvector to use as the y-coordinate.</p> </li> <li> <code>vec3</code>               (<code>int</code>)           \u2013            <p>Index of the eigenvector to use as the z-coordinate.</p> </li> <li> <code>filename</code>               (<code>str</code>, default:                   <code>'espacespec.txt'</code> )           \u2013            <p>The name of the file to save the output. The default is 'espacespec.txt', and the data in the file will be saved in a comma-separated value format.</p> </li> </ul> Source code in <code>spectral_clustering/similarity_graph.py</code> <pre><code>def export_pointcloud_on_eigenvectors_3d(keigenvec, vec1, vec2, vec3, filename='espacespec.txt'):\n    \"\"\"Export a 3D point cloud using specific eigenvector indices.\n\n    This function extracts points from the given eigenvector matrix based on\n    specified indices and exports the resulting 3D coordinates into a text file\n    in a tabular format. The saved file consists of points where each row\n    contains three values representing a single point in 3D space. The points\n    are separated by commas for easier parsing.\n\n    Parameters\n    ----------\n    keigenvec : ndarray\n        A 2D array where each column represents an eigenvector and rows\n        represent points in the dataset. It is expected to have at least\n        three columns to extract 3D coordinates.\n    vec1 : int\n        Index of the eigenvector to use as the x-coordinate.\n    vec2 : int\n        Index of the eigenvector to use as the y-coordinate.\n    vec3 : int\n        Index of the eigenvector to use as the z-coordinate.\n    filename : str, optional\n        The name of the file to save the output. The default is\n        'espacespec.txt', and the data in the file will be saved\n        in a comma-separated value format.\n    \"\"\"\n    pts = keigenvec[:, [vec1, vec2, vec3]]\n    pts = pts.reshape(keigenvec.shape[0], 3)\n    np.savetxt(filename, pts, delimiter=',')\n</code></pre>"},{"location":"reference/spectral_clustering/split_and_merge/","title":"split_and_merge","text":""},{"location":"reference/spectral_clustering/split_and_merge/#spectral_clustering.split_and_merge.create_a_subgraph_copy","title":"create_a_subgraph_copy","text":"<pre><code>create_a_subgraph_copy(G, list_of_nodes=[])\n</code></pre> <p>Creates a subgraph as a copy based on the given list of nodes. This function preserves the attributes of the original graph and nodes. If the graph is a multigraph, it copies all edges and their attributes for the specified nodes; otherwise, it works with simple graphs.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>Graph or DiGraph or MultiGraph or MultiDiGraph</code>)           \u2013            <p>The original graph from which the subgraph is to be created. This can be any NetworkX graph instance.</p> </li> <li> <code>list_of_nodes</code>               (<code>list</code>, default:                   <code>[]</code> )           \u2013            <p>A list of nodes to be included in the subgraph. If not provided, an empty list will result in a subgraph with no nodes. Each node in this list must exist in the original graph.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SG</code> (              <code>Graph or DiGraph or MultiGraph or MultiDiGraph</code> )          \u2013            <p>A deep copy of the subgraph containing only the nodes and edges specified by the <code>list_of_nodes</code>. The type of the resulting graph matches the type of the input graph.</p> </li> </ul> Source code in <code>spectral_clustering/split_and_merge.py</code> <pre><code>def create_a_subgraph_copy(G, list_of_nodes=[]):\n    \"\"\"\n    Creates a subgraph as a copy based on the given list of nodes. This function preserves the\n    attributes of the original graph and nodes. If the graph is a multigraph, it copies all\n    edges and their attributes for the specified nodes; otherwise, it works with simple graphs.\n\n    Parameters\n    ----------\n    G : networkx.Graph or networkx.DiGraph or networkx.MultiGraph or networkx.MultiDiGraph\n        The original graph from which the subgraph is to be created. This can be any NetworkX\n        graph instance.\n\n    list_of_nodes : list, optional\n        A list of nodes to be included in the subgraph. If not provided, an empty list will\n        result in a subgraph with no nodes. Each node in this list must exist in the original\n        graph.\n\n    Returns\n    -------\n    SG : networkx.Graph or networkx.DiGraph or networkx.MultiGraph or networkx.MultiDiGraph\n        A deep copy of the subgraph containing only the nodes and edges specified by the\n        `list_of_nodes`. The type of the resulting graph matches the type of the input graph.\n    \"\"\"\n    largest_wcc = list_of_nodes\n    SG = G.__class__()\n    SG.add_nodes_from((n, G.nodes[n]) for n in largest_wcc)\n    if SG.is_multigraph():\n        SG.add_edges_from((n, nbr, key, d)\n                          for n, nbrs in G.adj.items() if n in largest_wcc\n                          for nbr, keydict in nbrs.items() if nbr in largest_wcc\n                          for key, d in keydict.items())\n    else:\n        SG.add_edges_from((n, nbr, d)\n                          for n, nbrs in G.adj.items() if n in largest_wcc\n                          for nbr, d in nbrs.items() if nbr in largest_wcc)\n    SG.graph.update(G.graph)\n    return SG\n</code></pre>"},{"location":"reference/spectral_clustering/split_and_merge/#spectral_clustering.split_and_merge.create_subgraphs_to_work","title":"create_subgraphs_to_work","text":"<pre><code>create_subgraphs_to_work(quotientgraph, list_quotient_node_to_work=[])\n</code></pre> <p>Creates subgraphs from the given quotient graph by focusing on specific nodes to work with. This function builds a Riemannian subgraph using the original graph stored in the given quotient graph, and includes the nodes mapped to specified quotient graph nodes.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>Any</code>)           \u2013            <p>The quotient graph object that contains the point cloud graph.</p> </li> <li> <code>list_quotient_node_to_work</code>               (<code>list</code>, default:                   <code>[]</code> )           \u2013            <p>List of nodes in the quotient graph for which the corresponding nodes in the point cloud graph will be included in the subgraph. Defaults to an empty list.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Graph</code>           \u2013            <p>The created subgraph that includes all the nodes from the original graph associated with the given list of quotient graph nodes.</p> </li> </ul> Source code in <code>spectral_clustering/split_and_merge.py</code> <pre><code>def create_subgraphs_to_work(quotientgraph, list_quotient_node_to_work=[]):\n    \"\"\"\n    Creates subgraphs from the given quotient graph by focusing on specific nodes to work with.\n    This function builds a Riemannian subgraph using the original graph stored in the given\n    quotient graph, and includes the nodes mapped to specified quotient graph nodes.\n\n    Parameters\n    ----------\n    quotientgraph : Any\n        The quotient graph object that contains the point cloud graph.\n    list_quotient_node_to_work : list, optional\n        List of nodes in the quotient graph for which the corresponding nodes in the point\n        cloud graph will be included in the subgraph. Defaults to an empty list.\n\n    Returns\n    -------\n    networkx.Graph\n        The created subgraph that includes all the nodes from the original graph associated\n        with the given list of quotient graph nodes.\n    \"\"\"\n    lqg = list_quotient_node_to_work\n    G = quotientgraph.point_cloud_graph\n\n    lpcd = []\n    for qnode in lqg:\n        list_of_nodes_each = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == qnode]\n        lpcd += list_of_nodes_each\n\n    subgraph_riemannian = nx.subgraph(G, lpcd)\n\n    return subgraph_riemannian\n</code></pre>"},{"location":"reference/spectral_clustering/split_and_merge/#spectral_clustering.split_and_merge.opti_energy_dot_product","title":"opti_energy_dot_product","text":"<pre><code>opti_energy_dot_product(quotientgraph, subgraph_riemannian, angle_to_stop=30, export_iter=True, list_leaves=[])\n</code></pre> <p>Optimize graph energy by iteratively merging nodes based on dot product energy.</p> <p>This function modifies the given quotient graph and its subgraph to iteratively optimize energy by merging nodes connected by edges with the lowest energy. The merging process involves updating node attributes and subgraph structures. Optionally, iteration results can be exported or visualized after each update.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>Graph</code>)           \u2013            <p>The quotient graph on which optimization is performed. This is modified in place and used in conjunction with its associated point cloud graph.</p> </li> <li> <code>subgraph_riemannian</code>               (<code>Graph</code>)           \u2013            <p>A subgraph of the quotient graph focusing on a particular region of the point cloud. This graph plays a key role in computing and organizing cluster information.</p> </li> <li> <code>angle_to_stop</code>               (<code>float</code>, default:                   <code>30</code> )           \u2013            <p>The angle (in degrees) that determines the stopping criterion for energy optimization. The default is 30 degrees. The energy to stop is computed as <code>1 - cos(angle_to_stop)</code>.</p> </li> <li> <code>export_iter</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Boolean flag to specify if intermediate results of the quotient graph optimization should be exported. The default is True.</p> </li> <li> <code>list_leaves</code>               (<code>list</code>, default:                   <code>[]</code> )           \u2013            <p>A list of node identifiers in the graph that are considered leaves. These nodes may affect energy calculations during optimization.</p> </li> </ul> Source code in <code>spectral_clustering/split_and_merge.py</code> <pre><code>def opti_energy_dot_product(quotientgraph, subgraph_riemannian, angle_to_stop=30,\n                            export_iter=True, list_leaves=[]):\n    \"\"\"\n    Optimize graph energy by iteratively merging nodes based on dot product energy.\n\n    This function modifies the given quotient graph and its subgraph to iteratively\n    optimize energy by merging nodes connected by edges with the lowest energy.\n    The merging process involves updating node attributes and subgraph structures.\n    Optionally, iteration results can be exported or visualized after each update.\n\n    Parameters\n    ----------\n    quotientgraph : networkx.Graph\n        The quotient graph on which optimization is performed. This is modified in\n        place and used in conjunction with its associated point cloud graph.\n\n    subgraph_riemannian : networkx.Graph\n        A subgraph of the quotient graph focusing on a particular region of the\n        point cloud. This graph plays a key role in computing and organizing\n        cluster information.\n\n    angle_to_stop : float, optional\n        The angle (in degrees) that determines the stopping criterion for energy\n        optimization. The default is 30 degrees. The energy to stop is computed\n        as `1 - cos(angle_to_stop)`.\n\n    export_iter : bool, optional\n        Boolean flag to specify if intermediate results of the quotient graph\n        optimization should be exported. The default is True.\n\n    list_leaves : list, optional\n        A list of node identifiers in the graph that are considered leaves.\n        These nodes may affect energy calculations during optimization.\n    \"\"\"\n    energy_to_stop = 1 - np.cos(np.radians(angle_to_stop))\n    # take the edge of higher energy and fuse the two nodes involved, then rebuilt the graph, export and redo\n    energy_min = 0\n    i = 0\n    SG = subgraph_riemannian\n    # Create a hard copy subgraph of the quotient graph to compute the energy on a focused part\n    list_quotient_node_to_work = []\n    for no in SG.nodes:\n        list_quotient_node_to_work.append(SG.nodes[no]['quotient_graph_node'])\n    list_of_new_quotient_graph_nodes = list(set(list_quotient_node_to_work))\n    SQG = create_a_subgraph_copy(quotientgraph, list_of_new_quotient_graph_nodes)\n    SQG.point_cloud_graph = SG\n    SQG.compute_direction_info(list_leaves=list_leaves)\n\n    while energy_min &lt; energy_to_stop:\n        # compute energy on nodes\n        start1 = time.time()\n        end1 = time.time()\n        time1 = end1 - start1\n        print(time1)\n        # selection of the edge that bears the less energy\n        start2 = time.time()\n        energy_per_edges = nx.get_edge_attributes(SQG, 'energy_dot_product')\n        edge_to_delete = min(energy_per_edges.items(), key=operator.itemgetter(1))[0]\n        print(edge_to_delete)\n        print(energy_per_edges[edge_to_delete])\n        energy_min = energy_per_edges[edge_to_delete]\n        end2 = time.time()\n        time2 = end2 - start2\n        print(time2)\n\n        # Update node direction mean and intra class node number\n        m1 = SQG.nodes[edge_to_delete[0]]['dir_gradient_mean']\n        m2 = SQG.nodes[edge_to_delete[1]]['dir_gradient_mean']\n        n1 = SQG.nodes[edge_to_delete[0]]['intra_class_node_number']\n        n2 = SQG.nodes[edge_to_delete[1]]['intra_class_node_number']\n        SQG.nodes[edge_to_delete[0]]['dir_gradient_mean'] = (1 / (1 + n2 / n1)) * m1 + (1 / (1 + n1 / n2)) * m2\n        SQG.nodes[edge_to_delete[0]]['intra_class_node_number'] = n1 + n2\n\n        # one cluster is merged into the other one, change of labels on the sub pointcloudgraph label\n        start3 = time.time()\n        list_of_nodes = [x for x, y in SG.nodes(data=True) if y['quotient_graph_node'] == edge_to_delete[1]]\n        for j in range(len(list_of_nodes)):\n            SG.nodes[list_of_nodes[j]]['quotient_graph_node'] = edge_to_delete[0]\n        end3 = time.time()\n        time3 = end3 - start3\n        print(time3)\n        start4 = time.time()\n\n        # Update subgraph_quotient structure\n        SQG = nx.contracted_nodes(SQG, edge_to_delete[0], edge_to_delete[1], self_loops=False)\n        SQG.point_cloud_graph = SG\n        end4 = time.time()\n        time4 = end4 - start4\n        # Update dot energies\n        for e in SQG.edges(edge_to_delete[0]):\n            v1 = SQG.nodes[e[0]]['dir_gradient_mean']\n            v2 = SQG.nodes[e[1]]['dir_gradient_mean']\n            if e[0] in list_leaves or e[1] in list_leaves:\n                SQG.edges[e]['energy_dot_product'] = 4\n            else:\n                dot = v1[0] * v2[0] + v1[1] * v2[1] + v1[2] * v2[2]\n                energy_dot_product = 1 - dot\n                SQG.edges[e]['energy_dot_product'] = energy_dot_product\n\n        print(time4)\n        print('end loop')\n\n        if export_iter:\n            export_some_graph_attributes_on_point_cloud(pcd_g=quotientgraph.point_cloud_graph,\n                                                        graph_attribute='quotient_graph_node',\n                                                        filename='graph_attribute_quotient_graph_' + str(i) + '.txt')\n            # display_and_export_quotient_graph_matplotlib(quotient_graph=quotientgraph, node_sizes=20,\n            # filename=\"quotient_graph_matplotlib_QG_intra_class_number_\" + str(\n            #    i),\n            # data_on_nodes='intra_class_node_number')\n        i += 1\n\n    quotientgraph.rebuild(G=quotientgraph.point_cloud_graph)\n    export_some_graph_attributes_on_point_cloud(pcd_g=quotientgraph.point_cloud_graph,\n                                                graph_attribute='quotient_graph_node',\n                                                filename='final_opti_energy_dot_product.txt')\n</code></pre>"},{"location":"reference/spectral_clustering/split_and_merge/#spectral_clustering.split_and_merge.opti_energy_dot_product_old","title":"opti_energy_dot_product_old","text":"<pre><code>opti_energy_dot_product_old(quotientgraph, energy_to_stop=0.13, leaves_out=False, list_graph_node_to_work=[], export_iter=True)\n</code></pre> <p>Optimize the energy dot product in a graph by iteratively fusing nodes with higher energy edges, rebuilding the graph, and exporting the results. The method modifies the graph and performs operations like edge energy computation, label updates, and graph attribute exports.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>object</code>)           \u2013            <p>A graph object representing the quotient graph. Assumes it has methods to compute direction info, rebuild the graph, and attributes related to the point cloud graph.</p> </li> <li> <code>energy_to_stop</code>               (<code>float</code>, default:                   <code>0.13</code> )           \u2013            <p>Threshold energy value to stop the optimization process. Default is 0.13.</p> </li> <li> <code>leaves_out</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, treats the graph clusters excluding the leaf nodes during the optimization steps. Default is False.</p> </li> <li> <code>list_graph_node_to_work</code>               (<code>list</code>, default:                   <code>[]</code> )           \u2013            <p>A list of specific graph nodes from the point cloud to consider during the optimization process. If empty, the method will compute and process all edges with energy details in the graph. Default is an empty list.</p> </li> <li> <code>export_iter</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, exports graph attributes and visualizations at every iteration of the optimization process. Default is True.</p> </li> </ul> Notes <p>This function is designed for specialized usage with quotient graphs and associated point cloud graphs. The graph manipulation includes operations like merging graph nodes associated by minimum energy, updating attributes in the point cloud graph, and regenerating the quotient graph. The energy is calculated between nodes or edges, directly impacting the choice of clusters or edges for merging. Repeated iterations are performed until the minimum energy exceeds the specified <code>energy_to_stop</code> value. Optionally, leaf nodes may be excluded during processing to focus on core clusters.</p> <p>The function also relies on external calls, such as exporting attributes to a file and displaying the resulting quotient graphs using matplotlib. These external utilities must be implemented separately, and their proper functioning is assumed.</p> Source code in <code>spectral_clustering/split_and_merge.py</code> <pre><code>def opti_energy_dot_product_old(quotientgraph, energy_to_stop=0.13, leaves_out=False, list_graph_node_to_work=[],\n                                export_iter=True):\n    \"\"\"\n    Optimize the energy dot product in a graph by iteratively fusing nodes with higher energy edges,\n    rebuilding the graph, and exporting the results. The method modifies the graph and performs operations\n    like edge energy computation, label updates, and graph attribute exports.\n\n    Parameters\n    ----------\n    quotientgraph : object\n        A graph object representing the quotient graph. Assumes it has methods to compute direction info,\n        rebuild the graph, and attributes related to the point cloud graph.\n    energy_to_stop : float, optional\n        Threshold energy value to stop the optimization process. Default is 0.13.\n    leaves_out : bool, optional\n        If True, treats the graph clusters excluding the leaf nodes during the optimization steps.\n        Default is False.\n    list_graph_node_to_work : list, optional\n        A list of specific graph nodes from the point cloud to consider during the optimization process.\n        If empty, the method will compute and process all edges with energy details in the graph. Default is an empty list.\n    export_iter : bool, optional\n        If True, exports graph attributes and visualizations at every iteration of the optimization process.\n        Default is True.\n\n    Notes\n    -----\n    This function is designed for specialized usage with quotient graphs and associated point cloud graphs.\n    The graph manipulation includes operations like merging graph nodes associated by minimum energy,\n    updating attributes in the point cloud graph, and regenerating the quotient graph. The energy is\n    calculated between nodes or edges, directly impacting the choice of clusters or edges for merging.\n    Repeated iterations are performed until the minimum energy exceeds the specified `energy_to_stop`\n    value. Optionally, leaf nodes may be excluded during processing to focus on core clusters.\n\n    The function also relies on external calls, such as exporting attributes to a file and displaying\n    the resulting quotient graphs using matplotlib. These external utilities must be implemented\n    separately, and their proper functioning is assumed.\n    \"\"\"\n    # take the edge of higher energy and fuse the two nodes involved, then rebuilt the graph, export and redo\n    list_leaves = [x for x in quotientgraph.nodes() if quotientgraph.degree(x) == 1]\n    energy_min = 0\n    i = 0\n\n    while energy_min &lt; energy_to_stop:\n        G = quotientgraph.point_cloud_graph\n        if not list_graph_node_to_work:\n            # select the edge\n            quotientgraph.compute_direction_info(list_leaves)\n            energy_per_edges = nx.get_edge_attributes(quotientgraph, 'energy_dot_product')\n            edge_to_delete = min(energy_per_edges.items(), key=operator.itemgetter(1))[0]\n            print(edge_to_delete)\n            print(energy_per_edges[edge_to_delete])\n            energy_min = energy_per_edges[edge_to_delete]\n            # make list of nodes inside the different quotient graph nodes to work with\n            list_of_nodes = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == edge_to_delete[1]]\n            for j in range(len(list_of_nodes)):\n                G.nodes[list_of_nodes[j]]['quotient_graph_node'] = edge_to_delete[0]\n\n        else:\n            # retrieve the quotient graphe nodes that encapsulate the nodes from pointcloudgraph (list_graph_node_to_work)\n            list_quotient_node_to_work = []\n            for no in range(len(list_graph_node_to_work)):\n                list_quotient_node_to_work.append(G.nodes[list_graph_node_to_work[no]]['quotient_graph_node'])\n            list_of_new_quotient_graph_nodes = list(set(list_quotient_node_to_work))\n\n            # create a subgraph of the quotient graph with only the interesting nodes and compute energy on nodes\n            S = nx.subgraph(quotientgraph, list_of_new_quotient_graph_nodes)\n            quotientgraph.compute_direction_info(list_leaves=[])\n            # selection of the edge that bears the less energy\n            energy_per_edges = nx.get_edge_attributes(S, 'energy_dot_product')\n            edge_to_delete = min(energy_per_edges.items(), key=operator.itemgetter(1))[0]\n            print(edge_to_delete)\n            print(energy_per_edges[edge_to_delete])\n            energy_min = energy_per_edges[edge_to_delete]\n            # one cluster is merged into the other one, change of labels on the pointcloudgraph label\n            list_of_nodes = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == edge_to_delete[1]]\n            for j in range(len(list_of_nodes)):\n                G.nodes[list_of_nodes[j]]['quotient_graph_node'] = edge_to_delete[0]\n\n        if leaves_out:\n            list_one_point_per_leaf = []\n            for l in list_leaves:\n                list_one_point_per_leaf.append([x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == l][0])\n            list_leaves = []\n            for p in list_one_point_per_leaf:\n                list_leaves.append(G.nodes[p]['quotient_graph_node'])\n\n        if export_iter:\n            export_some_graph_attributes_on_point_cloud(pcd_g=quotientgraph.point_cloud_graph,\n                                                        graph_attribute='quotient_graph_node',\n                                                        filename='graph_attribute_quotient_graph_' + str(i) + '.txt')\n            quotientgraph.rebuild(G=quotientgraph.point_cloud_graph)\n            display_and_export_quotient_graph_matplotlib(quotient_graph=quotientgraph, node_sizes=20,\n                                                         filename=\"quotient_graph_matplotlib_QG_intra_class_number_\" + str(\n                                                             i),\n                                                         data_on_nodes='intra_class_node_number')\n        i += 1\n\n    quotientgraph.rebuild(G=quotientgraph.point_cloud_graph)\n    export_some_graph_attributes_on_point_cloud(pcd_g=quotientgraph.point_cloud_graph,\n                                                graph_attribute='quotient_graph_node',\n                                                filename='final_split_and_merge.txt')\n\n    \"\"\"\n    # try to treat the clusters two by two, without the leaves in it. following a shortest path\n    for l in list_leaves:\n        if l != root:\n            path = nx.bidirectional_shortest_path(quotientgraph, root, l)\n            path.pop()\n            path.pop(0)\n            le = len(path)\n            if len(path) &gt;= 2:                    \n            for i in range(le-1):\n                    quotientgraph.segment_several_nodes_using_attribute(list_quotient_node_to_work=[path[i], path[i+1]])\n                G = quotientgraph.point_cloud_graph\n                quotientgraph.rebuild(G)\n\n\n    \"\"\"\n</code></pre>"},{"location":"reference/spectral_clustering/split_and_merge/#spectral_clustering.split_and_merge.oversegment_part","title":"oversegment_part","text":"<pre><code>oversegment_part(quotientgraph, subgraph_riemannian, average_size_cluster=20)\n</code></pre> <p>Segments an input subgraph using clustering and updates the corresponding quotient graph.</p> <p>This function performs oversegmentation of a given subgraph using the KMeans clustering algorithm. It determines a number of clusters based on the average cluster size provided. The resulting cluster labels are then integrated into the quotient graph to represent the updated segmentation.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>object</code>)           \u2013            <p>The input quotient graph to be updated with new segmentation labels.</p> </li> <li> <code>subgraph_riemannian</code>               (<code>Graph</code>)           \u2013            <p>The subgraph to be segmented, where each node must have a 'pos' attribute representing its spatial coordinates.</p> </li> <li> <code>average_size_cluster</code>               (<code>int</code>, default:                   <code>20</code> )           \u2013            <p>The target average number of nodes per cluster. Defaults to 20.</p> </li> </ul> Notes <p>This function expects a Riemannian subgraph that includes spatial positions stored under the 'pos' node attribute. KMeans clustering is performed on these positions. The function also assumes that the quotient graph has methods to update itself with new node labels. The clustering process includes configuring KMeans to perform up to 20 runs (<code>n_init=20</code>) and allow 300 iterations per run with specified tolerance.</p> Source code in <code>spectral_clustering/split_and_merge.py</code> <pre><code>def oversegment_part(quotientgraph, subgraph_riemannian, average_size_cluster=20):\n    \"\"\"\n    Segments an input subgraph using clustering and updates the corresponding quotient graph.\n\n    This function performs oversegmentation of a given subgraph using the KMeans clustering\n    algorithm. It determines a number of clusters based on the average cluster size provided.\n    The resulting cluster labels are then integrated into the quotient graph to represent\n    the updated segmentation.\n\n    Parameters\n    ----------\n    quotientgraph : object\n        The input quotient graph to be updated with new segmentation labels.\n\n    subgraph_riemannian : networkx.Graph\n        The subgraph to be segmented, where each node must have a 'pos' attribute representing\n        its spatial coordinates.\n\n    average_size_cluster : int, optional\n        The target average number of nodes per cluster. Defaults to 20.\n\n    Notes\n    -----\n    This function expects a Riemannian subgraph that includes spatial positions stored under the\n    'pos' node attribute. KMeans clustering is performed on these positions. The function also\n    assumes that the quotient graph has methods to update itself with new node labels. The\n    clustering process includes configuring KMeans to perform up to 20 runs (`n_init=20`) and\n    allow 300 iterations per run with specified tolerance.\n    \"\"\"\n    SG = subgraph_riemannian\n\n    # get all the x,y,z coordinates in an np.array\n    t1 = time.time()\n    Xcoord = np.zeros((len(SG), 3))\n    for u in range(len(SG)):\n        Xcoord[u] = SG.nodes[list(SG.nodes)[u]]['pos']\n    t2 = time.time()\n    print(t2 - t1)\n    # determine a number of cluster we would like to have\n    number_of_points = len(SG)\n    number_of_clusters = number_of_points / average_size_cluster\n\n    t3 = time.time()\n    # clustering via Kmeans to obtain new labels\n    clustering = skc.KMeans(n_clusters=int(number_of_clusters), init='k-means++', n_init=20, max_iter=300,\n                            tol=0.0001).fit(Xcoord)\n    clustering_labels = clustering.labels_[:, np.newaxis] + max(quotientgraph.nodes) + 1\n    t4 = time.time()\n    print(t4 - t3)\n    # Integration of the new labels in the quotient graph and updates\n    t5 = time.time()\n    num = 0\n    for i in SG.nodes:\n        SG.nodes[i]['quotient_graph_node'] = clustering_labels[num]\n        num += 1\n    quotientgraph.rebuild(quotientgraph.point_cloud_graph)\n    t6 = time.time()\n    print(t6 - t5)\n</code></pre>"},{"location":"reference/spectral_clustering/split_and_merge/#spectral_clustering.split_and_merge.oversegment_part_return_list","title":"oversegment_part_return_list","text":"<pre><code>oversegment_part_return_list(quotientgraph, list_quotient_node_to_work=[], average_size_cluster=20)\n</code></pre> <p>Clusters points in a point cloud graph and updates the quotient graph nodes.</p> <p>This function performs clustering on nodes within specified quotient graph nodes and updates their associated quotient graph labels based on the clustering results. The updated quotient graph integrates new labels for further processing.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>object</code>)           \u2013            <p>The quotient graph, which contains the point cloud graph structure (<code>point_cloud_graph</code>) and nodes to be updated with new labels.</p> </li> <li> <code>list_quotient_node_to_work</code>               (<code>list</code>, default:                   <code>[]</code> )           \u2013            <p>A list of quotient graph nodes to be processed. The nodes within these quotient graph nodes are clustered and updated. Default is an empty list.</p> </li> <li> <code>average_size_cluster</code>               (<code>int</code>, default:                   <code>20</code> )           \u2013            <p>The average number of points per cluster, used to determine the desired number of clusters during the clustering process. Default is 20.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>           \u2013            <p>A list of point cloud graph nodes (from the quotient graph node updates) that were processed and are available for subsequent operations.</p> </li> </ul> Source code in <code>spectral_clustering/split_and_merge.py</code> <pre><code>def oversegment_part_return_list(quotientgraph, list_quotient_node_to_work=[], average_size_cluster=20):\n    \"\"\"\n    Clusters points in a point cloud graph and updates the quotient graph nodes.\n\n    This function performs clustering on nodes within specified quotient graph nodes and updates\n    their associated quotient graph labels based on the clustering results. The updated\n    quotient graph integrates new labels for further processing.\n\n    Parameters\n    ----------\n    quotientgraph : object\n        The quotient graph, which contains the point cloud graph structure (`point_cloud_graph`)\n        and nodes to be updated with new labels.\n    list_quotient_node_to_work : list, optional\n        A list of quotient graph nodes to be processed. The nodes within these quotient graph\n        nodes are clustered and updated. Default is an empty list.\n    average_size_cluster : int, optional\n        The average number of points per cluster, used to determine the desired number of\n        clusters during the clustering process. Default is 20.\n\n    Returns\n    -------\n    list\n        A list of point cloud graph nodes (from the quotient graph node updates)\n        that were processed and are available for subsequent operations.\n    \"\"\"\n    lw = list_quotient_node_to_work\n    G = quotientgraph.point_cloud_graph\n    # make list of nodes inside the different quotient graph nodes to work with\n    list_of_nodes = []\n    for qnode in lw:\n        list_of_nodes_each = [x for x, y in G.nodes(data=True) if y['quotient_graph_node'] == qnode]\n        list_of_nodes += list_of_nodes_each\n\n    # get all the x,y,z coordinates in an np.array\n    Xcoord = np.zeros((len(list_of_nodes), 3))\n    for i in range(len(list_of_nodes)):\n        Xcoord[i] = G.nodes[list_of_nodes[i]]['pos']\n\n    # determine a number of cluster we would like to have\n    number_of_points = len(list_of_nodes)\n    number_of_clusters = number_of_points / average_size_cluster\n\n    # clustering via Kmeans to obtain new labels\n    clustering = skc.KMeans(n_clusters=int(number_of_clusters), init='k-means++', n_init=20, max_iter=300,\n                            tol=0.0001).fit(Xcoord)\n    clustering_labels = clustering.labels_[:, np.newaxis] + max(quotientgraph.nodes) + 1\n\n    # Integration of the new labels in the quotient graph and updates\n    for i in range(len(list_of_nodes)):\n        G.nodes[list_of_nodes[i]]['quotient_graph_node'] = clustering_labels[i]\n    quotientgraph.rebuild(G)\n\n    # return of the list of nodes in pointcloudgraph to keep working with them\n    list_of_nodes_pointcloudgraph = list_of_nodes\n    return list_of_nodes_pointcloudgraph\n</code></pre>"},{"location":"reference/spectral_clustering/split_and_merge/#spectral_clustering.split_and_merge.resegment_nodes_with_elbow_method","title":"resegment_nodes_with_elbow_method","text":"<pre><code>resegment_nodes_with_elbow_method(QG, QG_nodes_to_rework=[], number_of_cluster_tested=10, attribute='norm_gradient', number_attribute=1, standardization=False, numer=1, G_mod=True, export_div=False, ret=False)\n</code></pre> <p>Resegments the nodes of a given quotient graph using the elbow method to find the optimal number of clusters.</p> <p>This function takes a quotient graph and a list of nodes to rework, applies the elbow method to resegment them into a more optimal clustering structure, and updates the graph accordingly. The function uses k-means clustering for segmentation and provides an option to standardize certain attributes prior to clustering.</p> <p>Parameters:</p> <ul> <li> <code>QG</code>               (<code>any</code>)           \u2013            <p>The quotient graph on which the resegmentation will be performed.</p> </li> <li> <code>QG_nodes_to_rework</code>               (<code>list</code>, default:                   <code>[]</code> )           \u2013            <p>A list of quotient graph nodes to rework their clustering. Defaults to an empty list.</p> </li> <li> <code>number_of_cluster_tested</code>               (<code>int</code>, default:                   <code>10</code> )           \u2013            <p>The maximum number of clusters to test using the elbow method. Defaults to <code>10</code>.</p> </li> <li> <code>attribute</code>               (<code>str</code>, default:                   <code>'norm_gradient'</code> )           \u2013            <p>The node attribute used for clustering. Defaults to <code>'norm_gradient'</code>.</p> </li> <li> <code>number_attribute</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The dimensionality of the node attribute used for clustering. Defaults to <code>1</code>.</p> </li> <li> <code>standardization</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, the attributes used for clustering are standardized using StandardScaler. Defaults to <code>False</code>.</p> </li> <li> <code>numer</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>An offset added to the new cluster labels. Defaults to <code>1</code>.</p> </li> <li> <code>G_mod</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, modifies the original graph by updating the nodes with the new cluster labels. Defaults to <code>True</code>.</p> </li> <li> <code>export_div</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, exports the new clustered labels to text files. Defaults to <code>False</code>.</p> </li> <li> <code>ret</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>If True, returns the cluster centers of the new segmentation. Defaults to <code>False</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>(ndarray, optional)</code>           \u2013            <p>An array of the cluster centers, if <code>ret</code> is set to True and clustering is performed successfully.</p> </li> </ul> Source code in <code>spectral_clustering/split_and_merge.py</code> <pre><code>def resegment_nodes_with_elbow_method(QG, QG_nodes_to_rework=[], number_of_cluster_tested=10,\n                                      attribute='norm_gradient', number_attribute=1, standardization=False, numer=1,\n                                      G_mod=True, export_div=False, ret=False):\n    \"\"\"Resegments the nodes of a given quotient graph using the elbow method to find the optimal number of clusters.\n\n    This function takes a quotient graph and a list of nodes to rework, applies the elbow method to\n    resegment them into a more optimal clustering structure, and updates the graph accordingly. The\n    function uses k-means clustering for segmentation and provides an option to standardize certain\n    attributes prior to clustering.\n\n    Parameters\n    ----------\n    QG : any\n        The quotient graph on which the resegmentation will be performed.\n    QG_nodes_to_rework : list, optional\n        A list of quotient graph nodes to rework their clustering.\n        Defaults to an empty list.\n    number_of_cluster_tested : int, optional\n        The maximum number of clusters to test using the elbow method.\n        Defaults to `10`.\n    attribute : str, optional\n        The node attribute used for clustering.\n        Defaults to ``'norm_gradient'``.\n    number_attribute : int, optional\n        The dimensionality of the node attribute used for clustering.\n        Defaults to ``1``.\n    standardization : bool, optional\n        If True, the attributes used for clustering are standardized using StandardScaler.\n        Defaults to ``False``.\n    numer : int, optional\n        An offset added to the new cluster labels.\n        Defaults to ``1``.\n    G_mod : bool, optional\n        If True, modifies the original graph by updating the nodes with the new cluster labels.\n        Defaults to ``True``.\n    export_div : bool, optional\n        If True, exports the new clustered labels to text files.\n        Defaults to ``False``.\n    ret : bool, optional\n        If True, returns the cluster centers of the new segmentation.\n        Defaults to ``False``.\n\n    Returns\n    -------\n    numpy.ndarray, optional\n        An array of the cluster centers, if `ret` is set to True and clustering is performed successfully.\n    \"\"\"\n    G = QG.point_cloud_graph\n    qg_values = nx.get_node_attributes(G, 'quotient_graph_node')\n    maxi = max(qg_values.values())\n    num = maxi + numer\n    for i in QG_nodes_to_rework:\n        sub = create_subgraphs_to_work(quotientgraph=QG, list_quotient_node_to_work=[i])\n        SG = sub\n        list_nodes = list(SG.nodes)\n        # creation of matrices to work with in the elbow_method package\n        if len(SG.nodes) &gt; number_of_cluster_tested:\n            Xcoord = np.zeros((len(SG), 3))\n            for u in range(len(SG)):\n                Xcoord[u] = SG.nodes[list(SG.nodes)[u]]['pos']\n            Xnorm = np.zeros((len(SG), number_attribute))\n            for u in range(len(SG)):\n                Xnorm[u] = SG.nodes[list(SG.nodes)[u]][attribute]\n\n            if standardization:\n                sc = StandardScaler()\n                Xnorm = sc.fit_transform(Xnorm)\n\n            # Instantiate the clustering model and visualizer\n            model = KMeans()\n            visualizer = KElbowVisualizer(model, k=(1, number_of_cluster_tested), metric='distortion')\n\n            visualizer.fit(Xnorm)  # Fit the data to the visualizer\n            # visualizer.show()        # Finalize and render the figure\n            # Resegment and actualize the pointcloudgraph\n            k_opt = visualizer.elbow_value_\n            print(k_opt)\n            if k_opt &gt; 1:\n                clustering = skc.KMeans(n_clusters=k_opt, init='k-means++', n_init=20, max_iter=300, tol=0.0001).fit(\n                    Xnorm)\n                new_labels = np.zeros((len(SG.nodes), 4))\n                new_labels[:, 0:3] = Xcoord\n                for pt in range(len(list_nodes)):\n                    new_labels[pt, 3] = clustering.labels_[pt] + num\n                    if G_mod:\n                        G.nodes[list_nodes[pt]]['quotient_graph_node'] = new_labels[pt, 3]\n                num += k_opt + len(list_nodes)\n\n                # print(i, ' divided in ', k_opt)\n                if export_div:\n                    np.savetxt('pcd_new_labels_' + str(i) + '.txt', new_labels, delimiter=\",\")\n                    indices = np.argsort(new_labels[:, 3])\n                    arr_temp = new_labels[indices]\n                    np.array_split(arr_temp, np.where(np.diff(arr_temp[:, 3]) != 0)[0] + 1)\n                    v = 0\n                    for arr in arr_temp:\n                        np.savetxt('pcd_new_labels_' + str(i) + str(v) + '.txt', arr, delimiter=\",\")\n                        v += 1\n                if ret is True:\n                    cluster_c = clustering.cluster_centers_\n                    return cluster_c\n\n            else:\n                print(\"nothing to cluster\")\n</code></pre>"},{"location":"reference/spectral_clustering/split_and_merge/#spectral_clustering.split_and_merge.select_all_quotientgraph_nodes_from_pointcloudgraph_cluster","title":"select_all_quotientgraph_nodes_from_pointcloudgraph_cluster","text":"<pre><code>select_all_quotientgraph_nodes_from_pointcloudgraph_cluster(G, QG, labelpointcloudgraph, attribute='kmeans_labels')\n</code></pre> <p>Select all quotient graph nodes corresponding to a specific point cloud graph cluster.</p> <p>This function identifies and selects the quotient graph nodes which correspond to a specific cluster in the point cloud graph. The selection is based on the provided clustering labels and a specified attribute.</p> <p>Parameters:</p> <ul> <li> <code>G</code>               (<code>Graph</code>)           \u2013            <p>The original point cloud graph containing the clustering labels.</p> </li> <li> <code>QG</code>               (<code>Graph</code>)           \u2013            <p>The quotient graph derived from the point cloud graph.</p> </li> <li> <code>labelpointcloudgraph</code>               (<code>int</code>)           \u2013            <p>The label of the cluster in the point cloud graph to be matched.</p> </li> <li> <code>attribute</code>               (<code>str</code>, default:                   <code>'kmeans_labels'</code> )           \u2013            <p>The clustering attribute name used for matching, default is 'kmeans_labels'.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list_leaves</code> (              <code>list</code> )          \u2013            <p>A list of quotient graph nodes associated with the specific cluster label.</p> </li> </ul> Source code in <code>spectral_clustering/split_and_merge.py</code> <pre><code>def select_all_quotientgraph_nodes_from_pointcloudgraph_cluster(G, QG, labelpointcloudgraph, attribute='kmeans_labels'):\n    \"\"\"\n    Select all quotient graph nodes corresponding to a specific point cloud graph cluster.\n\n    This function identifies and selects the quotient graph nodes which correspond to a\n    specific cluster in the point cloud graph. The selection is based on the provided\n    clustering labels and a specified attribute.\n\n    Parameters\n    ----------\n    G : networkx.Graph\n        The original point cloud graph containing the clustering labels.\n    QG : networkx.Graph\n        The quotient graph derived from the point cloud graph.\n    labelpointcloudgraph : int\n        The label of the cluster in the point cloud graph to be matched.\n    attribute : str, optional\n        The clustering attribute name used for matching, default is 'kmeans_labels'.\n\n    Returns\n    -------\n    list_leaves : list\n        A list of quotient graph nodes associated with the specific cluster label.\n\n    \"\"\"\n    # Select clusters that were associated with the smallest value of kmeans centroid.\n    compute_quotient_graph_mean_attribute_from_points(G, QG, attribute=attribute)\n    list_leaves = [x for x in QG.nodes() if QG.nodes[x][attribute + '_mean'] == labelpointcloudgraph]\n    return list_leaves\n</code></pre>"},{"location":"reference/spectral_clustering/split_and_merge/#spectral_clustering.split_and_merge.select_minimum_centroid_class","title":"select_minimum_centroid_class","text":"<pre><code>select_minimum_centroid_class(clusters_centers)\n</code></pre> <p>Selects the label of the cluster with the minimum centroid value.</p> <p>This function identifies the cluster with the smallest centroid value from the provided array of cluster centroids and returns the corresponding cluster label.</p> <p>Parameters:</p> <ul> <li> <code>clusters_centers</code>               (<code>ndarray</code>)           \u2013            <p>A 1D numpy array containing the centroid values of all clusters.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>The label of the cluster with the smallest centroid value.</p> </li> </ul> Source code in <code>spectral_clustering/split_and_merge.py</code> <pre><code>def select_minimum_centroid_class(clusters_centers):\n    \"\"\"\n    Selects the label of the cluster with the minimum centroid value.\n\n    This function identifies the cluster with the smallest centroid\n    value from the provided array of cluster centroids and returns\n    the corresponding cluster label.\n\n    Parameters\n    ----------\n    clusters_centers : numpy.ndarray\n        A 1D numpy array containing the centroid values of all clusters.\n\n    Returns\n    -------\n    int\n        The label of the cluster with the smallest centroid value.\n    \"\"\"\n    mincluster = np.where(clusters_centers == np.amin(clusters_centers))\n    labelmincluster = mincluster[0][0]\n    return labelmincluster\n</code></pre>"},{"location":"reference/spectral_clustering/topological_energy/","title":"topological_energy","text":""},{"location":"reference/spectral_clustering/topological_energy/#spectral_clustering.topological_energy.define_and_optimize_topological_energy","title":"define_and_optimize_topological_energy","text":"<pre><code>define_and_optimize_topological_energy(quotient_graph, point_cloud_graph, exports=True, formulae='improved', number_of_iteration=1000, choice_of_node_to_change='max_energy')\n</code></pre> <p>Compute and optimize the topological scores of each node in the PointCloudGraph.</p> <p>This function first calculates the initial topological scores for each node in the <code>point_cloud_graph</code> using the <code>init_topo_scores</code> function. Following this, it optimizes the topological energy using the <code>optimization_topo_scores</code> function.</p> <p>Parameters:</p> <ul> <li> <code>quotient_graph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph derived from the <code>PointCloudGraph</code>.</p> </li> <li> <code>point_cloud_graph</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The associated distance-based PointCloudGraph.</p> </li> <li> <code>exports</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, exports the computed scores to a <code>.txt</code> file and saves a visualization of the scores on the quotient graph as a <code>.png</code> image. Default is True.</p> </li> <li> <code>formulae</code>               (<code>str</code>, default:                   <code>'improved'</code> )           \u2013            <p>Determines the formula used to compute the topological energy for a node. Options are: - <code>'improved'</code> (default): Uses the improved formula. - <code>'old'</code>: Uses the old formula.</p> </li> <li> <code>number_of_iteration</code>               (<code>int</code>, default:                   <code>1000</code> )           \u2013            <p>The number of iterations for topological energy optimization. Default is 1000.</p> </li> <li> <code>choice_of_node_to_change</code>               (<code>str</code>, default:                   <code>'max_energy'</code> )           \u2013            <p>The method used to select a node for changing its cluster. Options are: - <code>'max_energy'</code> (default): Selects the node with the maximum energy. - <code>'random_proba_energy'</code>: Selects a node based on a probability distribution   of energy values. - <code>'max_energy_and_select'</code>: Selects the maximum energy node with additional   selection criteria.</p> </li> </ul> Notes <p>The function consists of two main steps: 1. Calculation of initial topological scores with <code>init_topo_scores</code>. 2. Optimization of scores using <code>optimization_topo_scores</code>.</p> <p>At the end of the process, a summary message is printed to indicate that the optimization has been completed.</p> Source code in <code>spectral_clustering/topological_energy.py</code> <pre><code>def define_and_optimize_topological_energy(quotient_graph,\n                                           point_cloud_graph,\n                                           exports=True,\n                                           formulae='improved',\n                                           number_of_iteration=1000,\n                                           choice_of_node_to_change='max_energy'):\n    \"\"\"Compute and optimize the topological scores of each node in the PointCloudGraph.\n\n    This function first calculates the initial topological scores for each node in\n    the `point_cloud_graph` using the `init_topo_scores` function. Following this, it\n    optimizes the topological energy using the `optimization_topo_scores` function.\n\n    Parameters\n    ----------\n    quotient_graph : spectral_clustering.graph.QuotientGraph\n        The quotient graph derived from the `PointCloudGraph`.\n    point_cloud_graph : spectral_clustering.graph.PointCloudGraph\n        The associated distance-based PointCloudGraph.\n    exports : bool, optional\n        If True, exports the computed scores to a `.txt` file and saves a visualization\n        of the scores on the quotient graph as a `.png` image. Default is True.\n    formulae : str, optional\n        Determines the formula used to compute the topological energy for a node.\n        Options are:\n        - `'improved'` (default): Uses the improved formula.\n        - `'old'`: Uses the old formula.\n    number_of_iteration : int, optional\n        The number of iterations for topological energy optimization. Default is 1000.\n    choice_of_node_to_change : str, optional\n        The method used to select a node for changing its cluster. Options are:\n        - `'max_energy'` (default): Selects the node with the maximum energy.\n        - `'random_proba_energy'`: Selects a node based on a probability distribution\n          of energy values.\n        - `'max_energy_and_select'`: Selects the maximum energy node with additional\n          selection criteria.\n\n    Notes\n    -----\n    The function consists of two main steps:\n    1. Calculation of initial topological scores with `init_topo_scores`.\n    2. Optimization of scores using `optimization_topo_scores`.\n\n    At the end of the process, a summary message is printed to indicate that the\n    optimization has been completed.\n    \"\"\"\n    init_topo_scores(quotient_graph=quotient_graph,\n                     point_cloud_graph=point_cloud_graph,\n                     exports=exports,\n                     formulae=formulae)\n    optimization_topo_scores(quotientgraph=quotient_graph,\n                             pointcloudgraph=point_cloud_graph,\n                             exports=exports,\n                             number_of_iteration=number_of_iteration,\n                             choice_of_node_to_change=choice_of_node_to_change,\n                             formulae=formulae)\n\n    print('Optimization of topological energy : Done')\n</code></pre>"},{"location":"reference/spectral_clustering/topological_energy/#spectral_clustering.topological_energy.init_topo_scores","title":"init_topo_scores","text":"<pre><code>init_topo_scores(quotient_graph, point_cloud_graph, exports=True, formulae='improved')\n</code></pre> <p>Calculate the topological scores for each node in the PointCloudGraph and associated energy metrics for the QuotientGraph.</p> <p>This function computes the number of adjacent clusters in the PointCloudGraph that are different from the cluster of the considered node. It also calculates a per-node energy score for the QuotientGraph and the global topological energy of the entire QuotientGraph, which is the sum of the energies of its nodes.</p> <p>Parameters:</p> <ul> <li> <code>quotient_graph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The QuotientGraph object representing the coarse-grained view of the PointCloudGraph.</p> </li> <li> <code>point_cloud_graph</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The PointCloudGraph object, typically a distance-based graph, associated with the quotient graph.</p> </li> <li> <code>exports</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, exports the computed scores to a <code>.txt</code> file and a matplotlib visualization (<code>.png</code>) of the quotient graph. Default is True.</p> </li> <li> <code>formulae</code>               (<code>(improved, old)</code>, default:                   <code>'improved'</code> )           \u2013            <p>Specifies the formula used to compute the topological energy for each node: - 'improved': A refined computation method based on normalized counts of adjacent   clusters. - 'old': A simpler, earlier computational approach. Default is 'improved'.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>This function modifies <code>quotient_graph</code> and <code>point_cloud_graph</code> in place by adding attributes such as: - <code>number_of_adj_labels</code> for the PointCloudGraph nodes. - <code>topological_energy</code> for the QuotientGraph nodes. Additionally, the global topological energy is stored in the <code>quotient_graph.graph</code> attribute: <code>global_topological_energy</code>.</p> </li> </ul> Notes <ul> <li>When <code>formulae='improved'</code>, the energy calculation considers the normalized   contributions of connections to clusters different from the node\u2019s own cluster.</li> <li>This function works in-place, directly modifying the input graph objects.</li> <li>If <code>exports</code> is True, the function will generate:<ul> <li>A <code>.txt</code> file containing the computed energy scores for the PointCloudGraph.</li> <li>A <code>.png</code> visualization of the QuotientGraph with node energies annotated.</li> </ul> </li> </ul> See Also <p>export_some_graph_attributes_on_point_cloud : Export node attributes for visualization or analysis. display_and_export_quotient_graph_matplotlib : Display and save a visualization of the graph structure.</p> Source code in <code>spectral_clustering/topological_energy.py</code> <pre><code>def init_topo_scores(quotient_graph, point_cloud_graph, exports=True, formulae='improved'):\n    \"\"\"\n    Calculate the topological scores for each node in the PointCloudGraph and associated\n    energy metrics for the QuotientGraph.\n\n    This function computes the number of adjacent clusters in the PointCloudGraph that are\n    different from the cluster of the considered node. It also calculates a per-node energy\n    score for the QuotientGraph and the global topological energy of the entire QuotientGraph,\n    which is the sum of the energies of its nodes.\n\n    Parameters\n    ----------\n    quotient_graph : spectral_clustering.graph.QuotientGraph\n        The QuotientGraph object representing the coarse-grained view of the PointCloudGraph.\n    point_cloud_graph : spectral_clustering.graph.PointCloudGraph\n        The PointCloudGraph object, typically a distance-based graph, associated with\n        the quotient graph.\n    exports : bool, optional\n        If True, exports the computed scores to a `.txt` file and a matplotlib\n        visualization (`.png`) of the quotient graph. Default is True.\n    formulae : {'improved', 'old'}, optional\n        Specifies the formula used to compute the topological energy for each node:\n        - 'improved': A refined computation method based on normalized counts of adjacent\n          clusters.\n        - 'old': A simpler, earlier computational approach. Default is 'improved'.\n\n    Returns\n    -------\n    None\n        This function modifies `quotient_graph` and `point_cloud_graph` in place by adding\n        attributes such as:\n        - `number_of_adj_labels` for the PointCloudGraph nodes.\n        - `topological_energy` for the QuotientGraph nodes.\n        Additionally, the global topological energy is stored in the `quotient_graph.graph`\n        attribute: `global_topological_energy`.\n\n    Notes\n    -----\n    - When `formulae='improved'`, the energy calculation considers the normalized\n      contributions of connections to clusters different from the node\u2019s own cluster.\n    - This function works in-place, directly modifying the input graph objects.\n    - If `exports` is True, the function will generate:\n        - A `.txt` file containing the computed energy scores for the PointCloudGraph.\n        - A `.png` visualization of the QuotientGraph with node energies annotated.\n\n    See Also\n    --------\n    export_some_graph_attributes_on_point_cloud : Export node attributes for visualization or analysis.\n    display_and_export_quotient_graph_matplotlib : Display and save a visualization of the graph structure.\n    \"\"\"\n    QG = quotient_graph\n    G = point_cloud_graph\n\n    # Determinate a score for each vertex in a quotient node. Normalized by the number of neighbors\n    # init\n    maxNeighbSize = 0\n    for u in G.nodes:\n        G.nodes[u]['number_of_adj_labels'] = 0\n    for u in QG.nodes:\n        QG.nodes[u]['topological_energy'] = 0\n    # global score for the entire graph\n    QG.graph['global_topological_energy'] = 0\n    # for to compute the score of each vertex\n    if formulae == 'old':\n        for v in G.nodes:\n            number_of_neighb = len([n for n in G[v]])\n            for n in G[v]:\n                if G.nodes[v]['quotient_graph_node'] != G.nodes[n]['quotient_graph_node']:\n                    G.nodes[v]['number_of_adj_labels'] += 1\n            G.nodes[v]['number_of_adj_labels'] /= number_of_neighb\n            u = G.nodes[v]['quotient_graph_node']\n            QG.nodes[u]['topological_energy'] += G.nodes[v]['number_of_adj_labels']\n            QG.graph['global_topological_energy'] += G.nodes[v]['number_of_adj_labels']\n    elif formulae == 'improved':\n        for v in G.nodes:\n            list_neighb_clust = []\n            for n in G[v]:\n                list_neighb_clust.append(G.nodes[n]['quotient_graph_node'])\n            number_of_clusters = len(Counter(list_neighb_clust).keys())\n            if number_of_clusters == 1 and list_neighb_clust[0] == G.nodes[v]['quotient_graph_node']:\n                G.nodes[v]['number_of_adj_labels'] = 0\n            else:\n                number_same = list_neighb_clust.count(G.nodes[v]['quotient_graph_node'])\n                number_diff = len(list_neighb_clust) - number_same\n                G.nodes[v]['number_of_adj_labels'] = number_diff / \\\n                                                     (number_diff + (number_of_clusters - 1) * number_same)\n            u = G.nodes[v]['quotient_graph_node']\n            QG.nodes[u]['topological_energy'] += G.nodes[v]['number_of_adj_labels']\n            QG.graph['global_topological_energy'] += G.nodes[v]['number_of_adj_labels']\n\n    if exports:\n        export_some_graph_attributes_on_point_cloud(G, graph_attribute='number_of_adj_labels',\n                                                    filename='graph_attribute_energy_init.txt')\n\n        display_and_export_quotient_graph_matplotlib(QG, node_sizes=20, name=\"quotient_graph_matplotlib_energy_init\",\n                                                     data_on_nodes='topological_energy')\n</code></pre>"},{"location":"reference/spectral_clustering/topological_energy/#spectral_clustering.topological_energy.optimization_topo_scores","title":"optimization_topo_scores","text":"<pre><code>optimization_topo_scores(quotientgraph, pointcloudgraph, exports=True, number_of_iteration=1000, choice_of_node_to_change='max_energy', formulae='improved')\n</code></pre> <p>Optimizes the topological scores by iteratively modifying clusters of nodes in a point cloud graph and updating the corresponding energies.</p> <p>The function starts by selecting a node based on its energy using the specified selection method. The selected node changes its cluster to one of its neighbor's clusters. The function then updates the global topological energy and other graph properties accordingly. The process is repeated for a specified number of iterations and can export the results, including graphs showing energy evolution.</p> <p>Parameters:</p> <ul> <li> <code>quotientgraph</code>               (<code>QuotientGraph</code>)           \u2013            <p>The quotient graph that contains meta-information about clusters and associated energy values. This graph gets updated with changes during optimization.</p> </li> <li> <code>pointcloudgraph</code>               (<code>PointCloudGraph</code>)           \u2013            <p>The point cloud graph where each node represents a point and is associated with cluster data. This is the main graph on which optimization operations are performed.</p> </li> <li> <code>exports</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>If True, the function will export the graph showing the evolution of the global energy, the quotient graph with energy values for each node, and point-cloud-related data. Default is True.</p> </li> <li> <code>number_of_iteration</code>               (<code>int</code>, default:                   <code>1000</code> )           \u2013            <p>The total number of iterations to perform for optimization. Default is 1000.</p> </li> <li> <code>choice_of_node_to_change</code>               (<code>str</code>, default:                   <code>'max_energy'</code> )           \u2013            <p>Method used to select the node for changing its cluster. Options include: - 'max_energy': Select nodes with the maximum energy. - 'random_proba_energy': Select nodes probabilistically based on normalized energy. - 'max_energy_and_select': Select nodes with maximum energy, applying additional   constraints to avoid repeated selections. Default is 'max_energy'.</p> </li> <li> <code>formulae</code>               (<code>str</code>, default:                   <code>'improved'</code> )           \u2013            <p>The formula used for updating the energy based on cluster changes. Options: - 'old': Uses the original formula for energy updates. - 'improved': Uses an enhanced formula to adjust energy dependencies. This must match the formula used during the initialization of the system. Default is 'improved'.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>None</code>           \u2013            <p>This function modifies the given input graphs (<code>quotientgraph</code> and <code>pointcloudgraph</code>) in place and optionally exports results as files.</p> </li> </ul> Notes <ul> <li>The function internally tracks the global energy values across iterations and can   export these results visually as scatter plots.</li> <li>Clusters for the nodes are determined by their neighbors' attributes and random   weight probabilities derived from their local environment.</li> </ul> Source code in <code>spectral_clustering/topological_energy.py</code> <pre><code>def optimization_topo_scores(quotientgraph, pointcloudgraph, exports=True, number_of_iteration=1000,\n                             choice_of_node_to_change='max_energy', formulae='improved'):\n    \"\"\"Optimizes the topological scores by iteratively modifying clusters of nodes in\n    a point cloud graph and updating the corresponding energies.\n\n    The function starts by selecting a node based on its energy using the specified\n    selection method. The selected node changes its cluster to one of its neighbor's\n    clusters. The function then updates the global topological energy and other graph\n    properties accordingly. The process is repeated for a specified number of iterations\n    and can export the results, including graphs showing energy evolution.\n\n    Parameters\n    ----------\n    quotientgraph : spectral_clustering.graph.QuotientGraph\n        The quotient graph that contains meta-information about clusters and associated\n        energy values. This graph gets updated with changes during optimization.\n    pointcloudgraph : spectral_clustering.graph.PointCloudGraph\n        The point cloud graph where each node represents a point and is associated with\n        cluster data. This is the main graph on which optimization operations are performed.\n    exports : bool, optional\n        If True, the function will export the graph showing the evolution of the global\n        energy, the quotient graph with energy values for each node, and point-cloud-related\n        data. Default is True.\n    number_of_iteration : int, optional\n        The total number of iterations to perform for optimization. Default is 1000.\n    choice_of_node_to_change : str, optional\n        Method used to select the node for changing its cluster. Options include:\n        - 'max_energy': Select nodes with the maximum energy.\n        - 'random_proba_energy': Select nodes probabilistically based on normalized energy.\n        - 'max_energy_and_select': Select nodes with maximum energy, applying additional\n          constraints to avoid repeated selections.\n        Default is 'max_energy'.\n    formulae : str, optional\n        The formula used for updating the energy based on cluster changes. Options:\n        - 'old': Uses the original formula for energy updates.\n        - 'improved': Uses an enhanced formula to adjust energy dependencies.\n        This must match the formula used during the initialization of the system.\n        Default is 'improved'.\n\n    Returns\n    -------\n    None\n        This function modifies the given input graphs (`quotientgraph` and\n        `pointcloudgraph`) in place and optionally exports results as files.\n\n    Notes\n    -----\n    - The function internally tracks the global energy values across iterations and can\n      export these results visually as scatter plots.\n    - Clusters for the nodes are determined by their neighbors' attributes and random\n      weight probabilities derived from their local environment.\n    \"\"\"\n    G = pointcloudgraph\n\n    # nombre d'it\u00e9rations\n    iter = number_of_iteration\n    # Liste contenant l'\u00e9nergie globale du graph\n    evol_energy = [quotientgraph.graph['global_topological_energy']]\n\n    # list to detect repetition in 'max_energy_and_select'\n    detect_rep = []\n    ban_list = []\n\n    # Start loops for the number of iteration specified\n    for i in range(iter):\n\n        # Choice of point to move from a cluster to another.\n\n        if choice_of_node_to_change == 'max_energy':\n            # Creation of a dictionary with the energy per node\n            energy_per_node = nx.get_node_attributes(G, 'number_of_adj_labels')\n            # Extraction of a random point to treat, use of \"smart indexing\"\n            nodes = np.array(list(energy_per_node.keys()))\n            mylist = list(energy_per_node.values())\n            myRoundedList = [round(x, 2) for x in mylist]\n            node_energies = np.array(myRoundedList)\n            maximal_energy_nodes = nodes[node_energies == np.max(node_energies)]\n            node_to_change = np.random.choice(maximal_energy_nodes)\n        if choice_of_node_to_change == 'random_proba_energy':\n            energy_per_node = nx.get_node_attributes(G, 'number_of_adj_labels')\n            nodes = np.array(list(energy_per_node.keys()))\n            total_energy = quotientgraph.graph['global_topological_energy']\n            l = list(energy_per_node.values())\n            node_energies = np.array([e / total_energy for e in l])\n            node_to_change = np.random.choice(nodes, p=node_energies)\n        if choice_of_node_to_change == 'max_energy_and_select':\n            energy_per_node = nx.get_node_attributes(G, 'number_of_adj_labels')\n            nodes = np.array(list(energy_per_node.keys()))\n            node_energies = np.array(list(energy_per_node.values()))\n            maximal_energy_nodes = nodes[node_energies == np.max(node_energies)]\n            node_to_change = np.random.choice(maximal_energy_nodes)\n            if ban_list.count(node_to_change) == 0:\n                if detect_rep.count(node_to_change) == 0 and ban_list.count(node_to_change) == 0:\n                    detect_rep.append(node_to_change)\n                if detect_rep.count(node_to_change) != 0:\n                    detect_rep.append(node_to_change)\n            if ban_list.count(node_to_change) != 0:\n                sort_energy_per_node = {k: v for k, v in\n                                        sorted(energy_per_node.items(), key=lambda item: item[1], reverse=True)}\n                for c in sort_energy_per_node:\n                    if ban_list.count(c) == 0:\n                        node_to_change = c\n                        if detect_rep.count(node_to_change) == 0:\n                            detect_rep.append(node_to_change)\n                        else:\n                            detect_rep.append(node_to_change)\n                        break\n            if detect_rep.count(node_to_change) &gt;= G.nearest_neighbors * 2:\n                ban_list.append(node_to_change)\n                detect_rep = []\n\n        # print()\n        # print(i)\n        # print(ban_list)\n        # print(node_to_change)\n        # print(G.nodes[node_to_change]['number_of_adj_labels'])\n        # print(G.nodes[node_to_change]['quotient_graph_node'])\n\n        # change the cluster of the node_to_change\n        number_of_neighb = len([n for n in G[node_to_change]])\n        # attribution for each label a probability depending on the number of points having this label\n        # in the neighborhood of node_to_change\n        # stocked in a dictionary\n        old_cluster = G.nodes[node_to_change]['quotient_graph_node']\n        proba_label = {}\n        for n in G[node_to_change]:\n            if G.nodes[n]['quotient_graph_node'] not in proba_label:\n                proba_label[G.nodes[n]['quotient_graph_node']] = 0\n            proba_label[G.nodes[n]['quotient_graph_node']] += 1.0 / number_of_neighb\n\n        new_label_proba = np.random.random()\n        new_energy = 0\n        range_origin = 0\n        for l in proba_label:\n            if new_label_proba &lt;= range_origin or new_label_proba &gt; range_origin + proba_label[l]:\n                new_energy += proba_label[l]\n            else:\n                G.nodes[node_to_change]['quotient_graph_node'] = l\n            range_origin += proba_label[l]\n\n        new_cluster = G.nodes[node_to_change]['quotient_graph_node']\n\n        update_quotient_graph_attributes_when_node_change_cluster(quotientgraph, old_cluster, new_cluster,\n                                                                  node_to_change)\n\n        if formulae == 'old':\n            # update of energy for the node changed\n            previous_energy = G.nodes[node_to_change]['number_of_adj_labels']\n            G.nodes[node_to_change]['number_of_adj_labels'] = new_energy\n            quotientgraph.graph['global_topological_energy'] += (new_energy - previous_energy)\n            u = G.nodes[node_to_change]['quotient_graph_node']\n            quotientgraph.nodes[u]['topological_energy'] += new_energy\n            quotientgraph.nodes[old_cluster]['topological_energy'] -= previous_energy\n            # update of energy for the neighbors\n            for n in G[node_to_change]:\n                previous_energy = G.nodes[n]['number_of_adj_labels']\n                G.nodes[n]['number_of_adj_labels'] = 0\n                for v in G[n]:\n                    number_of_neighb = len([n for n in G[v]])\n                    if G.nodes[n]['quotient_graph_node'] != G.nodes[v]['quotient_graph_node']:\n                        G.nodes[n]['number_of_adj_labels'] += 1 / number_of_neighb\n                quotientgraph.graph['global_topological_energy'] += (\n                        G.nodes[n]['number_of_adj_labels'] - previous_energy)\n                u = G.nodes[n]['quotient_graph_node']\n                quotientgraph.nodes[u]['topological_energy'] += (G.nodes[n]['number_of_adj_labels'] - previous_energy)\n\n        elif formulae == 'improved':\n            # update of energy for the node changed\n            list_neighb_clust = []\n            previous_energy = G.nodes[node_to_change]['number_of_adj_labels']\n            for n in G[node_to_change]:\n                list_neighb_clust.append(G.nodes[n]['quotient_graph_node'])\n            number_of_clusters = len(Counter(list_neighb_clust).keys())\n            if number_of_clusters == 1 and list_neighb_clust[0] == new_cluster:\n                G.nodes[node_to_change]['number_of_adj_labels'] = 0\n            else:\n                number_same = list_neighb_clust.count(G.nodes[node_to_change]['quotient_graph_node'])\n                number_diff = len(list_neighb_clust) - number_same\n                G.nodes[node_to_change]['number_of_adj_labels'] = number_diff / (\n                        number_diff + (number_of_clusters - 1) * number_same)\n\n            new_energy = G.nodes[node_to_change]['number_of_adj_labels']\n            quotientgraph.graph['global_topological_energy'] += (new_energy - previous_energy)\n            quotientgraph.nodes[new_cluster]['topological_energy'] += new_energy\n            quotientgraph.nodes[old_cluster]['topological_energy'] -= previous_energy\n\n            # update energy of the neighbors\n            for n in G[node_to_change]:\n                list_neighb_clust = []\n                previous_energy = G.nodes[n]['number_of_adj_labels']\n                G.nodes[n]['number_of_adj_labels'] = 0\n                for v in G[n]:\n                    list_neighb_clust.append(G.nodes[v]['quotient_graph_node'])\n                number_of_clusters = len(Counter(list_neighb_clust).keys())\n                if number_of_clusters == 1 and list_neighb_clust[0] == G.nodes[n]['quotient_graph_node']:\n                    G.nodes[n]['number_of_adj_labels'] = 0\n                else:\n                    number_same = list_neighb_clust.count(G.nodes[n]['quotient_graph_node'])\n                    number_diff = len(list_neighb_clust) - number_same\n                    G.nodes[n]['number_of_adj_labels'] = number_diff / (\n                            number_diff + (number_of_clusters - 1) * number_same)\n                new_energy = G.nodes[n]['number_of_adj_labels']\n                quotientgraph.graph['global_topological_energy'] += (new_energy - previous_energy)\n                u = G.nodes[n]['quotient_graph_node']\n                quotientgraph.nodes[u]['topological_energy'] += (new_energy - previous_energy)\n\n        # update list containing all the differents stages of energy obtained\n        evol_energy.append(quotientgraph.graph['global_topological_energy'])\n\n    quotientgraph.delete_empty_edges_and_nodes()\n    quotientgraph.point_cloud_graph = G\n    if exports:\n        from matplotlib import pyplot as plt\n        figure = plt.figure(1)\n        figure.clf()\n        figure.gca().set_title(\"Evolution_of_energy\")\n        plt.autoscale(enable=True, axis='both', tight=None)\n        figure.gca().scatter(range(len(evol_energy)), evol_energy, color='blue')\n        figure.set_size_inches(10, 10)\n        figure.subplots_adjust(wspace=0, hspace=0)\n        figure.tight_layout()\n        figure.savefig('Evolution_global_energy')\n        print(\"Export \u00e9nergie globale\")\n\n        display_and_export_quotient_graph_matplotlib(quotientgraph, node_sizes=20,\n                                                     name=\"quotient_graph_matplotlib_energy_final\",\n                                                     data_on_nodes='topological_energy')\n        export_some_graph_attributes_on_point_cloud(G, graph_attribute='number_of_adj_labels',\n                                                    filename='graph_attribute_energy_final.txt')\n\n        export_some_graph_attributes_on_point_cloud(G, graph_attribute='quotient_graph_node',\n                                                    filename='graph_attribute_quotient_graph_node_final.txt')\n</code></pre>"},{"location":"reference/spectral_clustering/utils/","title":"utils","text":""},{"location":"reference/spectral_clustering/utils/angle/","title":"angle","text":""},{"location":"reference/spectral_clustering/utils/size/","title":"size","text":""},{"location":"reference/spectral_clustering/utils/size/#spectral_clustering.utils.size.getsize","title":"getsize","text":"<pre><code>getsize(obj)\n</code></pre> <p>sum size of object &amp; members.</p> Source code in <code>spectral_clustering/utils/size.py</code> <pre><code>def getsize(obj):\n    \"\"\"sum size of object &amp; members.\"\"\"\n    if isinstance(obj, (type, ModuleType, FunctionType)):\n        raise TypeError('getsize() does not take argument of type: '+ str(type(obj)))\n    seen_ids = set()\n    size = 0\n    objects = [obj]\n    while objects:\n        need_referents = []\n        for obj in objects:\n            if not isinstance(obj, (type, ModuleType, FunctionType)) and id(obj) not in seen_ids:\n                seen_ids.add(id(obj))\n                size += sys.getsizeof(obj)\n                need_referents.append(obj)\n        objects = get_referents(*need_referents)\n    return size\n</code></pre>"},{"location":"reference/spectral_clustering/utils/sparse/","title":"sparse","text":""}]}